---
status: wip
type: documentation
---
# Lukhas Orchestrator: Skill Capsules & Neurofabric

# North-star principles

* **Don’t delete; encapsulate.** Wrap each submodule as a “skill capsule” with a tiny adapter, not a rewrite.
* **Uniform contracts → emergent graphs.** If every capsule advertises inputs/outputs/cost/safety, an orchestrator can wire them together on demand.
* **Two loops, one fabric.** Fast **reflex loop** (policy-gated actions) + slower **deliberation loop** (planning, reflection, learning) run over the same event fabric.

---

# 1) Skill Capsules: a universal wrapper for every submodule

Give every directory in `core/`, `memory/`, `consciousness/` a **manifest** + a **thin adapter** exposing the same entrypoints.

### 1.1 `module.yaml` (declarative manifest)

Place at the submodule root:

```yaml
name: bio_symbolic
version: 0.3.1
lane: candidate           # accepted | candidate | quarantine
owner: research@lukhas.ai
category: reasoning       # memory|reasoning|io|safety|planning|analysis
risk_class: R2            # R0 (no risk) → R4 (privileged)
inputs:
  - name: text
    schema: string
  - name: context
    schema_ref: schemas/context_v1.json
outputs:
  - name: embedding
    schema_ref: schemas/vec768.json
  - name: trace
    schema_ref: schemas/trace_v1.json
events_published:
  - topic: lukhas.reasoning.embedding.created
events_subscribed:
  - topic: lukhas.memory.recall.requested
capabilities:
  - reason.embed
cost_estimate_ms: 18
safety:
  scopes_required: [ "memory.read", "trace.write" ]
  pii_touch: none
  policy_gate: guardian.v1
healthcheck: python -m bio_symbolic.healthcheck
```

### 1.2 Adapter shim (one file per module)

Common Python interface (keeps legacy code intact):

```python
# adapters/skills/bio_symbolic.py
from lukhas.accepted.orchestrator.skill_api import Skill

class BioSymbolic(Skill):
    NAME = "bio_symbolic"
    VERSION = "0.3.1"
    CAPABILITIES = ["reason.embed"]
    RISK_CLASS = "R2"

    def run(self, *, text: str, context: dict = None, **kw):
        # call into original module without changing it
        from lukhas.candidate.bio_symbolic import embed  # legacy untouched
        vec, trace = embed(text, context or {})
        return {"embedding": vec, "trace": trace}
```

> Outcome: every submodule now looks identical to the orchestrator: **discoverable**, **routable**, **measurable**.

---

# 2) The Neurofabric: typed events + semantic I/O matching

Your earlier context bus shim can evolve into a **Neurofabric** that supports both rule-based and learned wiring.

### 2.1 Typed topics

* `lukhas.identity.*` (auth/ΛID)
* `lukhas.memory.*` (write/read/recall)
* `lukhas.reasoning.*` (plan/act/explain)
* `lukhas.consciousness.*` (reflect/evaluate)
* `lukhas.io.*` (email/drive/web)

Each event carries:

```json
{
  "topic": "lukhas.reasoning.plan.requested",
  "payload": { "goal": "...", "constraints": ["safe","cost<50ms"] },
  "schema": "schemas/plan_request_v1.json",
  "trace_id": "LT-...",
  "capabilities": ["plan.compose"]
}
```

### 2.2 Affordance (emergent) routing

* **Symbolic match:** “capabilities” and JSON-Schema I/O compatibility.
* **Semantic match (optional):** cosine(sim(“goal”), module descriptor). This lets a reasoning module “discover” memory tools it hasn’t hard-coded.
* **Bandit selection:** if 3 skills can serve, pick via UCB/Thompson Sampling on past reward (quality, latency, user rating).

---

# 3) Memory as a first-class substrate (not a DB)

Make `memory/` the **shared workspace** every capsule can lean on—no direct DBs from skills.

**Memory Facade API**

* `write_event(trace, ttl, tags)` → append-only
* `read_semantic(query, k, filters)` → vectors + filters
* `get_working(key, ttl=…)/set_working(key, obj, ttl)` → task scratchpad
* `folds.begin(session_id)/commit/rollback` → snapshotting for pipelines
* `policy_memo(scope)` → cached policy decisions (reduce hot-path calls)

Memory types:

* **Episodic** (events/Λ-traces)
* **Semantic** (embeddings, lexicons)
* **Procedural** (tools proficiency, “how to do X”)
* **Config** (feature flags, lanes, risk)

> Anything in `consciousness/` should **never** write elsewhere—always via the facade → auditability + reversibility.

---

# 4) Consciousness as control, not magic

Use `consciousness/` to **govern** the graph, not to do the work itself.

Loops:

* **Reflex loop (fast path):** goal → policy gate → skill execution → Λ-trace.
* **Deliberation loop (slow path):** plan (SRM) → evaluate (MAE) → select pipeline → run → reflect (CIL) → update bandit priors + memory.

**What to implement now**

* `SRM.plan(goal, constraints)` → returns a DAG of skill calls (edges carry scopes + cost ceilings)
* `MAE.evaluate(dag, policy)` → mutates/annotates DAG (block risky edges, add step-up prompts)
* `CIL.reflect(outcome, feedback)` → writes a learning delta to memory (improve next routing)

---

# 5) Core as the spine

Let `core/` provide:

* **Capability tokens** & scope enforcement in hot path
* **Rate limiting** per capability & user
* **Resource scheduler** (CPU/GPU slots for heavy skills)
* **Message contracts** (schema registry; reject ambiguous payloads)
* **Observability** (spans, metrics per skill & edge)

---

# 6) Migration path for your existing code (no deprecation)

1. **Index**: auto-generate `module.yaml` for every subdir (heuristics from filenames).
2. **Wrap**: add 50-line `Skill` adapter pointing at the legacy function(s).
3. **Register**: `skill_registry.load_from(repo_root)` reads all manifests.
4. **Test**: golden path per skill (`run()` smoke test + contract test).
5. **Measure**: log latency, error, user feedback → feed bandit.
6. **Plasticity rules**: if (error\_rate↑ or quality↓) → reroute to alternative skill until self-heals.

---

# 7) Safety & alignment baked in

* **Default-deny scopes** on every edge; **step-up** on risky transitions.
* **Λ-trace** for all privileged actions (already in your shim).
* **Duress/shadow gesture** → halt pipeline + alert.
* **Kill-switch** feature flag per skill capsule; zero-cost rollback.
* **Residency & logging**: everything through Memory Facade → reproducible.

---

# 8) Quick wins (next 48 hours)

1. **Drop a manifest** into 10 high-value submodules (3/core, 4/memory, 3/consciousness).
2. **Add adapters** (one file each) implementing `Skill.run(**kw)`.
3. **Skill Registry**: tiny loader that scans `**/module.yaml`, registers skills on the bus.
4. **Memory Facade**: one module with the 5 calls listed above; wire traces there.
5. **Reflex pipeline**: goal → `identity_tag_resolver` → `memory.read_semantic` → chosen skill → `memory.write_event`.
6. **Bandit selector**: simplest UCB on success/latency/reward (emoji stars or 1-5).
7. **Two canaries**:

   * *Reasoning* (e.g., `bio_symbolic` → embedding)
   * *Memory* (recall→augment→summarize)

---

# 9) Deeper wins (2 weeks)

* **MAE/SRM/CIL** thin versions (see §4): plan/evaluate/reflect that just annotate DAGs.
* **Schema registry**: JSON Schemas for top 15 message types.
* **Plasticity policies**: YAML rules like “if scope = drive.write → require\_step\_up”.
* **Semantic I/O matching**: embed `inputs/outputs` docs once and cache.

---

# 10) Prompts for your Claude agents (copy/paste)

### A4 – Orchestration Brain

> Implement the Skill Capsule system.
>
> 1. Create `lukhas/accepted/orchestrator/skill_api.py` exposing `class Skill`, `register(skill)`, and `invoke(name, **kw)`.
> 2. Create `lukhas/accepted/orchestrator/skill_registry.py` that scans for `module.yaml`, validates, imports `adapters/skills/<name>.py`, and registers.
> 3. Extend the context bus to support `skills.invoke` topic with payload `{name, inputs}`, returning `{outputs, trace_id}`.
> 4. Add UCB bandit selector when `name` is a capability (e.g., `reason.embed`) not a concrete skill.

### A3 – Integration Master

> For each of these modules, add a `module.yaml` + adapter:
>
> * `core/identity_tag_resolver`
> * `memory/semantic_folds`
> * `memory/interface`
> * `consciousness/self_reflection`
> * `consciousness/moral_alignment_engine`
> * `core/quantum_attention` (mark risk\_class R3)
>   Provide smoke tests calling `Skill.run()`.

### A6 – Testing & DevOps

> Add contract tests: `tests/skills/test_contracts.py` iterates over registry and validates:
>
> * manifest present, schema links resolve, `run()` returns declared outputs, Λ-trace recorded for risk\_class ≥ R2.
>   Add latency & error histogram per skill. Fail tests if any P95 > target or missing trace.

### A2 – Compliance Guardian

> Implement policy gates: given edge `{from_skill→to_skill, scopes}`, enforce scopes; add `require_step_up` for `drive.write`, `email.send`, and any R≥R3; record denial & rationale in Λ-trace.

### A5 – UX & Feedback

> Add a tiny UI card “Why this step?” showing the DAG and the policy rationale; star/emoji feedback posted as `lukhas.feedback.rating` → used as reward in bandit.

### A7 – Security Ops

> Wrap risky skills with capability tokens (hot path); ensure tokens never leave the process in logs; add gitleaks/semgrep checks for adapters.

---

# 11) Minimal code you can drop in now

**Skill base (tiny)**

```python
# lukhas/accepted/orchestrator/skill_api.py
from abc import ABC, abstractmethod

class Skill(ABC):
    NAME: str
    VERSION: str
    CAPABILITIES: list[str] = []
    RISK_CLASS: str = "R1"

    @abstractmethod
    def run(self, **kwargs): ...

# simple global registry
_REG = {}
def register(skill: Skill):
    _REG[skill.NAME] = skill

def invoke(name: str, **kw):
    if name in _REG:
        return _REG[name].run(**kw)
    # treat name as capability → pick via bandit (stub)
    cand = [s for s in _REG.values() if name in s.CAPABILITIES]
    if not cand:
        raise LookupError(f"No skill or capability '{name}'")
    # naive selection for now
    return cand[0].run(**kw)
```

**Registry loader (skeleton)**

```python
# lukhas/accepted/orchestrator/skill_registry.py
import pathlib, yaml, importlib
from .skill_api import register

def load_from(root: str):
    for p in pathlib.Path(root).rglob("module.yaml"):
        data = yaml.safe_load(p.read_text())
        name = data["name"]
        adapter = f"adapters.skills.{name}"
        try:
            mod = importlib.import_module(adapter)
            # adapter module must expose a class named CamelCase of name
            clsname = ''.join(part.capitalize() for part in name.split('_'))
            register(getattr(mod, clsname)())
        except Exception as e:
            # log but don’t crash the whole load
            print(f"[skill-registry] skip {name}: {e}")
```

---

## Why this works for my vision:

* **Brain-inspired**: skills = cortical columns; neurofabric = white-matter tracts; plasticity = bandit + reflection.
* **Emergence without chaos**: strict contracts + policy gates + telemetry let me rewire safely.
* **No deprecation necessary**: legacy logic is preserved, wrapped, measured, and promoted when it proves itself.

---
## MATADA Alignment Update (v1)

**Contract:** Every Skill Capsule MUST emit a `node_out` conforming to `matada_node_v1.json` (`$id: lukhas://schemas/matada_node_v1.json`). The orchestrator treats nodes as first-class outputs and routes by declared `capabilities` + schema compatibility.

**Adapter change:** Extend each `adapters/skills/<name>.py` to return:
```python
return {
  "outputs": {...},
  "trace_id": trace_id,
  "node_out": matada_node  # validated against schema
}
```

Registry checks: The skill registry validates node_out during smoke tests. CI fails if schema validation fails, if provenance.consent_scopes is missing, or if state.confidence/salience are absent.

Governance: Nodes MUST include provenance.{tenant,policy_version,capabilities} to allow retrospective audits, policy replay, and residency checks.
