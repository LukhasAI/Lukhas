"""
âš›ï¸ True Quantum Entropy Generator for QRG System

Provides quantum-grade randomness for cryptographic operations and consciousness-aware
pattern generation in Quantum Resonance Glyphs.
"""

import hashlib
import logging
import os
import secrets
import time
from dataclasses import dataclass
from enum import Enum
from typing import Any, Optional

import numpy as np

logger = logging.getLogger(__name__)


# Î›TAG: entropy_source_catalog
class QuantumEntropySource(Enum):
    """Available quantum entropy sources"""

    HARDWARE_RNG = "hardware_rng"
    QUANTUM_API = "quantum_api"
    ATMOSPHERIC_NOISE = "atmospheric_noise"
    CRYPTOGRAPHIC_SECURE = "cryptographic_secure"
    HYBRID_ENSEMBLE = "hybrid_ensemble"


# Backwards compatibility for legacy imports
QIEntropySource = QuantumEntropySource


@dataclass
class EntropyProfile:
    """Profile for entropy generation requirements"""

    bits_required: int = 256
    quality_level: str = "quantum_grade"  # quantum_grade, crypto_secure, standard
    refresh_rate: float = 1.0  # Hz
    bias_correction: bool = True
    von_neumann_extraction: bool = True
    chi_squared_validation: bool = True


class TrueQuantumRandomness:
    """
    âš›ï¸ True Quantum Entropy Generator

    Provides quantum-grade randomness for cryptographic security and consciousness-aware
    pattern generation in QRG systems. Implements multiple entropy sources with
    bias correction and statistical validation.
    """

    def __init__(
        self,
        entropy_source: QuantumEntropySource = QuantumEntropySource.HYBRID_ENSEMBLE,
    ):
        """
        Initialize quantum entropy generator

        Args:
            entropy_source: Primary entropy source to use
        """
        self.entropy_source = entropy_source
        self.entropy_pool = bytearray()
        self.pool_size = 4096  # bytes
        self.min_entropy_threshold = 0.8  # bits per byte

        # Entropy quality metrics
        self.entropy_quality = {
            "bias": 0.0,
            "autocorrelation": 0.0,
            "chi_squared": 0.0,
            "entropy_rate": 0.0,
        }

        self._initialize_entropy_sources()
        self._seed_entropy_pool()

        logger.info(f"âš›ï¸ Quantum entropy generator initialized with {entropy_source.value}")

    def _initialize_entropy_sources(self):
        """Initialize available entropy sources"""
        self.entropy_sources = {}

        # Hardware RNG (if available)
        try:
            # Check for hardware random number generator
            with open("/dev/hwrng", "rb") as hwrng:
                test_bytes = hwrng.read(32)
                if len(test_bytes) == 32:
                    self.entropy_sources[QuantumEntropySource.HARDWARE_RNG] = True
                    logger.info("ðŸ”§ Hardware RNG detected and available")
        except (FileNotFoundError, PermissionError):
            self.entropy_sources[QuantumEntropySource.HARDWARE_RNG] = False

        # Cryptographic secure random (always available)
        self.entropy_sources[QuantumEntropySource.CRYPTOGRAPHIC_SECURE] = True

        # Quantum API sources (simulated - in production would connect to quantum
        # services)
        self.entropy_sources[QuantumEntropySource.QUANTUM_API] = True

        # Atmospheric noise (simulated)
        self.entropy_sources[QuantumEntropySource.ATMOSPHERIC_NOISE] = True
        logger.info(f"ðŸŒ Initialized {sum(self.entropy_sources.values())} entropy sources")

    def _seed_entropy_pool(self):
        """Seed the initial entropy pool"""
        # Combine multiple entropy sources
        seed_sources = [
            secrets.token_bytes(32),  # Cryptographically secure
            os.urandom(32),  # OS random
            self._generate_timing_entropy(32),  # Timing-based
            self._generate_memory_entropy(32),  # Memory layout
            self._simulate_quantum_entropy(32),  # Simulated quantum
        ]

        # Hash combine all sources
        combined_entropy = b"".join(seed_sources)
        seed_hash = hashlib.blake2b(combined_entropy, digest_size=64).digest()

        self.entropy_pool.extend(seed_hash)
        logger.info(f"ðŸŒ± Entropy pool seeded with {len(self.entropy_pool)} bytes")

    def generate_quantum_bytes(self, num_bytes: int, profile: Optional[EntropyProfile] = None) -> bytes:
        """
        Generate quantum-grade random bytes

        Args:
            num_bytes: Number of bytes to generate
            profile: Optional entropy profile for requirements

        Returns:
            bytes: Quantum-grade random bytes
        """
        if not profile:
            profile = EntropyProfile(bits_required=num_bytes * 8)

        # Ensure we have sufficient entropy
        self._maintain_entropy_pool(num_bytes * 2)

        # Extract entropy based on source
        if self.entropy_source == QuantumEntropySource.HYBRID_ENSEMBLE:
            raw_bytes = self._extract_hybrid_entropy(num_bytes)
        elif self.entropy_source == QuantumEntropySource.QUANTUM_API:
            raw_bytes = self._extract_quantum_api_entropy(num_bytes)
        elif self.entropy_source == QuantumEntropySource.HARDWARE_RNG:
            raw_bytes = self._extract_hardware_entropy(num_bytes)
        else:
            raw_bytes = self._extract_cryptographic_entropy(num_bytes)

        # Apply bias correction if requested
        corrected_bytes = self._apply_bias_correction(raw_bytes) if profile.bias_correction else raw_bytes

        # Apply von Neumann extraction if requested
        if profile.von_neumann_extraction:
            extracted_bytes = self._von_neumann_extract(corrected_bytes, num_bytes)
        else:
            extracted_bytes = corrected_bytes[:num_bytes]

        # Validate quality if requested
        if profile.chi_squared_validation:
            self._validate_entropy_quality(extracted_bytes)

        logger.debug(f"âš›ï¸ Generated {len(extracted_bytes)} quantum bytes")
        return extracted_bytes

    def _extract_hybrid_entropy(self, num_bytes: int) -> bytes:
        """Extract entropy from multiple sources and combine"""
        sources_data = []

        # Quantum API source (simulated)
        if self.entropy_sources.get(QuantumEntropySource.QUANTUM_API):
            sources_data.append(self._simulate_quantum_entropy(num_bytes))

        # Hardware RNG source
        if self.entropy_sources.get(QuantumEntropySource.HARDWARE_RNG):
            sources_data.append(self._extract_hardware_entropy(num_bytes))

        # Cryptographic source
        sources_data.append(self._extract_cryptographic_entropy(num_bytes))

        # Atmospheric noise (simulated)
        sources_data.append(self._simulate_atmospheric_noise(num_bytes))

        # Combine using cryptographic hash
        combined = b"".join(sources_data)
        return hashlib.blake2b(combined, digest_size=num_bytes).digest()

    def _extract_quantum_api_entropy(self, num_bytes: int) -> bytes:
        """Extract entropy from qi API sources (simulated)"""
        # In production, would connect to:
        # - IBM Quantum Network
        # - IonQ quantum computers
        # - Rigetti quantum processors
        # - ID Quantique quantum RNGs

        # Simulated quantum measurements
        quantum_measurements = []
        for _ in range(num_bytes * 8):
            # Simulate quantum bit measurement (0 or 1)
            # In reality, would measure quantum superposition collapse
            measurement = secrets.randbelow(2)
            quantum_measurements.append(measurement)

        # Convert measurements to bytes
        quantum_bytes = bytearray()
        for i in range(0, len(quantum_measurements), 8):
            byte_bits = quantum_measurements[i : i + 8]
            if len(byte_bits) == 8:
                byte_value = sum(bit * (2 ** (7 - idx)) for idx, bit in enumerate(byte_bits))
                quantum_bytes.append(byte_value)

        return bytes(quantum_bytes[:num_bytes])

    def _extract_hardware_entropy(self, num_bytes: int) -> bytes:
        """Extract entropy from hardware RNG"""
        try:
            # Try hardware RNG first
            with open("/dev/hwrng", "rb") as hwrng:
                return hwrng.read(num_bytes)
        except (FileNotFoundError, PermissionError):
            # Fallback to OS urandom (which may use hardware on some systems)
            return os.urandom(num_bytes)

    def _extract_cryptographic_entropy(self, num_bytes: int) -> bytes:
        """Extract cryptographically secure entropy"""
        return secrets.token_bytes(num_bytes)

    def _simulate_quantum_entropy(self, num_bytes: int) -> bytes:
        """Simulate quantum entropy generation"""
        # Simulate quantum measurements with realistic noise characteristics
        measurements = []

        for _ in range(num_bytes * 8):
            # Simulate quantum superposition collapse
            # Real quantum measurements would show true randomness
            base_random = secrets.randbits(1)

            # Add quantum-like noise characteristics
            timing_noise = int(time.time() * 1000000) % 2
            measurement = base_random ^ timing_noise
            measurements.append(measurement)

        # Convert to bytes
        quantum_bytes = bytearray()
        for i in range(0, len(measurements), 8):
            bits = measurements[i : i + 8]
            if len(bits) == 8:
                byte_val = sum(bit << (7 - j) for j, bit in enumerate(bits))
                quantum_bytes.append(byte_val)

        return bytes(quantum_bytes[:num_bytes])

    def _simulate_atmospheric_noise(self, num_bytes: int) -> bytes:
        """Simulate atmospheric noise entropy"""
        # In production, would sample atmospheric radio noise
        # Using simulated atmospheric characteristics

        noise_samples = []
        base_time = time.time()

        for i in range(num_bytes):
            # Simulate atmospheric noise with time-varying characteristics
            time_factor = (base_time + i * 0.001) * 1000000
            noise_sample = int(time_factor) % 256

            # Add some variation
            variation = secrets.randbelow(64) - 32
            noise_sample = (noise_sample + variation) % 256

            noise_samples.append(noise_sample)

        return bytes(noise_samples)

    def _generate_timing_entropy(self, num_bytes: int) -> bytes:
        """Generate entropy from high-resolution timing"""
        timing_bytes = []

        for _ in range(num_bytes):
            # High-resolution timing
            precise_time = time.time_ns()
            timing_byte = precise_time % 256
            timing_bytes.append(timing_byte)

            # Small delay to ensure timing variation
            time.sleep(0.000001)  # 1 microsecond

        return bytes(timing_bytes)

    def _generate_memory_entropy(self, num_bytes: int) -> bytes:
        """Generate entropy from memory layout randomization"""
        memory_objects = []

        # Create objects to sample memory layout entropy
        for _ in range(num_bytes):
            # Memory addresses contain ASLR entropy
            obj = object()
            addr = id(obj)
            memory_byte = addr % 256
            memory_objects.append(memory_byte)

        return bytes(memory_objects)

    def _apply_bias_correction(self, raw_bytes: bytes) -> bytes:
        """Apply bias correction to raw entropy"""
        # Von Neumann debiasing for each pair of bits
        debiased_bits = []

        for byte_val in raw_bytes:
            for i in range(0, 8, 2):
                bit1 = (byte_val >> i) & 1
                bit2 = (byte_val >> (i + 1)) & 1

                # Von Neumann debiasing: 01 -> 0, 10 -> 1, 00/11 -> discard
                if bit1 == 0 and bit2 == 1:
                    debiased_bits.append(0)
                elif bit1 == 1 and bit2 == 0:
                    debiased_bits.append(1)

        # Convert back to bytes
        debiased_bytes = bytearray()
        for i in range(0, len(debiased_bits), 8):
            if i + 7 < len(debiased_bits):
                byte_val = sum(debiased_bits[i + j] << (7 - j) for j in range(8))
                debiased_bytes.append(byte_val)

        return bytes(debiased_bytes)

    def _von_neumann_extract(self, input_bytes: bytes, output_length: int) -> bytes:
        """Apply von Neumann extraction for uniform distribution"""
        # Implementation of von Neumann extraction
        extracted_bits = []

        for byte_val in input_bytes:
            for i in range(0, 8, 2):
                if len(extracted_bits) >= output_length * 8:
                    break

                bit1 = (byte_val >> i) & 1
                bit2 = (byte_val >> (i + 1)) & 1

                if bit1 != bit2:  # Different bits
                    extracted_bits.append(bit1)

        # Convert to bytes
        extracted_bytes = bytearray()
        for i in range(0, len(extracted_bits), 8):
            if len(extracted_bytes) >= output_length:
                break
            if i + 7 < len(extracted_bits):
                byte_val = sum(extracted_bits[i + j] << (7 - j) for j in range(8))
                extracted_bytes.append(byte_val)

        # Pad if necessary
        while len(extracted_bytes) < output_length:
            extracted_bytes.append(0)

        return bytes(extracted_bytes[:output_length])

    def _validate_entropy_quality(self, entropy_bytes: bytes) -> dict[str, float]:
        """Validate entropy quality using statistical tests"""
        if not entropy_bytes:
            return {"error": "No entropy to validate"}

        # Chi-squared test
        chi_squared = self._chi_squared_test(entropy_bytes)

        # Bias calculation
        bias = self._calculate_bias(entropy_bytes)

        # Autocorrelation test
        autocorr = self._autocorrelation_test(entropy_bytes)

        # Entropy rate calculation
        entropy_rate = self._calculate_entropy_rate(entropy_bytes)

        quality_metrics = {
            "chi_squared": chi_squared,
            "bias": bias,
            "autocorrelation": autocorr,
            "entropy_rate": entropy_rate,
            "quality_score": self._calculate_quality_score(chi_squared, bias, autocorr, entropy_rate),
        }

        self.entropy_quality.update(quality_metrics)

        if quality_metrics["quality_score"] < 0.8:
            logger.warning(f"âš ï¸ Low entropy quality: {quality_metrics['quality_score']:.3f}")
        else:
            logger.debug(f"âœ… Good entropy quality: {quality_metrics['quality_score']:.3f}")

        return quality_metrics

    def _chi_squared_test(self, data: bytes) -> float:
        """Perform chi-squared test for uniformity"""
        if not data:
            return 1.0

        # Count frequency of each byte value
        frequencies = [0] * 256
        for byte_val in data:
            frequencies[byte_val] += 1

        # Expected frequency
        expected = len(data) / 256.0

        # Chi-squared statistic
        chi_squared = sum((freq - expected) ** 2 / expected for freq in frequencies if expected > 0)

        # Normalize (rough approximation)
        return min(chi_squared / (255 * expected), 1.0)

    def _calculate_bias(self, data: bytes) -> float:
        """Calculate bias in bit distribution"""
        if not data:
            return 0.0

        bit_count = 0
        total_bits = len(data) * 8

        for byte_val in data:
            bit_count += bin(byte_val).count("1")

        expected_bits = total_bits / 2.0
        bias = abs(bit_count - expected_bits) / expected_bits

        return bias

    def _autocorrelation_test(self, data: bytes) -> float:
        """Test for autocorrelation in the data"""
        if len(data) < 2:
            return 0.0

        # Simple lag-1 autocorrelation
        mean_val = sum(data) / len(data)

        numerator = sum((data[i] - mean_val) * (data[i + 1] - mean_val) for i in range(len(data) - 1))
        denominator = sum((x - mean_val) ** 2 for x in data)

        if denominator == 0:
            return 0.0

        autocorr = abs(numerator / denominator)
        return autocorr

    def _calculate_entropy_rate(self, data: bytes) -> float:
        """Calculate Shannon entropy rate"""
        if not data:
            return 0.0

        # Count byte frequencies
        frequencies = {}
        for byte_val in data:
            frequencies[byte_val] = frequencies.get(byte_val, 0) + 1

        # Calculate entropy
        entropy = 0.0
        data_len = len(data)

        for count in frequencies.values():
            prob = count / data_len
            if prob > 0:
                entropy -= prob * np.log2(prob)

        # Normalize to [0, 1]
        max_entropy = 8.0  # 8 bits per byte
        return entropy / max_entropy

    def _calculate_quality_score(self, chi_squared: float, bias: float, autocorr: float, entropy_rate: float) -> float:
        """Calculate overall quality score"""
        # Weight different factors
        weights = {
            "chi_squared": 0.2,  # Lower is better
            "bias": 0.3,  # Lower is better
            "autocorr": 0.2,  # Lower is better
            "entropy_rate": 0.3,  # Higher is better
        }

        # Convert to quality scores (0-1, higher is better)
        chi_quality = 1.0 - min(chi_squared, 1.0)
        bias_quality = 1.0 - min(bias, 1.0)
        autocorr_quality = 1.0 - min(autocorr, 1.0)
        entropy_quality = entropy_rate

        overall_quality = (
            weights["chi_squared"] * chi_quality
            + weights["bias"] * bias_quality
            + weights["autocorr"] * autocorr_quality
            + weights["entropy_rate"] * entropy_quality
        )

        return overall_quality

    def _maintain_entropy_pool(self, min_bytes: int):
        """Maintain entropy pool with minimum bytes available"""
        if len(self.entropy_pool) < min_bytes:
            additional_entropy = self._extract_hybrid_entropy(min_bytes * 2)
            self.entropy_pool.extend(additional_entropy)

            # Keep pool from growing too large
            if len(self.entropy_pool) > self.pool_size:
                self.entropy_pool = self.entropy_pool[-self.pool_size :]

    def get_entropy_quality_report(self) -> dict[str, Any]:
        """Get detailed entropy quality report"""
        return {
            "entropy_source": self.entropy_source.value,
            "available_sources": {source.value: available for source, available in self.entropy_sources.items()},
            "pool_size": len(self.entropy_pool),
            "quality_metrics": self.entropy_quality.copy(),
            "recommendations": self._generate_quality_recommendations(),
        }

    def _generate_quality_recommendations(self) -> list[str]:
        """Generate recommendations for improving entropy quality"""
        recommendations = []

        if self.entropy_quality.get("bias", 0) > 0.1:
            recommendations.append("Consider additional bias correction")

        if self.entropy_quality.get("autocorr", 0) > 0.1:
            recommendations.append("Increase entropy source diversity")

        if self.entropy_quality.get("entropy_rate", 1) < 0.9:
            recommendations.append("Verify entropy source quality")

        if not self.entropy_sources.get(QuantumEntropySource.HARDWARE_RNG):
            recommendations.append("Consider hardware RNG for enhanced security")

        return recommendations
