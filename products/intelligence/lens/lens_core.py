#!/usr/bin/env python3
"""
Î›Lens Core - Symbolic File Dashboard Engine
Transforms files into interactive AR/VR-ready symbolic representations
"""

import asyncio
import hashlib
import json
import time
import uuid
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Optional

# Import modular components
try:
    from .parsers import CodeParser, CSVParser, DataParser, MarkdownParser, PDFParser, TextParser
    from .renderers import Web2DRenderer, XRRenderer
    from .symbols import GlyphSymbol, SymbolGenerator
except ImportError:
    # Fallback for when module is imported outside package context
    from products.intelligence.lens.parsers import (
        CodeParser,
        CSVParser,
        DataParser,
        MarkdownParser,
        PDFParser,
        TextParser,
    )
    from products.intelligence.lens.renderers import Web2DRenderer, XRRenderer
    from products.intelligence.lens.symbols import GlyphSymbol, SymbolGenerator


@dataclass
class SymbolicDashboard:
    """Complete symbolic representation of a file"""

    id: str
    source_file: str
    symbols: list[GlyphSymbol]
    relationships: list[dict[str, Any]]
    metadata: dict[str, Any]
    render_format: str  # "2d", "3d", "ar", "vr"
    created_at: float
    lambda_signature: str  # Î› branded signature


class Î›Lens:
    """
    Main Î›Lens engine for symbolic file transformation
    Powered by LUKHAS consciousness and GLYPH communication
    """

    def __init__(self, config: Optional[dict] = None):
        self.config = config or self._default_config()
        self.dashboards: dict[str, SymbolicDashboard] = {}
        self.symbol_cache: dict[str, GlyphSymbol] = {}
        self.lambda_brand = "Î›"

        # Initialize subsystems
        self.parser_registry = self._init_parsers()
        self.symbol_generator = SymbolGenerator()
        self.relationship_analyzer = RelationshipAnalyzer()
        self.web_renderer = Web2DRenderer()
        self.ar_renderer = XRRenderer()

    def _default_config(self) -> dict:
        """Default Î›Lens configuration"""
        return {
            "brand": "LUKHAS",
            "symbol": "Î›",
            "max_symbols": 1000,
            "detail_level": "high",
            "privacy_mode": True,
            "local_processing": False,
            "ar_enabled": True,
            "consciousness_level": 0.8,
            "glyph_density": "medium",
        }

    def _init_parsers(self) -> dict:
        """Initialize file parsers"""
        return {
            "pdf": PDFParser(),
            "txt": TextParser(),
            "py": CodeParser(),
            "json": DataParser(),
            "md": MarkdownParser(),
            "csv": CSVParser(),
            # Add more parsers as needed
        }

    async def transform(self, file_path: str, options: Optional[dict] = None) -> SymbolicDashboard:
        """
        Transform a file into a symbolic dashboard

        Args:
            file_path: Path to the file to transform
            options: Optional transformation options

        Returns:
            SymbolicDashboard object with symbolic representation
        """
        options = options or {}
        file_ext = Path(file_path).suffix.lower().strip(".")

        # Select appropriate parser
        parser = self.parser_registry.get(file_ext)
        if not parser:
            raise ValueError(f"Unsupported file type: {file_ext}")

        # Parse file content
        parsed_content = await parser.parse(file_path)

        # Generate symbols
        symbols = await self.symbol_generator.generate(
            parsed_content,
            symbol_style=options.get("symbol_style", "modern"),
            max_symbols=options.get("max_symbols", self.config["max_symbols"]),
        )

        # Analyze relationships
        relationships = await self.relationship_analyzer.analyze(symbols)

        # Create dashboard
        dashboard_id = str(uuid.uuid4())
        dashboard = SymbolicDashboard(
            id=dashboard_id,
            source_file=file_path,
            symbols=symbols,
            relationships=relationships,
            metadata={
                "file_type": file_ext,
                "processing_time": time.time(),
                "options": options,
                "lambda_version": "1.0.0",
            },
            render_format=options.get("format", "3d"),
            created_at=time.time(),
            lambda_signature=self._generate_signature(symbols),
        )

        # Cache dashboard
        self.dashboards[dashboard_id] = dashboard

        # Render if requested
        if options.get("render", True):
            await self._render_dashboard(dashboard)

        return dashboard

    def _generate_signature(self, symbols: list[GlyphSymbol]) -> str:
        """Generate Lambda signature for dashboard"""
        symbol_hash = hashlib.sha256(json.dumps([s.id for s in symbols]).encode()).hexdigest()[:8]
        return f"{self.lambda_brand}-{symbol_hash.upper()}"

    async def _render_dashboard(self, dashboard: SymbolicDashboard):
        """Render dashboard in requested format"""
        if dashboard.render_format in ["ar", "vr", "3d"]:
            await self.ar_renderer.render(dashboard)
        elif dashboard.render_format in ["2d", "web"]:
            await self.web_renderer.render(dashboard)

    async def export_ar(self, dashboard_id: str, output_path: str) -> str:
        """Export dashboard for AR/VR viewing"""
        dashboard = self.dashboards.get(dashboard_id)
        if not dashboard:
            raise ValueError(f"Dashboard {dashboard_id} not found")

        # Convert to AR format (e.g., glTF)
        ar_data = await self.ar_renderer.export_gltf(dashboard)

        # Save to file
        with open(output_path, "wb") as f:
            f.write(ar_data)

        return output_path

    def get_dashboard(self, dashboard_id: str) -> Optional[SymbolicDashboard]:
        """Retrieve a cached dashboard"""
        return self.dashboards.get(dashboard_id)

    async def query_symbols(self, dashboard_id: str, query: str) -> list[GlyphSymbol]:
        """Query symbols in a dashboard using natural language"""
        dashboard = self.dashboards.get(dashboard_id)
        if not dashboard:
            return []

        # Simple keyword matching (could use NLP in production)
        results = []
        query_lower = query.lower()

        for symbol in dashboard.symbols:
            if query_lower in symbol.content.lower():
                results.append(symbol)

        return results


class RelationshipAnalyzer:
    """Analyzes relationships between symbols"""

    async def analyze(self, symbols: list[GlyphSymbol]) -> list[dict[str, Any]]:
        """Analyze relationships between symbols"""
        relationships = []

        # Simple similarity-based relationships
        for i, symbol1 in enumerate(symbols):
            for symbol2 in symbols[i + 1 :]:
                similarity = self._calculate_similarity(symbol1, symbol2)

                if similarity > 0.5:  # Threshold
                    relationship = {
                        "source": symbol1.id,
                        "target": symbol2.id,
                        "type": "related",
                        "strength": similarity,
                        "metadata": {"discovered_at": time.time()},
                    }
                    relationships.append(relationship)

                    # Update connections
                    symbol1.connections.append(symbol2.id)
                    symbol2.connections.append(symbol1.id)

        return relationships

    def _calculate_similarity(self, symbol1: GlyphSymbol, symbol2: GlyphSymbol) -> float:
        """Calculate similarity between two symbols"""
        # Simple text similarity (use better algorithms in production)
        content1 = symbol1.content.lower()
        content2 = symbol2.content.lower()

        # Check for common words
        words1 = set(content1.split())
        words2 = set(content2.split())

        if not words1 or not words2:
            return 0.0

        intersection = words1.intersection(words2)
        union = words1.union(words2)

        return len(intersection) / len(union) if union else 0.0


class ARRenderer:
    """Renders dashboards for AR/VR viewing"""

    async def render(self, dashboard: SymbolicDashboard):
        """Render dashboard in AR/VR format"""
        # Placeholder for AR rendering logic
        print(f"Rendering dashboard {dashboard.id} in {dashboard.render_format} format")

    async def export_gltf(self, dashboard: SymbolicDashboard) -> bytes:
        """Export dashboard as glTF for AR/VR"""
        # Simplified glTF structure
        gltf = {
            "asset": {"version": "2.0", "generator": "Î›Lens 1.0"},
            "scenes": [{"nodes": []}],
            "nodes": [],
            "meshes": [],
            "materials": [],
            "accessors": [],
            "bufferViews": [],
            "buffers": [],
        }

        # Add nodes for each symbol
        for i, symbol in enumerate(dashboard.symbols):
            node = {
                "name": f"symbol_{symbol.id}",
                "translation": list(symbol.position) if symbol.position else [0, 0, 0],
                "extras": {
                    "type": symbol.type.value,
                    "content": symbol.content,
                    "lambda": True,
                },
            }
            gltf["nodes"].append(node)
            gltf["scenes"][0]["nodes"].append(i)

        # Convert to JSON bytes
        return json.dumps(gltf, indent=2).encode("utf-8")


# Demo usage
if __name__ == "__main__":

    async def demo():
        """Demo Î›Lens functionality"""
        print("ğŸ” Î›Lens - Symbolic File Dashboard Demo")
        print("=" * 50)

        # Initialize Î›Lens
        lens = Î›Lens()

        # Create a sample file
        sample_file = "/tmp/sample.txt"
        with open(sample_file, "w") as f:
            f.write(
                """
            LUKHAS AI System Overview

            The LUKHAS system represents a breakthrough in symbolic artificial intelligence,
            combining consciousness modeling with ethical governance.

            Key Components:
            - Guardian System for ethical oversight
            - GLYPH communication protocol
            - Quantum-ready architecture
            - Lambda (Î›) branding throughout
            """
            )

        # Transform the file
        dashboard = await lens.transform(sample_file, {"format": "ar", "symbol_style": "modern"})

        print(f"\nâœ… Dashboard created: {dashboard.id}")
        print(f"ğŸ“Š Symbols generated: {len(dashboard.symbols)}")
        print(f"ğŸ”— Relationships found: {len(dashboard.relationships)}")
        print(f"Î› Signature: {dashboard.lambda_signature}")

        # Display symbols
        print("\nğŸ”® Generated Symbols:")
        for symbol in dashboard.symbols[:5]:
            print(f"  {symbol.type.value} {symbol.content[:50]}...")

        # Export for AR
        ar_path = "/tmp/dashboard.gltf"
        await lens.export_ar(dashboard.id, ar_path)
        print(f"\nğŸ“± AR export saved to: {ar_path}")

    # Run demo
    asyncio.run(demo())
