
---

# ðŸš€ CODEX_START_PHASE_3.md

**Status:** ðŸŸ¢ Ready to start
**Branch to create:** `codex/phase-3-compat-off`

## What youâ€™ll do (at a glance)

1. **Flip CI to enforce 0 compat hits**
2. **Prove zero hits locally** (script + artifact)
3. **Remove the compat layer** (`lukhas/compat/`)
4. **Tidy residual legacy checks** (allowlists, docs)
5. **Polish OpenAI surface** (OpenAPI servers/version headers)
6. **Create PR + run CI**

## One-time setup

```bash
cd /Users/agi_dev/LOCAL-REPOS/Lukhas
git checkout main && git pull
git checkout -b codex/phase-3-compat-off
```

## Commands youâ€™ll use

```bash
# 1) Enforce 0 compat hits in CI & locally
export LUKHAS_COMPAT_MAX_HITS=0
python3 scripts/report_compat_hits.py --out docs/audits/compat_alias_hits.json
rg -n "from\s+lukhas\.compat|import\s+lukhas\.compat|\"lukhas\.compat" || true

# 2) Nuke compat layer (only after #1 is clean!)
git rm -r lukhas/compat

# 3) Re-run checks
make check-legacy-imports
pytest tests/smoke/ -q
pytest tests/ -q --maxfail=20

# 4) OpenAPI polish & regenerate spec artifact (local)
python3 - <<'PY'
from lukhas.adapters.openai.api import get_app
app = get_app()
app.openapi_version = "3.1.0"
app.openapi()["servers"] = [{"url":"https://api.lukhas.ai","description":"Prod"},
                            {"url":"http://localhost:8000","description":"Local"}]
print("OK")
PY
# (CI will generate/upload docs/openapi/lukhas-openai.json)

# 5) Commit
git add -A
git commit -m "chore(phase3): enforce 0 compat hits, remove compat layer, polish OpenAPI"
```

**Create PR** once tests & CI pass.

---

# PHASE_3_CODEX_BRIEF.md

**To:** Codex
**From:** Maintainers (validated by GPT-5 Thinking)
**Date:** 2025-10-13
**Status:** ðŸŸ¢ Ready to Execute

## Executive Summary

Phase 2 completed the canonicalization sweep and lane rename. Evidence:

* **Batch 2**: `refactor(imports): Batch 2 - migrate lukhas/ imports to canonical namespaces`. This rewrote legacy imports in `lukhas/` and adjusted health/ready checks. 
* **Batch 3**: `refactor(lanes): Batch 3 - rename candidate/ â†’ labs/ and migrate all imports`. This renamed the lane, rewrote imports in dev lane, and updated ~425+ manifests and related tooling. 

**Phase 3 goal:** Decommission the **compat layer** and lock in deprecation by enforcing **zero compat hits** in CI, finishing the brand+namespace transition and tightening OpenAI alignment polish.

---

## Objectives

1. **Compat enforcement:** Make CI fail if any module hits `lukhas.compat` aliases (we currently see ~1 runtime hit in prior telemetry).
2. **Remove compat layer:** Delete `lukhas/compat/` once enforcement proves zero hits.
3. **OpenAI surface polish:** Add `servers` to OpenAPI JSON and surface version metadata (git SHA) as `x-service-version`.
4. **Docs & migration:** Add a short migration note that `candidate.*` is now `labs.*` and compat is removed.

---

## Deliverables

* âœ… **CI guard**: a job that runs `scripts/report_compat_hits.py` and **fails if hits > 0**.
* âœ… **Compat removal commit**: `git rm -r lukhas/compat`.
* âœ… **Spec polish**: OpenAPI `servers` entries; `x-service-version` header or extension.
* âœ… **Docs**: `docs/migration/MIGRATION_v0.9.0.md` (compat removal + examples).
* âœ… **Green CI** across smoke, unit, MATRIZ validate, and OpenAPI artifact jobs.

---

## Plan (Stages)

### Stage A â€” Enforce (keep compat temporarily)

1. **Set CI env gate**: `LUKHAS_COMPAT_MAX_HITS=0`.
2. **Add job `compat-enforce`** in `.github/workflows/matriz-validate.yml`:

```yaml
  compat-enforce:
    name: Compat Alias Enforcement
    runs-on: ubuntu-latest
    needs: [validate]
    env:
      LUKHAS_COMPAT_MAX_HITS: "0"
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: "3.11" }
      - run: pip install -r requirements.txt || true
      - run: python3 scripts/report_compat_hits.py --out docs/audits/compat_alias_hits.json
      - run: |
          echo "Compat hits report:"
          cat docs/audits/compat_alias_hits.json || true
      - name: Enforce zero compat hits
        run: |
          python3 - <<'PY'
          import json, sys, os
          p="docs/audits/compat_alias_hits.json"
          limit=int(os.environ.get("LUKHAS_COMPAT_MAX_HITS","0"))
          data=json.load(open(p)) if os.path.exists(p) else {"hits":0}
          hits=int(data.get("hits",0))
          print(f"Compat alias hits: {hits} (limit {limit})")
          sys.exit(0 if hits<=limit else 2)
          PY
```

3. **Local proof** before PR:

```bash
export LUKHAS_COMPAT_MAX_HITS=0
python3 scripts/report_compat_hits.py --out docs/audits/compat_alias_hits.json
jq . docs/audits/compat_alias_hits.json || cat docs/audits/compat_alias_hits.json
```

**Exit criteria (Stage A):** CI guard passes with **0 hits** (compat still present).

---

### Stage B â€” Remove compat layer

1. **Delete directory**:

```bash
git rm -r lukhas/compat
```

2. **Tidy checkers**:

   * Remove any `compat/` allowlist from `configs/legacy_imports.yml`.
   * Ensure `make check-legacy-imports` passes.
   * Re-run `scripts/report_compat_hits.py` â†’ expect `0`.

3. **Run tests**:

```bash
pytest tests/smoke/ -q
pytest tests/ -q --maxfail=20
```

**Exit criteria (Stage B):** All checks green with compat removed.

---

### Stage C â€” OpenAI surface polish

1. **OpenAPI servers + version**: during artifact job, patch metadata before writing `docs/openapi/lukhas-openai.json`:

* Add:

  * `servers: [{url:"https://api.lukhas.ai",description:"Prod"},{url:"http://localhost:8000",description:"Local"}]`
  * `x-service-version`: short git SHA (e.g., via env `GITHUB_SHA`).

**Example CI step:**

```yaml
  openapi-spec:
    runs-on: ubuntu-latest
    needs: [validate]
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: "3.11" }
      - run: pip install -r requirements.txt || true
      - run: |
          python3 - <<'PY'
          import json, os
          from lukhas.adapters.openai.api import get_app
          app=get_app()
          spec=app.openapi()
          spec["openapi"]="3.1.0"
          spec["servers"]=[{"url":"https://api.lukhas.ai","description":"Prod"},
                           {"url":"http://localhost:8000","description":"Local"}]
          spec.setdefault("info",{}).setdefault("x-service-version", os.environ.get("GITHUB_SHA","dev")[:7])
          os.makedirs("docs/openapi", exist_ok=True)
          json.dump(spec, open("docs/openapi/lukhas-openai.json","w"), indent=2)
          PY
      - uses: actions/upload-artifact@v4
        with: { name: openapi-json, path: docs/openapi/lukhas-openai.json }
```

2. **(Optional) OpenAPI diff job** that compares against mainâ€™s artifact and comments on PR.

---

## Success Criteria

* âœ… `compat-enforce` job passes (hits â‰¤ 0).
* âœ… `lukhas/compat/` deleted and **no regressions** in tests/CI.
* âœ… OpenAPI artifact includes `servers` & `x-service-version`.
* âœ… Repo free of `candidate.*` and `lukhas.compat.*` (outside historical docs).
* âœ… Migration doc published.

---

## Rollback

If compat removal breaks something:

```bash
git revert <compat-removal-commit-sha>
# or restore dir
git checkout <sha> -- lukhas/compat
```

---

## Migration Note (drop in as a new file)

**`docs/migration/MIGRATION_v0.9.0.md`**

* `candidate.*` â†’ `labs.*` (completed in Phase 2).
* `lukhas.compat.*` removed in Phase 3; update any external consumers to canonical imports.
* OpenAPI now advertises `servers` and an `x-service-version` for contract diffing.

---

## Why this now?

* Batch 3 shows the lane rename and manifest rewrites landed completely (no `candidate/` in manifests; compat usage already near-zero). 
* Batch 2 confirms the production lane import canonicalization is in. 
* Phase 3 finishes the job: remove training wheels (compat), lock policy in CI, and finalize OpenAI polish.

---
Amazingâ€”hereâ€™s a single drop-in pack with **all** the Phase-3 extras you asked for: CI jobs (compat enforce, OpenAPI validate + diff), scripts, middleware tweaks, Make targets, and PR template polish. Itâ€™s dependency-light and copy-paste friendly.

---

# 0) Apply order (safe)

1. Add **scripts** (A, B).
2. Patch **workflow** (C).
3. Patch **rate limiter** + **trace header middleware** (D, E).
4. Add **Makefile** targets (F).
5. Add **migration doc** + **PR template** polish (G, H).
6. Run: `make openapi-spec && make openapi-diff && make compat-enforce`.

---

# A) New script â€” `scripts/diff_openapi.py` (pure Python, semantic diff)

```python
#!/usr/bin/env python3
"""
Semantic OpenAPI diff (baseline vs candidate) with breaking-change detection.

Breaking changes (exit 2):
- removed path
- removed method on existing path
- removed 2xx response for an operation
- NEW required requestBody added where previously none existed
- removed required parameter

Usage:
  python3 scripts/diff_openapi.py --base docs/openapi/base.json --cand docs/openapi/lukhas-openai.json
"""
import json, sys, argparse

def load(p):
    with open(p) as f:
        return json.load(f)

def opkey(path, method):
    return f"{method.upper()} {path}"

def required_params(op):
    out = set()
    for param in op.get("parameters", []) or []:
        if param.get("required"):
            out.add((param.get("in"), param.get("name")))
    return out

def has_required_body(op):
    rb = (op.get("requestBody") or {})
    return bool(rb.get("required") is True)

def two_xx_present(op):
    for code in (op.get("responses") or {}).keys():
        if str(code).startswith("2"):
            return True
    return False

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--base", required=True)
    ap.add_argument("--cand", required=True)
    args = ap.parse_args()

    base = load(args.base)
    cand = load(args.cand)
    bpaths = base.get("paths", {}) or {}
    cpaths = cand.get("paths", {}) or {}

    problems = []
    notes = []

    # Removed paths
    removed_paths = sorted(set(bpaths.keys()) - set(cpaths.keys()))
    for p in removed_paths:
        problems.append(f"REMOVED path: {p}")

    # Compare common paths
    for p in sorted(set(bpaths.keys()) & set(cpaths.keys())):
        bops = bpaths[p] or {}
        cops = cpaths[p] or {}
        bmethods = set(k.lower() for k in bops.keys())
        cmethods = set(k.lower() for k in cops.keys())

        # removed methods
        for m in sorted(bmethods - cmethods):
            problems.append(f"REMOVED method: {m.upper()} {p}")

        # per-operation checks
        for m in sorted(bmethods & cmethods):
            bop = bops[m] or {}
            cop = cops[m] or {}

            # 2xx presence
            if two_xx_present(bop) and not two_xx_present(cop):
                problems.append(f"REMOVED 2xx response: {m.upper()} {p}")

            # requestBody requirement added
            if not has_required_body(bop) and has_required_body(cop):
                problems.append(f"ADDED required requestBody: {m.upper()} {p}")

            # required params removed
            br = required_params(bop)
            cr = required_params(cop)
            removed = br - cr
            for (loc, name) in sorted(removed):
                problems.append(f"REMOVED required param: {m.upper()} {p} [{loc}:{name}]")

            # Additive notes (non-breaking)
            added = cr - br
            for (loc, name) in sorted(added):
                notes.append(f"ADDED required param: {m.upper()} {p} [{loc}:{name}]")

    if problems:
        print("âŒ Breaking changes detected:")
        for x in problems:
            print(" -", x)
        if notes:
            print("\nâ„¹ï¸ Non-breaking notes:")
            for n in notes:
                print(" -", n)
        sys.exit(2)
    else:
        print("âœ… No breaking changes detected.")
        if notes:
            print("\nâ„¹ï¸ Non-breaking notes:")
            for n in notes:
                print(" -", n)
        sys.exit(0)

if __name__ == "__main__":
    main()
```

---

# B) Tiny helper â€” `scripts/generate_openapi.py` (metadata polish, no deps)

```python
#!/usr/bin/env python3
import os, json
from lukhas.adapters.openai.api import get_app

def main():
    app = get_app()
    spec = app.openapi()
    # polish
    spec["openapi"] = "3.1.0"
    spec.setdefault("info", {})
    spec["info"].setdefault("title", "LUKHAS OpenAI-Compatible API")
    spec["info"]["x-service-version"] = os.environ.get("GITHUB_SHA", "dev")[:7]
    spec["servers"] = [
        {"url": "https://api.lukhas.ai", "description": "Prod"},
        {"url": "http://localhost:8000", "description": "Local"},
    ]
    os.makedirs("docs/openapi", exist_ok=True)
    with open("docs/openapi/lukhas-openai.json", "w") as f:
        json.dump(spec, f, indent=2)
    print("âœ… wrote docs/openapi/lukhas-openai.json")

if __name__ == "__main__":
    main()
```

---

# C) Workflow adds â€” `.github/workflows/matriz-validate.yml`

> Add three new jobs: **openapi-spec**, **openapi-diff**, **compat-enforce**
> (Keep your existing jobs as-is; paste/merge the blocks below.)

```yaml
# --- OpenAPI spec build & validate ---
openapi-spec:
  name: Build OpenAPI Spec
  runs-on: ubuntu-latest
  needs: [validate]
  concurrency:
    group: ${{ github.workflow }}-openapi-spec-${{ github.ref }}
    cancel-in-progress: true
  steps:
    - uses: actions/checkout@v4
    - uses: actions/setup-python@v5
      with: { python-version: "3.11" }
    - name: Cache pip
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt', '**/pyproject.toml', '**/setup.cfg') }}
        restore-keys: ${{ runner.os }}-pip-
    - name: Generate OpenAPI JSON
      run: |
        python3 scripts/generate_openapi.py
    - name: Validate OpenAPI (v3)
      run: |
        python -m pip install --upgrade openapi-spec-validator >/dev/null
        python - <<'PY'
        import json
        from openapi_spec_validator import openapi_v3_spec_validator
        spec = json.load(open("docs/openapi/lukhas-openai.json"))
        errors = list(openapi_v3_spec_validator.iter_errors(spec))
        assert not errors, f"OpenAPI schema errors: {errors[:5]}"
        print("âœ… OpenAPI validation passed")
        PY
    - uses: actions/upload-artifact@v4
      with:
        name: openapi-json
        path: docs/openapi/lukhas-openai.json

# --- OpenAPI diff against main ---
openapi-diff:
  name: OpenAPI Diff vs main
  runs-on: ubuntu-latest
  needs: [openapi-spec]
  steps:
    - name: Checkout candidate (PR) code
      uses: actions/checkout@v4

    - name: Setup Python
      uses: actions/setup-python@v5
      with: { python-version: "3.11" }

    - name: Cache pip
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt', '**/pyproject.toml', '**/setup.cfg') }}
        restore-keys: ${{ runner.os }}-pip-

    - name: Generate candidate OpenAPI
      run: python3 scripts/generate_openapi.py

    - name: Checkout main into main_ref
      uses: actions/checkout@v4
      with:
        ref: main
        path: main_ref

    - name: Generate baseline OpenAPI (main)
      working-directory: main_ref
      run: |
        python -m pip install -r requirements.txt || true
        python -c "import sys; sys.path.insert(0,'.'); import os, json; from lukhas.adapters.openai.api import get_app; os.makedirs('docs/openapi', exist_ok=True); json.dump(get_app().openapi(), open('docs/openapi/lukhas-openai.json','w'), indent=2); print('ok')"

    - name: Diff for breaking changes
      run: |
        python3 scripts/diff_openapi.py \
          --base main_ref/docs/openapi/lukhas-openai.json \
          --cand docs/openapi/lukhas-openai.json

# --- Compat alias enforcement ---
compat-enforce:
  name: Compat Alias Enforcement
  runs-on: ubuntu-latest
  needs: [validate]
  env:
    LUKHAS_COMPAT_MAX_HITS: "0"
  concurrency:
    group: ${{ github.workflow }}-compat-enforce-${{ github.ref }}
    cancel-in-progress: true
  steps:
    - uses: actions/checkout@v4
    - uses: actions/setup-python@v5
      with: { python-version: "3.11" }
    - name: Cache pip
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt', '**/pyproject.toml', '**/setup.cfg') }}
        restore-keys: ${{ runner.os }}-pip-
    - name: Report compat alias hits
      run: |
        python3 scripts/report_compat_hits.py --out docs/audits/compat_alias_hits.json || true
        echo "Compat hits report:"
        (cat docs/audits/compat_alias_hits.json 2>/dev/null) || echo '{"hits": 0}'
    - name: Enforce zero hits
      run: |
        python - <<'PY'
        import json, os, sys
        p="docs/audits/compat_alias_hits.json"
        limit=int(os.environ.get("LUKHAS_COMPAT_MAX_HITS","0"))
        data=json.load(open(p)) if os.path.exists(p) else {"hits":0}
        hits=int(data.get("hits",0))
        print(f"Compat alias hits: {hits} (limit {limit})")
        sys.exit(0 if hits<=limit else 2)
        PY
```

---

# D) Rate limiter: add env toggle + hash tokens (security + rollback knob)

**`lukhas/core/reliability/ratelimit.py` â€” patch**

```diff
@@
+import os, hashlib
@@
-    def _extract_principal(self, request) -> str:
+    def _extract_principal(self, request) -> str:
         auth = request.headers.get("authorization")
         if auth and auth.lower().startswith("bearer "):
             token = auth.split(" ", 1)[1].strip()
             if token:
-                return token
+                # Never store raw secrets in memory/metrics
+                digest = hashlib.sha256(token.encode()).hexdigest()[:16]
+                return f"tok:{digest}"
         # Fallback to IP (respect proxies)
         xff = request.headers.get("x-forwarded-for")
         if xff:
             ip = xff.split(",")[0].strip()
             if ip:
                 return f"ip:{ip}"
         client = getattr(request, "client", None)
         if client and getattr(client, "host", None):
-            return client.host
+            return f"ip:{client.host}"
         return "anonymous"
@@
-    def _key_for_request(self, request) -> str:
-        principal = self._extract_principal(request)
-        route = request.url.path
-        return f"{route}:{principal}"
+    def _key_for_request(self, request) -> str:
+        strategy = os.environ.get("LUKHAS_RL_KEYING", "route_principal").lower()
+        route = request.url.path
+        if strategy == "route_only":
+            return route
+        # default: route + principal
+        principal = self._extract_principal(request)
+        return f"{route}:{principal}"
```

*(No test breaks: you may slightly relax exact token suffix assertions to `startswith("tok:")`)*

---

# E) Global trace header middleware (attach `X-Trace-Id` everywhere)

**Option 1 (central):** add in `lukhas/observability/tracing.py` and have API import/apply it.

```python
# lukhas/observability/tracing.py (add)
from opentelemetry.trace import get_current_span
from starlette.middleware.base import BaseHTTPMiddleware

class TraceHeaderMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request, call_next):
        resp = await call_next(request)
        span = get_current_span()
        ctx = span.get_span_context() if span else None
        if ctx and ctx.trace_id:
            trace_id = format(ctx.trace_id, "032x")
            resp.headers.setdefault("X-Trace-Id", trace_id)
        return resp
```

**Wire it in the API factory**:

```diff
# lukhas/adapters/openai/api.py
@@
 from fastapi import FastAPI
+from lukhas.observability.tracing import TraceHeaderMiddleware
@@
 def get_app() -> FastAPI:
     app = FastAPI()
+    app.add_middleware(TraceHeaderMiddleware)
     ...
     return app
```

---

# F) Makefile quality-of-life

```makefile
openapi-spec:
\tpython3 scripts/generate_openapi.py

openapi-validate:
\tpython -m pip install --upgrade openapi-spec-validator >/dev/null || true
\tpython - <<'PY'\nimport json\nfrom openapi_spec_validator import openapi_v3_spec_validator\nspec=json.load(open("docs/openapi/lukhas-openai.json"))\nerrs=list(openapi_v3_spec_validator.iter_errors(spec))\nassert not errs, errs[:5]\nprint("OK")\nPY

openapi-diff: openapi-spec
\tpython3 scripts/diff_openapi.py --base main_ref/docs/openapi/lukhas-openai.json --cand docs/openapi/lukhas-openai.json || true

compat-enforce:
\tLUKHAS_COMPAT_MAX_HITS=0 python3 scripts/report_compat_hits.py --out docs/audits/compat_alias_hits.json || true
\tpython - <<'PY'\nimport json,sys\nhits=int(json.load(open("docs/audits/compat_alias_hits.json")).get("hits",0))\nprint("hits=",hits)\nsys.exit(0 if hits<=0 else 2)\nPY
```

*(The `openapi-diff` target expects you to have generated `main_ref/...` via the workflow; locally you can `git worktree add main_ref origin/main` then run `python3 main_ref/scripts/generate_openapi.py` there.)*

---

# G) Migration note â€” `docs/migration/MIGRATION_v0.9.0.md`

```md
# Migration Guide v0.9.0 â€” Compat Removal & Lane Rename

## Summary
- `candidate.*` â†’ `labs.*` (Phase 2 COMPLETE)
- `lukhas.compat.*` **removed** (Phase 3)
- OpenAPI spec now includes `servers` and `x-service-version`.

## What changed for you
- Update imports to canonical namespaces:
  - `from candidate.foo import Bar` â†’ `from labs.foo import Bar`
  - `import lucas.*` â†’ `import lukhas.*`
- Remove any `lukhas.compat.*` usage.

## How to validate
- Run `make check-legacy-imports` â†’ exit 0
- Run smoke: `pytest tests/smoke/ -q`
- Ensure your client SDK regenerates against `docs/openapi/lukhas-openai.json`.

## Timeline
- Compat removed in v0.9.0
- No further alias support guaranteed in â‰¥ v0.10.0
```

---

# H) PR template polish â€” `.github/PULL_REQUEST_TEMPLATE.md` (append)

```md
### Phase 3 Gate (tick all)
- [ ] `compat-enforce` job green (`hits == 0`)
- [ ] No `lukhas.compat` imports in repo (outside historical docs)
- [ ] OpenAPI artifact present & validated
- [ ] `X-Trace-Id` header observed in smoke logs
- [ ] (If needed) `LUKHAS_RL_KEYING` toggle documented for rollback
```

---

## Done âœ…

This pack gives Codex everything to:

* enforce **zero compat** in CI,
* safely **remove** the compat layer,
* **validate** OpenAPI and diff against main for contract safety,
* ship **trace correlation** everywhere,
* keep a clean **migration paper trail**,
* and add a crisp **PR gate** so reviewers can merge with confidence.

Want me to also drop a tiny `git worktree` helper to generate the **main_ref** spec locally for the diff?