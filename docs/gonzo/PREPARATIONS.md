

# ğŸš¦ Immediate Focus (2â€“4h, high-impact only)

## 0) Cut a clean audit baseline (10 min)

Freeze a reproducible snapshot for the auditor.

```bash
# from a clean main
git pull --ff-only
AUD=$(date -u +%Y-%m-%dT%H%M%SZ)
git tag -a audit-$AUD -m "Audit baseline $AUD"
git push origin audit-$AUD

# health + spec snapshots (already working in your repo)
make openapi-spec
python3 scripts/system_health_audit.py  # writes docs/audits/health/latest.{json,md}
```

## 1) Lock â€œAudit Modeâ€ defaults (15 min)

Ensure the auditor sees least-privilege + observability.

```env
# .env.audit (new file)
LUKHAS_POLICY_MODE=strict
LUKHAS_RL_KEYING=route_principal
LUKHAS_RATE_RPS=10
LUKHAS_RATE_BURST=20
LUKHAS_IDEMP_TTL=300
LUKHAS_LOG_REDACT=1
LUKHAS_TRACE_HEADERS=1
```

* Use this env for the audit server (staging or local).
* We already emit **X-Trace-Id** and RL headers everywhere; this keeps the behavior consistent under load.

## 2) Close the last â€œmust-haveâ€ gaps (â‰¤90 min)

* **OpenAPI parity checks** (confirm what CI already enforces):

  * `/v1/models` returns `{ object:"list", data:[â€¦] }` âœ…
  * Request headers accepted: `OpenAI-Organization`, `OpenAI-Project` âœ…
  * Response headers documented: `X-RateLimit-*`, `X-Request-Id` âœ…
  * *Action*: run `make openapi-validate` and the **headers guard** (already wired).

* **Auth & scopes sanity**:

  * Default dev token scopes cover public API routes âœ…
  * Strict mode should 403 when scopes are missing (expected).
  * *Action*: re-run smoke with `permissive_env()` off on staging to validate strict gating.

* **Idempotency correctness**:

  * Replay emits `X-Idempotent-Replay: true` on cache hit (tests included).
  * *Action*: run the Redis E2E you dropped in (or use local memory path if Redis off).

* **Logging redaction**:

  * Confirm redactor patterns load in app start; sample a log line with an `sk-***` token â†’ should be `[REDACTED]`.
  * *Action*: tail logs during a smoke run and visually confirm.

* **Lane guard quick pass (no packaging)**:

  * Run the import-linter contracts we set without installing the package:

    ```bash
    make lane-guard
    ```
  * This stays advisory for the audit, just produce the report.

## 3) Green-light monitoring for the auditor (30â€“45 min)

* If Prometheus/Grafana are **not** required for the audit, skip deploy.
* If you want to include signals:

  ```bash
  ./scripts/deploy_monitoring_post_390.sh   # your deploy wrapper
  ./scripts/rc_soak_sentinel.sh || true    # non-blocking; prints SLOs
  ```

  Then attach dashboard PNGs or a quick GIF to the audit packet.

---

# ğŸ“¦ Produce the â€œAudit Packetâ€ (one command)

Drop these two files in to automate the bundle. (They only **collect**; no runtime edits.)

**scripts/make_audit_packet.sh**

```bash
#!/usr/bin/env bash
set -euo pipefail
STAMP=${STAMP:-$(date -u +%Y-%m-%dT%H%M%SZ)}
OUT=docs/audits/auditpack/$STAMP
mkdir -p "$OUT"

# 1) Health & RC soak artifacts (already generated by your runs)
cp -r docs/audits/health/latest.* "$OUT/" 2>/dev/null || true
test -d docs/audits/health/$STAMP && cp -r docs/audits/health/$STAMP/* "$OUT/" || true

# 2) OpenAPI
python3 scripts/generate_openapi.py
cp docs/openapi/lukhas-openapi.json "$OUT/"

# 3) CI & config snapshots
git rev-parse --short HEAD > "$OUT/GIT_SHA.txt"
cp .github/workflows/matriz-validate.yml "$OUT/" || true
cp .env.example "$OUT/" || true
test -f .env.audit && cp .env.audit "$OUT/" || true

# 4) Security & deps
python3 -m pip freeze > "$OUT/pip_freeze.txt" || true
( pipx run pip-audit || true ) > "$OUT/pip_audit.txt" || true

# 5) Lint & lane guard (advisory)
python3 -m ruff check lukhas core MATRIZ --statistics --no-cache > "$OUT/ruff_statistics.txt" || true
PYTHONPATH=$(pwd) lint-imports --contract .importlinter:prod_no_candidate || true
PYTHONPATH=$(pwd) lint-imports --contract .importlinter:integration_no_candidate || true

# 6) Golden flows & Postman (already in repo)
cp -r docs/postman "$OUT/postman" 2>/dev/null || true

# 7) Summary
cat > "$OUT/AUDIT_README.md" <<MD
# Lukhas Audit Packet â€” $STAMP

- Git SHA: \$(cat $OUT/GIT_SHA.txt)
- OpenAPI: lukhas-openapi.json
- Health: latest.{json,md}
- Lint: ruff_statistics.txt
- Security: pip_audit.txt
- CI: matriz-validate.yml
- Env: .env.example / .env.audit
- Postman: ./postman/

Runbook:
1) Validate OpenAPI: openapi-spec-validator lukhas-openapi.json
2) Exercise flows: newman run ./postman/LUKHAS_DX_Polish.postman_collection.json -e ./postman/LUKHAS.postman_environment.json
3) Check headers: X-Trace-Id, X-RateLimit-*, X-Request-Id present on 2xx/4xx/5xx
4) Review Guardian PDP signals in /healthz (policy_etag, decisions)
MD

echo "Audit packet at $OUT"
```

**Makefile**

```make
audit-pack:
	bash scripts/make_audit_packet.sh
```

Run it:

```bash
make audit-pack
# attach the new docs/audits/auditpack/<stamp>/ folder to the GPT Pro brief
```

---

# ğŸ§­ What to *pause* (until after the audit)

* Massive E402 refactors across non-critical packages (we already landed the hot paths).
* Colony/â€œAgent Networkâ€ renames beyond the approved docs RFC.
* Any invasive runtime changes in adapters/reliability unless they fix a P0 bug.

---

# âœ… Minimal â€œmust-mergeâ€ before audit

* **PR #396** (I001 dreams â€“ zero risk).
* **PR #406** (OpenAI terminology parity) â€” if not merged already; itâ€™s backward-compatible and the auditor expects these headers and list-shape.
* Any doc-only PRs (state sweep summaries, RC soak doc, RFCs) are safe to merge for context.

---

# ğŸ§ª Auditor quickstart (what they will actually run)

```bash
# start API (use your usual entrypoint)
uvicorn lukhas.adapters.openai.api:get_app --factory --port 8000 --reload

# set audit env
export $(grep -v '^#' .env.audit | xargs -I{} echo {})

# verify health & headers
curl -i http://localhost:8000/healthz
curl -i -H "Authorization: Bearer test" http://localhost:8000/v1/models

# run Postman golden flows
newman run docs/postman/LUKHAS_DX_Polish.postman_collection.json \
  -e docs/postman/LUKHAS.postman_environment.json

# validate OpenAPI
python3 -m pip install openapi-spec-validator
python3 - <<'PY'
import json; from openapi_spec_validator import validate
spec=json.load(open("docs/openapi/lukhas-openapi.json"))
validate(spec); print("OpenAPI valid")
PY
```

---

# ğŸ—ºï¸ After the audit (fast wins youâ€™ve queued)

* Merge the **error-budget rules** + **OpenAPI breakage guard** (already drafted).
* Finish **Dreams GA** mini-sprint (golden tests + MATRIZ node + SDK snippets).
* Execute **Colonyâ†’Agent Network** only after stakeholder approval.
* Continue E402 in â‰¤20-file slices (only in hot paths the auditor touches).

---

## TL;DR

1. Tag **audit baseline**, drop in **.env.audit**, run **make audit-pack**.
2. Merge only **safe, audit-helpful PRs** (#396, #406).
3. Pause broad refactors until after GPT Pro delivers findings