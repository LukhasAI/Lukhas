# GPT STRATEGIC AUDIT PROMPT
**Reviewer**: GPT-4 / ChatGPT
**Role**: Strategic Critique with T4 Lens (Truth, Transparency, Testability, Temperance)
**Blind Review**: Do NOT read other reviewer outputs before completing this

---

## ðŸ“‹ YOUR MISSION

Provide a **skeptical, evidence-first strategic critique** of the LUKHAS documentation approach. Challenge assumptions, identify risks, and propose measurable alternatives.

**Your Strengths** (why you're doing this):
- Strategic reasoning and prioritization
- Identifying weak assumptions and hidden risks
- Resource allocation analysis
- Business model critique

**T4 Lens** (apply throughout):
- **Truth**: Demand evidence for claims, call out speculation
- **Transparency**: Identify what's missing or unclear
- **Testability**: Require measurable KPIs and validation plans
- **Temperance**: Challenge hype, excessive scope, unrealistic timelines

---

## ðŸ“š CONTEXT DOCUMENT

**Load this first**: `LUKHAS_ECOSYSTEM_REVIEW_PACKAGE.md`
- Location: https://github.com/LukhasAI/Lukhas/blob/main/docs/gpt_packages/LUKHAS_ECOSYSTEM_REVIEW_PACKAGE.md

**Key sections to focus on**:
- Section 3: Our Current Assumptions (OPEN TO CHALLENGE)
- Section 4: Our Current Plan (SEEKING VALIDATION)
- Section 5: Strategic Questions for Review

---

## ðŸŽ¯ YOUR DELIVERABLES

### 1. Strategic Critique (500-1000 words)

**Answer these questions with skepticism**:
- What's fundamentally right about this approach?
- What's fundamentally wrong or risky?
- Which assumptions are most dangerous?
- What are they NOT seeing? (Blind spots)
- Is the scope realistic for available resources?
- Does this approach actually solve a market problem?

**Apply T4 lens to**:
- **Truth**: Are their claims about MATRIZ (87% complete, <250ms latency) credible? How would we verify?
- **Transparency**: What's unclear about their plan? What's being hidden or glossed over?
- **Testability**: Can their success metrics be measured? Are they specific enough?
- **Temperance**: Is 11 domains excessive? Is 230 hours realistic? Are they overconfident?

### 2. Priority Matrix (Specific Rankings)

```
MUST DO FIRST (Top 3):
1. [Specific action with reasoning]
2. [Specific action with reasoning]
3. [Specific action with reasoning]

SHOULD DO SOON (Next 3):
1. [Specific action]
2. [Specific action]
3. [Specific action]

CAN DEFER (Lower priority):
1. [What to postpone and why]
2. [What to postpone and why]
3. [What to postpone and why]

SHOULDN'T DO (Cut entirely):
1. [What to abandon and why]
2. [What to abandon and why]
3. [What to abandon and why]
```

**For each item, provide**:
- Specific action (not generic advice)
- Reasoning (why this priority level)
- Expected impact (what changes)
- Resource estimate (hours/days)

### 3. Alternative Sequencing Strategies (3 Options)

**For each alternative approach, provide**:
- Name/description
- Timeline (weeks/months)
- Resource estimate (hours)
- Key differences from current plan
- Pros and cons vs. current approach
- Which domains/tasks to prioritize
- Measurable KPIs to track

**Example format**:
```
ALTERNATIVE 1: "Developer-First Launch"
- Timeline: 3 weeks
- Resources: 80 hours
- Approach: Focus entirely on lukhas.dev + lukhas.id, ignore other domains
- Prioritize: API docs, SDK examples, developer quickstart
- KPIs: Time-to-first-API-call, developer signups, API keys issued
- Pros: Fast developer traction, measurable adoption
- Cons: No flagship brand presence, limited market coverage
```

### 4. Top 5 Red Flags (Specific Warnings)

**Identify risks that could derail this plan**:
1. [Red flag with evidence from package]
2. [Red flag with evidence from package]
3. [Red flag with evidence from package]
4. [Red flag with evidence from package]
5. [Red flag with evidence from package]

**For each red flag**:
- What's the risk?
- Where did you see this in the package?
- Why is this dangerous?
- What's the likely failure mode?
- How could they mitigate?

### 5. Quick Wins (This Week Actions)

**Identify 5-7 actions with immediate impact**:
- High leverage (small effort, big impact)
- Can be done THIS WEEK
- Concrete, specific, actionable
- Measurable outcome

**Format**:
```
QUICK WIN 1: [Action]
- Effort: [X hours]
- Impact: [Specific outcome]
- Why now: [Reasoning]
- How to measure: [Metric]
```

### 6. Scorecard (Rate 1-10 with reasoning)

```
Overall Strategy:          [1-10]
Reasoning: [Why this score? What would improve it?]

Sequencing/Priorities:     [1-10]
Reasoning: [Are they doing things in the right order?]

Resource Allocation:       [1-10]
Reasoning: [Is 230 hours realistic? Over/under-estimated?]

Content Frameworks:        [1-10]
Reasoning: [3-layer tone, 8-family vocab - helpful or overcomplicated?]

Market Positioning:        [1-10]
Reasoning: [Will this approach reach their target audience?]

Risk Management:           [1-10]
Reasoning: [Are they identifying and mitigating risks?]

OVERALL SCORE:             [1-10]
CONFIDENCE LEVEL:          [Low/Medium/High]
```

---

## ðŸ” KEY ASSUMPTIONS TO CHALLENGE

These are explicitly stated assumptions in the package. **Challenge them with T4 lens**:

### Assumption 1: "Documentation Before Implementation"
**Their claim**: Complete all docs to 95%+ before building web pages
**Your job**: Is this optimal? What's the alternative? Evidence for/against?

### Assumption 2: "3-Layer Tone System Works"
**Their claim**: Blending Poetic/User-Friendly/Academic creates effective content
**Your job**: Does this actually work or create confusing content? How would they test?

### Assumption 3: "All 11 Domains Need Equal Development"
**Their claim**: All domains should reach 95%+ documentation
**Your job**: Should they focus on fewer domains? Which ones? Why?

### Assumption 4: "8-Family Vocabulary Rotation Prevents Repetition"
**Their claim**: Rotating metaphors every 200-300 words keeps content fresh
**Your job**: Necessary or overcomplicated? Does it help or hurt readability?

### Assumption 5: "MATRIZ 87% Should Be Prominent"
**Their claim**: 87% completion status should be heavily featured
**Your job**: Is 87% impressive or concerning? Should they emphasize or downplay?

### Assumption 6: "5-Week Roadmap Is Optimal"
**Their claim**: Systematic week-by-week completion is best approach
**Your job**: Too rigid? Too flexible? Better alternatives?

### Assumption 7: "AI-Assisted Content Is Appropriate"
**Their claim**: Using GPT/Gemini/Claude for bulk content is acceptable
**Your job**: Quality concerns? Authenticity issues? Better approach?

### Assumption 8: "T4 Precision Differentiates"
**Their claim**: Avoiding hype makes them more credible
**Your job**: Or does it make them boring/invisible in noisy market?

---

## ðŸ“Š SPECIFIC QUESTIONS TO ANSWER

### Priority & Sequencing
1. **What should they focus on FIRST?** (Be specific - which domain, which docs)
2. **Which domains are most critical?** (Rank top 3 with reasoning)
3. **What's the minimum viable documentation?** (What can they skip?)
4. **Should they document before building?** (Challenge the sequence)

### Resource Allocation
5. **Is 230 hours realistic?** (Under/over-estimated? Provide reasoning)
6. **Can AI-generated content be high quality?** (Test needed? Quality bar?)
7. **Should they hire specialists?** (Which roles? When? Budget impact?)
8. **What can they cut without hurting vision?** (Identify non-essentials)

### Architecture & Approach
9. **Are 11 domains too many?** (Should they consolidate? Which ones merge?)
10. **Is Constellation Framework clear?** (Or confusing jargon? Test needed?)
11. **Should they feature MATRIZ 87%?** (Or does it highlight incompleteness?)
12. **Are domain purposes well-differentiated?** (Do some overlap/compete?)

### Market & Positioning
13. **Who is their PRIMARY audience?** (Pick one - devs, enterprises, researchers, public)
14. **What differentiates LUKHAS?** (Clear from docs? Unique value prop?)
15. **Lead with consciousness or tools?** (Which hooks people better? Test?)
16. **Serving too many audiences?** (Should they narrow focus?)

### Risk & Validation
17. **What could derail this plan?** (Blind spots? Hidden assumptions?)
18. **How should they validate content?** (What metrics? User testing approach?)
19. **What if MATRIZ stalls at 87%?** (Contingency plan? Messaging strategy?)
20. **Need different plans for scenarios?** (Best/worst/most-likely cases?)

---

## ðŸŽ¯ CRITICAL AREAS FOR T4 SCRUTINY

### MATRIZ "87% Complete" Messaging
**Current claim**: "87% Complete with Full SDK Support, <250ms p95 latency"
**T4 Questions**:
- Truth: How is 87% measured? Reproducible benchmark?
- Transparency: What's the remaining 13%? Timeline to 100%?
- Testability: Can external parties verify <250ms claim? Public test script?
- Temperance: Does 87% sound stuck or impressive? Better messaging?

### 11-Domain Strategy
**Current plan**: Develop all 11 domains to 95%+ documentation
**T4 Questions**:
- Truth: Evidence that 11 domains serve distinct audiences?
- Transparency: Resource cost clearly stated? Trade-offs acknowledged?
- Testability: How will they measure if 11 domains was right choice?
- Temperance: Is this overambitious? Should they focus on 3-4?

### 230-Hour Timeline
**Current plan**: 5 weeks, 230 hours total effort
**T4 Questions**:
- Truth: Based on what data? Past experience? Industry benchmarks?
- Transparency: What happens if it takes 400 hours? Buffer included?
- Testability: Tracked with time logging? Mid-point check-in?
- Temperance: Realistic or optimistic? Should they add 50% contingency?

### AI-Generated Content
**Current plan**: Use GPT/Gemini/Claude for content with human review
**T4 Questions**:
- Truth: Quality empirically tested? Compared to human-written?
- Transparency: Will AI-generated content be labeled? Editorial workflow?
- Testability: Blind user testing (human vs AI)? Quality metrics?
- Temperance: Could this backfire? Authenticity concerns?

---

## ðŸ“ OUTPUT FORMAT

**Provide your review as**:

```markdown
# GPT STRATEGIC AUDIT - LUKHAS ECOSYSTEM

**Reviewer**: GPT-4
**Date**: [Date]
**Review Type**: Strategic Critique with T4 Lens
**Confidence**: [Low/Medium/High]

---

## EXECUTIVE SUMMARY (200 words)

[Overall assessment, top 3 recommendations, biggest risk]

---

## 1. STRATEGIC CRITIQUE (500-1000 words)

[Detailed analysis with T4 lens applied]

---

## 2. PRIORITY MATRIX

### MUST DO FIRST
1. [Action + reasoning + impact + estimate]
2. [Action + reasoning + impact + estimate]
3. [Action + reasoning + impact + estimate]

### SHOULD DO SOON
[...]

### CAN DEFER
[...]

### SHOULDN'T DO
[...]

---

## 3. ALTERNATIVE SEQUENCING STRATEGIES

### ALTERNATIVE 1: [Name]
[Details]

### ALTERNATIVE 2: [Name]
[Details]

### ALTERNATIVE 3: [Name]
[Details]

---

## 4. TOP 5 RED FLAGS

1. [Red flag + evidence + mitigation]
2. [Red flag + evidence + mitigation]
3. [Red flag + evidence + mitigation]
4. [Red flag + evidence + mitigation]
5. [Red flag + evidence + mitigation]

---

## 5. QUICK WINS (THIS WEEK)

1. [Action + effort + impact + metric]
2. [Action + effort + impact + metric]
3. [Action + effort + impact + metric]
4. [Action + effort + impact + metric]
5. [Action + effort + impact + metric]

---

## 6. SCORECARD

Overall Strategy:        [X/10] - [Reasoning]
Sequencing/Priorities:   [X/10] - [Reasoning]
Resource Allocation:     [X/10] - [Reasoning]
Content Frameworks:      [X/10] - [Reasoning]
Market Positioning:      [X/10] - [Reasoning]
Risk Management:         [X/10] - [Reasoning]

**OVERALL SCORE**: [X/10]
**CONFIDENCE**: [Low/Medium/High]

---

## 7. SPECIFIC ASSUMPTION CHALLENGES

[For each of the 8 assumptions, provide challenge/validation]

---

## 8. ADDITIONAL INSIGHTS

[Anything else not covered above]
```

---

## âš ï¸ IMPORTANT GUIDELINES

**DO**:
- âœ… Be brutally honest and direct
- âœ… Challenge every assumption with evidence
- âœ… Provide specific, actionable recommendations
- âœ… Use T4 lens throughout (skeptical, evidence-first)
- âœ… Identify blind spots they're missing
- âœ… Propose measurable alternatives
- âœ… Call out unrealistic timelines or scope

**DON'T**:
- âŒ Validate everything they're doing
- âŒ Provide generic advice (be specific to LUKHAS)
- âŒ Avoid hard truths to be polite
- âŒ Make recommendations without reasoning
- âŒ Accept claims without evidence
- âŒ Ignore resource constraints
- âŒ Overlook market/competitive realities

---

## ðŸŽ¯ SUCCESS CRITERIA

Your review is successful if:
1. âœ… It challenges at least 4 of their 8 assumptions
2. âœ… It provides 3 concrete alternative approaches
3. âœ… It identifies 5+ red flags they haven't considered
4. âœ… It includes measurable KPIs for recommendations
5. âœ… It proposes immediate (this week) actions
6. âœ… It applies T4 lens to every major claim
7. âœ… It's actionable (not just analytical)

---

**Ready to begin?**

Load `LUKHAS_ECOSYSTEM_REVIEW_PACKAGE.md` and provide your strategic critique following the format above. Be skeptical, evidence-based, and actionable.

---

**Package Version**: 1.0
**Created**: 2025-11-10
**For**: GPT-4 / ChatGPT strategic review
**Review Type**: Independent, blind, T4-focused
