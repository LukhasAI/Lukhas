---
status: wip
type: documentation
owner: unknown
module: visionary
redirect: false
moved_to: null
---

Love that — let’s take a breath, lock the guardrails, then ship the two building blocks you asked for.

Moment of alignment (quick decisions)

Before wiring anything else, here are crisp defaults I’ll bake into the code below (you can tweak via env):
	1.	Simulation lane is offensive-capability neutral: creative/planning only; no bulk destructive intents.
	2.	Step-up auth (GTΨ) is required if the seed hints at high-risk actions (keywords/flags).
	3.	Duress/shadow signals immediately halt scheduling.
	4.	Default data retention for simulation jobs: 24h TTL (configurable).
	5.	Dream shards are persisted only via the Dream Inbox writer behind a capability scope.
	6.	No adapter/vendor calls from the simulation lane (enforced by import-linter).

⸻

Files to drop in

1) consciousness/simulation/policy.py

# consciousness/simulation/policy.py
from __future__ import annotations
import re, time
from typing import Any, Dict, List, Tuple

# --- Exceptions ------------------------------------------------------

class PolicyViolation(RuntimeError): ...
class StepUpRequired(RuntimeError): ...
class CapabilityError(RuntimeError): ...

# --- Tunables / Defaults --------------------------------------------

DEFAULTS = {
    # tags that must never appear in simulation requests
    "deny_ul_tags": {"ΛROOT", "ΛADMIN"},
    # crude heuristic patterns for destructive bulk intents
    "forbidden_patterns": [
        r"\b(drop|delete|wipe|erase)\b.*\b(all|everything|entire|full)\b",
        r"\b(exfiltrate|dump)\b.*\b(dataset|pii|secrets?)\b",
    ],
    # hints that should trigger step-up (GTΨ)
    "step_up_keywords": [
        r"\bproduction\b", r"\broot\b", r"\brotate keys\b", r"\bdelete account\b",
        r"\bmass\b.*\bemail\b", r"\bbulk\b.*\baction\b",
    ],
    # seed size guard
    "max_goal_chars": 600,
    # flag fields that indicate duress/shadow
    "duress_flag_keys": ["duress", "shadow"],
    # default TTL for jobs (ms)
    "default_job_ttl_ms": 24 * 60 * 60 * 1000,
}

# --- Helpers ---------------------------------------------------------

def _match_any(text: str, patterns: List[str]) -> bool:
    for p in patterns:
        if re.search(p, text, flags=re.I):
            return True
    return False

def _flags(seed: Dict[str, Any]) -> Dict[str, Any]:
    return ((seed.get("constraints") or {}).get("flags") or {})

# --- Public API ------------------------------------------------------

def sanitize_seed(seed: Dict[str, Any]) -> Dict[str, Any]:
    """Return a minimally sanitized copy (trim oversize fields)."""
    cleaned = dict(seed or {})
    goal = (cleaned.get("goal") or "")
    if len(goal) > DEFAULTS["max_goal_chars"]:
        cleaned["goal"] = goal[: DEFAULTS["max_goal_chars"]] + "…"
    return cleaned

def enforce_seed(seed: Dict[str, Any]) -> None:
    """
    Raise PolicyViolation or StepUpRequired if seed violates policy
    or requires step-up auth (GTΨ). No return on success.
    """
    if not isinstance(seed, dict):
        raise PolicyViolation("Seed must be a JSON object.")

    # Duress / shadow kill-switch
    flags = _flags(seed)
    if any(bool(flags.get(k)) for k in DEFAULTS["duress_flag_keys"]):
        raise PolicyViolation("Simulation denied due to duress/shadow signal.")

    # UL tag denylist
    tags = set((seed.get("ul_tags") or [])[:50])
    if tags & DEFAULTS["deny_ul_tags"]:
        raise PolicyViolation("Seed contains privileged UL tags not permitted in simulation.")

    # Destructive bulk heuristics
    goal = ((seed.get("goal") or "") + " ").strip()
    if _match_any(goal, DEFAULTS["forbidden_patterns"]):
        raise PolicyViolation("Destructive or bulk intent not allowed in simulation lane.")

    # Step-up hints (require GTΨ)
    if _match_any(goal, DEFAULTS["step_up_keywords"]) or bool(flags.get("require_step_up")):
        raise StepUpRequired("GTΨ step-up authentication required for this request.")

def job_ttl_ms() -> int:
    return int(DEFAULTS["default_job_ttl_ms"])


⸻

2) consciousness/simulation/job_store.py

# consciousness/simulation/job_store.py
from __future__ import annotations
import json, os, time, uuid
from typing import Any, Dict, Optional

try:
    import redis  # type: ignore
except Exception:
    redis = None  # optional dependency

class JobStore:
    """Unified interface; picks backend from env (memory|redis)."""

    def __init__(self, backend: "BaseBackend"):
        self._b = backend

    # ---- Factory ----------------------------------------------------
    @classmethod
    def from_env(cls) -> "JobStore":
        mode = (os.getenv("SIM_JOB_STORE", "memory")).lower()
        if mode == "redis" and redis is not None and os.getenv("REDIS_URL"):
            return cls(RedisBackend(os.getenv("REDIS_URL")!))
        return cls(MemoryBackend())

    # ---- API --------------------------------------------------------
    def create_job(self, seed: Dict[str, Any], trace_id: str, ttl_ms: int) -> str:
        job_id = f"JOB-{uuid.uuid4().hex[:12]}"
        payload = {
            "trace_id": trace_id,
            "seed": seed,
            "status": "scheduled",
            "created_ts": int(time.time() * 1000),
            "artifacts": None,
        }
        self._b.put(job_id, payload, ttl_ms)
        return job_id

    def get(self, job_id: str) -> Optional[Dict[str, Any]]:
        return self._b.get(job_id)

    def set_artifacts(self, job_id: str, shards: Any) -> None:
        job = self._b.get(job_id)
        if not job:
            return
        job["artifacts"] = shards
        job["status"]  = "complete"
        self._b.put(job_id, job)

    def cancel(self, job_id: str) -> Optional[Dict[str, Any]]:
        job = self._b.get(job_id)
        if not job:
            return None
        if job.get("status") == "complete":
            return job
        job["status"] = "cancelled"
        self._b.put(job_id, job)
        return job

    def queue_depth(self) -> int:
        return self._b.depth()

# ---------------- Backends ----------------

class BaseBackend:
    def put(self, key: str, value: Dict[str, Any], ttl_ms: int | None = None) -> None: ...
    def get(self, key: str) -> Optional[Dict[str, Any]]: ...
    def depth(self) -> int: ...

class MemoryBackend(BaseBackend):
    _store: Dict[str, Dict[str, Any]] = {}
    def put(self, key: str, value: Dict[str, Any], ttl_ms: int | None = None) -> None:
        # naive TTL ignored in memory mode; acceptable for dev
        self._store[key] = json.loads(json.dumps(value))  # detaching copy
    def get(self, key: str) -> Optional[Dict[str, Any]]:
        v = self._store.get(key)
        return json.loads(json.dumps(v)) if v is not None else None
    def depth(self) -> int:
        return len(self._store)

class RedisBackend(BaseBackend):
    def __init__(self, url: str):
        self.r = redis.Redis.from_url(url, decode_responses=True)
        self.prefix = "lukhas:sim:jobs:"
        self.index  = self.prefix + "index"

    def _k(self, key: str) -> str:
        return self.prefix + key

    def put(self, key: str, value: Dict[str, Any], ttl_ms: int | None = None) -> None:
        s = json.dumps(value, separators=(",", ":"))
        pipe = self.r.pipeline()
        pipe.set(self._k(key), s)
        pipe.sadd(self.index, key)
        if ttl_ms:
            pipe.pexpire(self._k(key), int(ttl_ms))
        pipe.execute()

    def get(self, key: str) -> Optional[Dict[str, Any]]:
        s = self.r.get(self._k(key))
        return json.loads(s) if s else None

    def depth(self) -> int:
        try:
            return int(self.r.scard(self.index))
        except Exception:
            return 0

Env knobs
	•	SIM_JOB_STORE=redis|memory (default memory)
	•	REDIS_URL=redis://localhost:6379/0

⸻

3) Updated canonical consciousness/simulation/api.py (drop-in replacement)

# consciousness/simulation/api.py
from __future__ import annotations
import os, time, uuid
from typing import Any, Dict, List, Optional, TypedDict

from memory.inbox.dreams.writer import persist_dream_shards
from .policy import enforce_seed, PolicyViolation, StepUpRequired, job_ttl_ms
from .job_store import JobStore

# ------------------------ Capability ------------------------

class CapabilityError(RuntimeError): ...
class NotFound(RuntimeError): ...

class CapabilityToken(TypedDict, total=False):
    token_id: str
    scopes: List[str]
    exp_ts: float
    issued_ts: float

SIM_SCHEDULE_SCOPE = "consciousness.simulation.schedule"
SIM_COLLECT_SCOPE  = "consciousness.simulation.collect"
INBOX_WRITE_SCOPE  = "memory.inbox.dreams.write"

def _require_scope(token: Optional[Dict[str, Any]], *required: str) -> None:
    if not token:
        raise CapabilityError("Missing capability token.")
    scopes = set(token.get("scopes") or [])
    missing = [s for s in required if s not in scopes]
    if missing:
        raise CapabilityError(f"Missing required scope(s): {', '.join(missing)}")
    if float(token.get("exp_ts", 0)) <= time.time():
        raise CapabilityError("Capability token expired.")

# ------------------------ Config / Store ------------------------

def _lt_id() -> str:
    return f"LT-{int(time.time()*1000)}-{uuid.uuid4().hex[:8]}"

def _simulation_enabled() -> bool:
    return os.getenv("SIMULATION_ENABLED", "true").lower() in ("1","true","yes","on")

_STORE = JobStore.from_env()

# ------------------------ Public API ------------------------

def health() -> Dict[str, Any]:
    return {
        "component": "consciousness.simulation",
        "enabled": _simulation_enabled(),
        "queue_depth": _STORE.queue_depth(),
        "time": int(time.time())
    }

def schedule(seed: Dict[str, Any], *, cap_token: Dict[str, Any]) -> Dict[str, Any]:
    _require_scope(cap_token, SIM_SCHEDULE_SCOPE)
    if not _simulation_enabled():
        raise PolicyViolation("Simulation lane disabled by operator policy.")
    # Policy & step-up checks
    enforce_seed(seed)

    trace_id = _lt_id()
    job_id   = _STORE.create_job(seed, trace_id, ttl_ms=job_ttl_ms())
    return {"trace_id": trace_id, "job_id": job_id, "accepted": True}

def collect(job_id: str, *, cap_token: Dict[str, Any]) -> Dict[str, Any]:
    _require_scope(cap_token, SIM_COLLECT_SCOPE, INBOX_WRITE_SCOPE)
    job = _STORE.get(job_id)
    if not job:
        raise NotFound(f"No such job_id: {job_id}")

    if job.get("artifacts") is None:
        seed = job["seed"]
        now  = int(time.time()*1000)
        shards: List[Dict[str, Any]] = [
            {
                "trace_id": job["trace_id"],
                "index": 0,
                "timestamp": now,
                "proposal": {
                    "summary": f"Simulated plan for goal: {seed.get('goal','(no goal)')}",
                    "ul_tags": (seed.get("ul_tags") or ["ΛSIM"])
                },
                "risks": [],
                "scores": {"coherence": 0.92, "safety": 0.99},
                "seed_meta": {"goal": seed.get("goal",""), "flags": (seed.get('constraints') or {}).get('flags', {})},
            }
        ]
        result_payload = {"trace_id": job["trace_id"], "shards": shards}
        persist_dream_shards(seed=seed, result=result_payload, cap_token=cap_token)
        _STORE.set_artifacts(job_id, shards)

    # fresh read (optional)
    job = _STORE.get(job_id) or job
    return {
        "trace_id": job["trace_id"],
        "job_id": job_id,
        "status": job["status"],
        "shards": job["artifacts"],
    }

def cancel(job_id: str, *, cap_token: Dict[str, Any]) -> Dict[str, Any]:
    _require_scope(cap_token, SIM_SCHEDULE_SCOPE)
    job = _STORE.cancel(job_id)
    if not job:
        raise NotFound(f"No such job_id: {job_id}")
    return {"trace_id": job["trace_id"], "job_id": job_id, "status": job["status"]}

Your existing test from earlier still passes unchanged.
If you want a policy test, add a seed with {"constraints":{"flags":{"duress":True}}} and assert PolicyViolation.

⸻

(Optional) sample .env for local dev

SIMULATION_ENABLED=true
SIM_JOB_STORE=memory
# For redis mode:
# SIM_JOB_STORE=redis
# REDIS_URL=redis://localhost:6379/0


⸻

What we just achieved
	•	Pulled policy logic out of the hot path into a clean policy module with step-up (GTΨ) triggers.
	•	Swapped the ad-hoc in-memory dict for a pluggable job store (memory by default, Redis when ready).
	•	Kept the Dream Inbox as the sole persistence sink for artifacts (capability-gated).
	•	Left import-linter guard in place (no adapter/vendor leakage into simulation).

---

## MATADA Alignment Update (v1)

Hard policy lines (simulation):
	•	FORBID_NODE_TYPES = {"DECISION","AWARENESS"}
	•	StepUpRequired for seeds implying privileged actions; deny node creation until GTΨ satisfied.
	•	Duress/shadow flags → immediate deny; emit PolicyViolation with Λ-trace correlation.
