---
status: wip
type: documentation
owner: unknown
module: visionary
redirect: false
moved_to: null
---

Absolutelyâ€”letâ€™s add the admin-only inbox reader and clarify the deprecation plan so you keep momentum without breaking callers.

â¸»

âœ… What weâ€™re adding now

1) Admin-only reader for Dream Inbox

Path: memory/inbox/dreams/reader_admin.py

from __future__ import annotations
import os, json, re, time, glob
from typing import Dict, Any, List, Optional, Iterable, TypedDict

# ---- Capabilities -----------------------------------------------------------

class CapabilityError(RuntimeError): ...
class NotFound(RuntimeError): ...

class CapabilityToken(TypedDict, total=False):
    token_id: str
    scopes: List[str]
    exp_ts: float
    issued_ts: float

READ_SCOPE  = "memory.inbox.dreams.read_admin"
PURGE_SCOPE = "memory.inbox.dreams.purge_admin"

def _require_scope(token: Optional[Dict[str, Any]], scope: str) -> None:
    if not token:
        raise CapabilityError("Missing capability token.")
    if scope not in set(token.get("scopes") or []):
        raise CapabilityError(f"Missing required scope: {scope}")
    if float(token.get("exp_ts", 0)) <= time.time():
        raise CapabilityError("Capability token expired.")

# ---- Backing selection (FS preferred, with in-memory fallback) --------------

def _fs_enabled() -> bool:
    return os.getenv("MEMORY_INBOX_FS_ENABLED", "false").lower() in ("1","true","yes","on")

def _root_dir() -> str:
    return os.getenv("MEMORY_INBOX_ROOT", "var/memory_inbox")

def _trace_dir(trace_id: str) -> str:
    return os.path.join(_root_dir(), "dreams", trace_id)

def _ls_fs_traces() -> Iterable[str]:
    base = os.path.join(_root_dir(), "dreams")
    if not os.path.isdir(base):
        return []
    for name in os.listdir(base):
        if os.path.isdir(os.path.join(base, name)):
            yield name

def _load_fs_artifacts(trace_id: str) -> List[Dict[str, Any]]:
    d = _trace_dir(trace_id)
    if not os.path.isdir(d):
        raise NotFound(f"No artifacts for trace: {trace_id}")
    blobs: List[Dict[str, Any]] = []
    for fp in sorted(glob.glob(os.path.join(d, "*.json"))):
        with open(fp, "r", encoding="utf-8") as f:
            payload = json.load(f)
            blobs.extend(list(payload.get("artifacts") or []))
    return blobs

# In-memory fallback (tests/dev)
def _load_mem_artifacts() -> List[Dict[str, Any]]:
    try:
        from memory.inbox.dreams.writer import _debug_inmemory_dump
        return _debug_inmemory_dump()
    except Exception:
        return []

# ---- Public API -------------------------------------------------------------

def list_traces(*, cap_token: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    Return summaries of available dream traces (admin).
    """
    _require_scope(cap_token, READ_SCOPE)
    items: List[Dict[str, Any]] = []
    if _fs_enabled():
        for trace_id in _ls_fs_traces():
            # Peek first file for quick summary
            artifacts = _load_fs_artifacts(trace_id)
            if not artifacts:
                continue
            newest_ts = max(a.get("timestamp", 0) for a in artifacts)
            items.append({"trace_id": trace_id, "count": len(artifacts), "last_ts": newest_ts})
    else:
        artifacts = _load_mem_artifacts()
        # group by trace
        grouped: Dict[str, List[Dict[str, Any]]] = {}
        for a in artifacts:
            grouped.setdefault(a.get("trace_id", "LT-unknown"), []).append(a)
        for tid, arr in grouped.items():
            newest_ts = max(x.get("timestamp", 0) for x in arr)
            items.append({"trace_id": tid, "count": len(arr), "last_ts": newest_ts})
    # newest first
    return sorted(items, key=lambda x: x["last_ts"], reverse=True)

def read_artifacts(
    trace_id: str,
    *,
    cap_token: Dict[str, Any],
    limit: Optional[int] = None,
) -> List[Dict[str, Any]]:
    """
    Load artifacts for a specific trace (admin).
    """
    _require_scope(cap_token, READ_SCOPE)
    data: List[Dict[str, Any]]
    if _fs_enabled():
        data = _load_fs_artifacts(trace_id)
    else:
        data = [a for a in _load_mem_artifacts() if a.get("trace_id") == trace_id]
        if not data:
            raise NotFound(f"No artifacts for trace: {trace_id}")
    data.sort(key=lambda x: (x.get("timestamp", 0), x.get("index", 0)))
    return data[:limit] if limit else data

def search(
    *,
    cap_token: Dict[str, Any],
    ul_tag: Optional[str] = None,
    goal_contains: Optional[str] = None,
    since_ts: Optional[int] = None,
) -> List[Dict[str, Any]]:
    """
    Lightweight search across all artifacts (admin). FS can be largeâ€”use filters.
    """
    _require_scope(cap_token, READ_SCOPE)
    def _matches(a: Dict[str, Any]) -> bool:
        if since_ts and int(a.get("timestamp", 0)) < int(since_ts): return False
        if ul_tag:
            tags = ((a.get("proposal") or {}).get("ul_tags") or [])
            if ul_tag not in tags: return False
        if goal_contains:
            sm = (a.get("seed_meta") or {}).get("goal") or ""
            if re.search(goal_contains, sm, re.I) is None: return False
        return True

    pool: List[Dict[str, Any]] = []
    if _fs_enabled():
        for tid in _ls_fs_traces():
            pool.extend(_load_fs_artifacts(tid))
    else:
        pool = _load_mem_artifacts()

    return [a for a in pool if _matches(a)]

def purge_trace(trace_id: str, *, cap_token: Dict[str, Any]) -> int:
    """
    Irreversibly removes artifacts for a given trace (admin).
    Returns number of deleted files (FS) or records (in-memory).
    """
    _require_scope(cap_token, PURGE_SCOPE)
    if _fs_enabled():
        d = _trace_dir(trace_id)
        if not os.path.isdir(d): return 0
        n = 0
        for fp in glob.glob(os.path.join(d, "*.json")):
            try:
                os.remove(fp); n += 1
            except OSError:
                pass
        try:
            os.rmdir(d)
        except OSError:
            pass
        return n
    else:
        # In-memory purge
        try:
            from memory.inbox.dreams.writer import _debug_inmemory_dump
            data = _debug_inmemory_dump()
            before = len(data)
            # Rebuild in place (tests only)
            data[:] = [a for a in data if a.get("trace_id") != trace_id]
            return before - len(data)
        except Exception:
            return 0

Quick test (optional): tests/memory/test_dreams_reader_admin.py

import time
from memory.inbox.dreams.writer import persist_dream_shards
from memory.inbox.dreams.reader_admin import list_traces, read_artifacts, search, purge_trace

def admin_token():
    now = time.time()
    return {
        "token_id": "admin",
        "scopes": ["memory.inbox.dreams.read_admin", "memory.inbox.dreams.purge_admin", "memory.inbox.dreams.write"],
        "exp_ts": now + 3600,
        "issued_ts": now - 5,
    }

def test_admin_roundtrip_inmemory():
    tok = admin_token()
    seed = {"goal": "Greet Î›ID users", "context": {}, "constraints": {"budgets": {}, "flags": {}}}
    res  = {"trace_id": "LT-test-1", "shards": [{"proposal": {"ul_tags": ["Î›SIM"]}, "risks": [], "scores": {}}]}
    persist_dream_shards(seed=seed, result=res, cap_token=tok)

    traces = list_traces(cap_token=tok)
    assert any(t["trace_id"] == "LT-test-1" for t in traces)

    arts = read_artifacts("LT-test-1", cap_token=tok)
    assert len(arts) >= 1

    q = search(cap_token=tok, ul_tag="Î›SIM", goal_contains="Î›ID")
    assert len(q) >= 1

    deleted = purge_trace("LT-test-1", cap_token=tok)
    assert deleted >= 1

ðŸ” Posture: Reader is admin-only, gated by memory.inbox.dreams.read_admin. Purge requires memory.inbox.dreams.purge_admin. This keeps the inbox write-mostly while giving ops a safe window for debugging or data subject requests.

â¸»

2) Tiny fix in the writer (typo)

In the writer you pasted earlier, rename _REDAC_KEYS â†’ _REDACT_KEYS inside _redact_seed():

if k.lower() in _REDACT_KEYS or re.search(...):
    ctx[k] = "[REDACTED]"


â¸»

ðŸ§­ Deprecation plan (answering your question)

â€œAre we deprecating the API files we have now?â€

Short answer:
	â€¢	Do not deprecate the new canonical lane: consciousness.simulation.api (keep as the source of truth).
	â€¢	Keep legacy entry points (like any prior dream_bridge_adapter or consciousness/dreams/api.py) as shims for now, with warnings + metrics, and set a removal date only after callers are migrated.

Why: You want stability for existing call-sites while you finish consolidation. The bridge we added already forwards to the canonical API; thatâ€™s the right pattern.

Recommended policy
	1.	Canonical API (stay)
	â€¢	Keep: consciousness/simulation/api.py
	â€¢	Import direction: adapters â†’ simulation, never the reverse (enforced by import-linter).
	2.	Legacy APIs (graceful sunset)
If you still have older files (examples):
	â€¢	consciousness/dreams/api.py
	â€¢	bridge/dreams.py or other historical adapters
Replace their bodies with a shim + warning:
Path: consciousness/dreams/api.py (shim)

import warnings
warnings.warn(
    "Deprecated: use 'consciousness.simulation.api' instead. "
    "This shim will be removed on 2025-11-01.",
    DeprecationWarning,
    stacklevel=2
)
from consciousness.simulation.api import *  # noqa


	3.	CI visibility
	â€¢	In your CI test step, treat DeprecationWarning as error for new usages only (or log a budget):

PYTHONWARNINGS=default::DeprecationWarning pytest -q


	â€¢	Or add a warning budget via pytest-warning-control plugin (e.g., max 0 new).

	4.	Import contracts
Add/keep an Import Linter contract:

[contract:simulation_cannot_depend_on_adapters]
name = Simulation cannot import adapters
type = forbidden
source_modules = consciousness.simulation
forbidden_modules = adapters


	5.	Removal date
	â€¢	Publish in DEPRECATIONS.md with a clear date (e.g., 2025-11-01), and auto-emit a log line at import so you can find lingering dependencies.

â¸»

ðŸ”§ Optional: tiny admin CLI (nice to have)

If helpful later, drop a small CLI wrapper:

Path: tools/dreams_admin_cli.py

#!/usr/bin/env python3
import os, json, time, argparse
from memory.inbox.dreams import reader_admin as R

def _token(scopes):
    now = time.time()
    return {"token_id": "cli", "scopes": scopes, "exp_ts": now + 300}

def main():
    p = argparse.ArgumentParser()
    sub = p.add_subparsers(dest="cmd", required=True)

    sub.add_parser("list")

    r = sub.add_parser("read");  r.add_argument("trace_id"); r.add_argument("--limit", type=int)
    s = sub.add_parser("search"); s.add_argument("--tag"); s.add_argument("--goal"); s.add_argument("--since", type=int)
    d = sub.add_parser("purge"); d.add_argument("trace_id")

    args = p.parse_args()
    if args.cmd == "list":
        out = R.list_traces(cap_token=_token(["memory.inbox.dreams.read_admin"]))
    elif args.cmd == "read":
        out = R.read_artifacts(args.trace_id, cap_token=_token(["memory.inbox.dreams.read_admin"]), limit=args.limit)
    elif args.cmd == "search":
        out = R.search(cap_token=_token(["memory.inbox.dreams.read_admin"]), ul_tag=args.tag, goal_contains=args.goal, since_ts=args.since)
    elif args.cmd == "purge":
        out = {"deleted": R.purge_trace(args.trace_id, cap_token=_token(["memory.inbox.dreams.purge_admin"]))}
    print(json.dumps(out, indent=2))

if __name__ == "__main__":
    main()


â¸»

ðŸ§ª Quick sanity checklist
	â€¢	SIMULATION_ENABLED=true in CI for tests that exercise the lane.
	â€¢	MEMORY_INBOX_FS_ENABLED=true + MEMORY_INBOX_ROOT=var/memory_inbox if you want file output locally.
	â€¢	Import-linter rules updated to prevent reverse imports.
	â€¢	DEPRECATIONS.md created with the 2025-11-01 removal target for any legacy APIs you shim.

---

## MATADA Alignment Update (v1)

Admin reader capabilities:
	â€¢	Filter/export by node.type, provenance.tenant, provenance.consent_scopes, timestamps.created_ts.
	â€¢	CLI pattern: tools/dreams_admin_cli.py export-nodes --trace LT-... > nodes.ldjson
	â€¢	Refuse export when consent scopes are insufficient; emit denial rationale with Î›-trace ID.

â¸»
