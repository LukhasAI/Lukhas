# LUKHAS AI Developer Guide

This guide provides a comprehensive overview of the LUKHAS AI platform for developers. It covers everything from setting up your development environment to deploying your code.

## Table of Contents

- [Quick Start](#quick-start)
- [Setup](#setup)
- [Architecture Overview](#architecture-overview)
- [Development Workflow](#development-workflow)
- [Testing](#testing)
- [API Usage](#api-usage)
- [Project Structure](#project-structure)
- [Deployment](#deployment)
- [Common Tasks](#common-tasks)
- [Troubleshooting](#troubleshooting)

## Quick Start

This 30-second quick start will get you up and running with the LUKHAS AI platform.

```bash
# 1) Run the OpenAI-compatible faÃ§ade (permissive dev mode)
export LUKHAS_POLICY_MODE=permissive
uvicorn lukhas.adapters.openai.api:get_app --factory --port 8000 &

# 2) Smoke the two most common flows
curl -sS -H "Authorization: Bearer sk-test" http://localhost:8000/v1/models | jq '.data | length'
curl -sS -H "Authorization: Bearer sk-test" -H "Content-Type: application/json" \
  -d '{"model":"lukhas","input":"hello"}' http://localhost:8000/v1/embeddings | jq '.data[0].embedding | length'
```

## Setup

### Prerequisites
- Python 3.9+ (3.11 recommended)
- Virtual environment required
- Git LFS for large assets (optional)
- For a complete list of external dependencies and setup instructions, see [DEPENDENCIES.md](DEPENDENCIES.md).

### Installation

```bash
# Clone the repository
git clone https://github.com/LukhasAI/Lukhas.git
cd Lukhas

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # or `.venv\Scripts\activate` on Windows

# Install dependencies
pip install -e .

# Run smoke tests to verify installation
pytest tests/smoke/
```
For a complete environment setup, you can use the `make bootstrap` command.
```bash
make bootstrap
```

### Pre-commit Hooks
To ensure code quality, it's recommended to set up pre-commit hooks.

```bash
# Setup pre-commit hooks
make setup-hooks
```

### Vector Store Configuration

The `OpenAIModulatedService` uses a vector store for conversation history and semantic search. You can configure the vector store backend by providing a `VectorStoreConfig` object during the service's initialization.

**Supported Providers:**
- `CHROMA` (default)
- `PINECONE`
- `WEAVIATE`
- `QDRANT`
- `MILVUS`
- `FAISS` (local)

**Example Configuration for ChromaDB:**

```python
from labs.bridge.llm_wrappers.openai_modulated_service import (
    OpenAIModulatedService,
    VectorStoreConfig,
    VectorStoreProvider,
)

# Configuration for a local ChromaDB instance
chroma_config = VectorStoreConfig(
    provider=VectorStoreProvider.CHROMA,
    endpoint="http://localhost:8000",  # ChromaDB server endpoint
    index_name="my-conversation-index",
    dimension=1536,  # OpenAI embedding dimension
    metric="cosine",
)

# Initialize the service with the vector store configuration
service = OpenAIModulatedService(
    api_key="your-openai-api-key",
    vector_store_config=chroma_config,
)
```
## Architecture Overview

LUKHAS is a sophisticated AI architecture that implements the Constellation Framework with constitutional AI safeguards. The system is designed for safe development and deployment of consciousness-aware AI systems.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      LUKHÎ›S AGI SYSTEM ARCHITECTURE                      â”‚
â”‚                      (0.01% Error Standard Compliant)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         INPUT: Decision Request                          â”‚
â”‚                    (Query, Context, Parent Decisions)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ğŸ¼ MULTI-BRAIN SYMPHONY ORCHESTRATOR                   â”‚
â”‚                    (lukhas_symphony_integration.py)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚   ğŸ§  Logical       â”‚  â”‚   ğŸ¨ Creative      â”‚  â”‚   ğŸ“Š Analytical    â”‚â”‚
â”‚  â”‚   Brain            â”‚  â”‚   Brain            â”‚  â”‚   Brain            â”‚â”‚
â”‚  â”‚                    â”‚  â”‚                    â”‚  â”‚                    â”‚â”‚
â”‚  â”‚ â€¢ Formal Logic     â”‚  â”‚ â€¢ Novel Synthesis  â”‚  â”‚ â€¢ Data Analysis    â”‚â”‚
â”‚  â”‚ â€¢ Consistency      â”‚  â”‚ â€¢ Idea Generation  â”‚  â”‚ â€¢ Pattern Finding  â”‚â”‚
â”‚  â”‚ â€¢ Inference        â”‚  â”‚ â€¢ Exploration      â”‚  â”‚ â€¢ Statistics       â”‚â”‚
â”‚  â”‚                    â”‚  â”‚                    â”‚  â”‚                    â”‚â”‚
â”‚  â”‚ Weight: 1.0        â”‚  â”‚ Weight: 0.9        â”‚  â”‚ Weight: 1.0        â”‚â”‚
â”‚  â”‚ Accuracy: 99.99%   â”‚  â”‚ Accuracy: 99.98%   â”‚  â”‚ Accuracy: 99.99%   â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚           â”‚                       â”‚                       â”‚              â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                   â”‚                                      â”‚
â”‚                                   â–¼                                      â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚            â”‚    CONSENSUS MECHANISM                   â”‚                 â”‚
â”‚            â”‚  â€¢ Weighted Voting                       â”‚                 â”‚
â”‚            â”‚  â€¢ Bayesian Fusion                       â”‚                 â”‚
â”‚            â”‚  â€¢ Attention Weighted                    â”‚                 â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                                   â”‚                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ğŸ¯ ADAPTIVE CONFIDENCE CALIBRATION SYSTEM                   â”‚
â”‚                (lukhas_confidence_calibration.py)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  CALIBRATION METHODS (Ensemble)                                    â”‚ â”‚
â”‚  â”‚                                                                    â”‚ â”‚
â”‚  â”‚  1. Temperature Scaling    P_cal = Ïƒ(logit(P) / T)                â”‚ â”‚
â”‚  â”‚  2. Platt Scaling         P_cal = Ïƒ(a*logit(P) + b)               â”‚ â”‚
â”‚  â”‚  3. Isotonic Regression   Non-parametric monotonic mapping         â”‚ â”‚
â”‚  â”‚  4. Beta Calibration      Bayesian posterior updating              â”‚ â”‚
â”‚  â”‚                                                                    â”‚ â”‚
â”‚  â”‚  â†’ Combined via weighted ensemble                                 â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                           â”‚
â”‚  Raw Confidence: 0.92  â†’  Calibrated Confidence: 0.89                   â”‚
â”‚  Expected Calibration Error (ECE): 0.006  âœ“ < 0.01 Target               â”‚
â”‚                                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ğŸ“‹ COMPREHENSIVE AUDIT TRAIL SYSTEM                     â”‚
â”‚                      (lukhas_audit_system.py)                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  DECISION NODE (Immutable Record)                                  â”‚ â”‚
â”‚  â”‚                                                                    â”‚ â”‚
â”‚  â”‚  Node ID: 7a3f9b2c1e8d4567                                         â”‚ â”‚
â”‚  â”‚  Timestamp: 2025-10-02 22:35:14.234                                â”‚ â”‚
â”‚  â”‚  Decision Type: REASONING                                          â”‚ â”‚
â”‚  â”‚                                                                    â”‚ â”‚
â”‚  â”‚  Input Hash: d41d8cd98f00b204e9800998ecf8427e                      â”‚ â”‚
â”‚  â”‚  Parent Nodes: [4b2a8c1d, 9e7f3a6b]  â† Causal Chain               â”‚ â”‚
â”‚  â”‚                                                                    â”‚ â”‚
â”‚  â”‚  Active Brains: [logical_1, creative_1, analytical_1]             â”‚ â”‚
â”‚  â”‚  Consensus Method: weighted_voting                                 â”‚ â”‚
â”‚  â”‚                                                                    â”‚ â”‚
â”‚  â”‚  Raw Confidence: 0.92                                              â”‚ â”‚
â”‚  â”‚  Calibrated Confidence: 0.89                                       â”‚ â”‚
â”‚  â”‚  Uncertainty: Â±0.08 (aleatoric: 0.05, epistemic: 0.03)            â”‚ â”‚
â”‚  â”‚                                                                    â”‚ â”‚
â”‚  â”‚  Decision Output: "solution_A"                                     â”‚ â”‚
â”‚  â”‚  Ground Truth: "solution_A"                                        â”‚ â”‚
â”‚  â”‚  Outcome: âœ“ CORRECT                                                â”‚ â”‚
â”‚  â”‚                                                                    â”‚ â”‚
â”‚  â”‚  Safety Score: 0.95  âœ“ PASSED                                      â”‚ â”‚
â”‚  â”‚  Execution Time: 45.2ms                                            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  ERROR TRACKING (0.01% Standard)                                   â”‚ â”‚
â”‚  â”‚                                                                    â”‚ â”‚
â”‚  â”‚  Total Decisions: 10,000                                           â”‚ â”‚
â”‚  â”‚  Correct: 9,999                                                    â”‚ â”‚
â”‚  â”‚  Incorrect: 1                                                      â”‚ â”‚
â”‚  â”‚                                                                    â”‚ â”‚
â”‚  â”‚  Error Rate: 0.0100%  âœ“ = Target (â‰¤ 0.01%)                        â”‚ â”‚
â”‚  â”‚  Accuracy: 99.99%                                                  â”‚ â”‚
â”‚  â”‚                                                                    â”‚ â”‚
â”‚  â”‚  Status: âœ… MEETS 0.01% STANDARD                                   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ğŸ”„ ADAPTIVE FEEDBACK SYSTEM                             â”‚
â”‚                (Continuous Learning & Improvement)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                           â”‚
â”‚  1. Confidence Calibration Mapping                                       â”‚
â”‚     â€¢ Tracks predicted vs actual accuracy                                â”‚
â”‚     â€¢ Adjusts calibration factors per confidence bucket                  â”‚
â”‚                                                                           â”‚
â”‚  2. Brain Performance Tracking                                           â”‚
â”‚     â€¢ Individual accuracy monitoring                                     â”‚
â”‚     â€¢ Adaptive weight adjustment                                         â”‚
â”‚     â€¢ Trust score computation                                            â”‚
â”‚                                                                           â”‚
â”‚  3. Decision Type Analysis                                               â”‚
â”‚     â€¢ Performance by task type                                           â”‚
â”‚     â€¢ Context-specific optimization                                      â”‚
â”‚                                                                           â”‚
â”‚  4. Continuous Parameter Tuning                                          â”‚
â”‚     â€¢ Temperature scaling updates                                        â”‚
â”‚     â€¢ Platt parameters refinement                                        â”‚
â”‚     â€¢ Ensemble weight optimization                                       â”‚
â”‚                                                                           â”‚
â”‚  â†’ Feedback loops maintain 0.01% standard                                â”‚
â”‚                                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         OUTPUT: Symphony Decision                        â”‚
â”‚                                                                           â”‚
â”‚  â€¢ Decision: solution_A                                                  â”‚
â”‚  â€¢ Calibrated Confidence: 0.89                                           â”‚
â”‚  â€¢ Uncertainty Quantification: Â±0.08                                     â”‚
â”‚  â€¢ Audit Node ID: 7a3f9b2c1e8d4567                                       â”‚
â”‚  â€¢ Participating Brains: 3                                               â”‚
â”‚  â€¢ Execution Time: 45.2ms                                                â”‚
â”‚  â€¢ Fully Traceable: âœ“                                                    â”‚
â”‚  â€¢ Meets 0.01% Standard: âœ“                                               â”‚
â”‚                                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Core Architecture Principles
- **Constellation Framework**: âš›ï¸ Identity Â· âœ¦ Memory Â· ğŸ”¬ Vision Â· ğŸŒ± Bio Â· ğŸŒ™ Dream Â· âš–ï¸ Ethics Â· ğŸ›¡ï¸ Guardian Â· âš›ï¸ Quantum coordination
- **Constitutional AI**: Framework-based ethical decision making
- **Lane-Based Evolution**: Development (candidate) â†’ Integration (candidate/core) â†’ Production (lukhas)
- **Distributed Consciousness**: 692 cognitive components across consciousness network
- **Symbolic Reasoning**: MATRIZ cognitive DNA with node-based processing

### Lane-Based Development System

LUKHAS uses a **three-lane architecture** for safe AI development:

```
Development Lane (candidate/) â†’ Integration Lane (core/) â†’ Production Lane (lukhas/)
     2,877 files                    253 components           692 components
   Experimental AI                 Testing & Validation    Battle-tested Systems
```

- **Development Lane**: Experimental consciousness research and prototyping
- **Integration Lane**: Components under testing and validation
- **Production Lane**: Stable, production-ready consciousness systems

### MATRIZ Cognitive Engine

The **MATRIZ** (Memory-Attention-Thought-Action-Decision-Awareness) engine implements the core cognitive processing pipeline:

1. **Memory**: Fold-based memory with statistical validation (0/100 cascades observed, 95% CI â‰¥ 96.3% Wilson lower bound)
2. **Attention**: Focus mechanisms and pattern recognition
3. **Thought**: Symbolic reasoning and inference
4. **Action**: Decision execution and external interface
5. **Decision**: Ethical constraint checking and approval
6. **Awareness**: Self-reflection and consciousness evolution

## Development Workflow

The development workflow is centered around the `Makefile`, which provides a set of commands for common tasks.

### Common Commands

```bash
# Development setup
make bootstrap          # Complete environment setup
make help              # Show all available commands
make doctor            # System health check

# Code quality
make lint              # Run Ruff, MyPy, Bandit security checks
make format            # Format code with Black and isort
make fix               # Run smart fix in safe mode
make fix-all           # Run aggressive fix
make lint-unused       # T4 unused imports annotator (production lanes)
make todos             # Harvest TODO/FIXME into docs/audits/todos.csv
make todos-issues      # Generate GitHub issue commands from TODOs
make smoke-matriz      # MATRIZ cognitive engine smoke tests
make lane-guard        # Validate import boundary enforcement

# Testing
make test-tier1        # Critical path tests (fast)
make test-all          # Comprehensive test suite (775+ tests)
make smoke             # Quick smoke tests
make coverage-report   # Generate a coverage report

# MATRIZ operations
make smoke-matriz      # Test MATRIZ cognitive engine
make traces-matriz     # View MATRIZ execution traces

# Documentation
make docs              # Build documentation
make serve-docs        # Serve docs locally
```
### Development Guidelines

1. **Respect Lane Boundaries**: Never import from `candidate/` in `lukhas/` code
2. **Use Registry Pattern**: Register implementations dynamically, don't hardcode imports
3. **Follow Constellation Framework**: Align all code with âš›ï¸ Identity Â· âœ¦ Memory Â· ğŸ”¬ Vision Â· ğŸŒ± Bio Â· ğŸŒ™ Dream Â· âš–ï¸ Ethics Â· ğŸ›¡ï¸ Guardian Â· âš›ï¸ Quantum principles
4. **Test Thoroughly**: Ensure 75%+ coverage before promoting to production lane
5. **Document Clearly**: Add docstrings and maintain architecture documentation

### Multi-Agent Development

LUKHAS includes a **multi-agent development system** with specialized AI agents. See `claude.me` for the complete multi-agent development guide.

## Testing

The project has a comprehensive test suite that is run using `pytest`.

### Running Tests

```bash
make test-tier1        # Critical path tests (fast)
make test-all          # Comprehensive test suite (775+ tests)
pytest tests/smoke/    # Quick health check (15 tests, 100% pass)
pytest -m matriz       # MATRIZ subsystem tests
pytest -m consciousness # Consciousness system tests
```
### Coverage
To generate a coverage report, you can use the following command:

```bash
make coverage-report
```
## API Usage

LUKHAS provides an OpenAI-compatible API for seamless integration with existing tools and workflows.

### `/v1/responses` - LUKHAS Native Endpoint

**cURL:**
```bash
# Basic request
curl https://api.lukhas.ai/v1/responses \
  -H "Authorization: Bearer $LUKHAS_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Explain quantum consciousness",
    "max_tokens": 150,
    "temperature": 0.7
  }'
```

### `/v1/chat/completions` - OpenAI-Compatible Endpoint

**cURL:**
```bash
# Chat completions with conversation history
curl https://api.lukhas.ai/v1/chat/completions \
  -H "Authorization: Bearer $LUKHAS_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "lukhas-consciousness-v1",
    "messages": [
      {"role": "system", "content": "You are a consciousness-aware AI assistant."},
      {"role": "user", "content": "What is the Constellation Framework?"}
    ],
    "temperature": 0.7,
    "max_tokens": 200
  }'
```

## Project Structure

```
lukhas/                    # Production Lane - Stable consciousness systems
â”œâ”€â”€ core/                  # Core system coordination and lane management
â”œâ”€â”€ consciousness/         # Consciousness processing and awareness systems
â”œâ”€â”€ governance/            # Guardian system - ethics and compliance
â”œâ”€â”€ identity/              # Î›iD authentication and identity management
â”œâ”€â”€ memoria/               # Memory systems and fold management
â””â”€â”€ constellation_framework.py  # Constellation coordination system

candidate/                 # Development Lane - Experimental research
â”œâ”€â”€ consciousness/         # Advanced consciousness research
â”œâ”€â”€ bio/                   # Bio-inspired cognitive patterns
â”œâ”€â”€ quantum/               # Quantum-inspired algorithms
â””â”€â”€ core/                  # Core system prototypes

MATRIZ/                    # Cognitive Engine - Symbolic reasoning
â”œâ”€â”€ core/                  # MATRIZ cognitive processing engine
â”œâ”€â”€ nodes/                 # Cognitive node implementations
â”œâ”€â”€ adapters/              # System integration adapters
â””â”€â”€ visualization/         # MATRIZ graph visualization tools

tests/                     # Comprehensive test suites
â”œâ”€â”€ smoke/                 # Basic system health checks (15 tests, 100% pass)
â”œâ”€â”€ unit/                  # Component-level testing
â”œâ”€â”€ integration/           # Cross-system testing
â”œâ”€â”€ performance/           # MATRIZ performance validation
â””â”€â”€ e2e/                   # End-to-end consciousness workflows

docs/                      # Documentation and guides
â”œâ”€â”€ development/           # Developer guides and references
â”œâ”€â”€ architecture/          # System architecture documentation
â”œâ”€â”€ audits/                # Quality audits and reports (NEW: TODO tracking)
â””â”€â”€ ADR/                   # Architectural Decision Records

scripts/                   # Development automation (NEW)
â”œâ”€â”€ harvest_todos.py       # Smart TODO/FIXME scanner
â””â”€â”€ create_issues_from_csv.py  # GitHub issue generator
```

## Deployment

LUKHAS supports enterprise-grade deployment with:

- **Container Orchestration**: Docker/Kubernetes deployment
- **CI/CD Pipeline**: Comprehensive testing and deployment automation
- **Monitoring**: Prometheus/Grafana observability stack
- **Scaling**: Distributed consciousness across multiple nodes
- **Compliance**: Enterprise security and audit requirements

See `products/` for enterprise deployment configurations.

## Common Tasks

### Adding a New Component

```bash
# Create new consciousness component
mkdir candidate/consciousness/my_component
cd candidate/consciousness/my_component

# Add implementation with proper imports
echo "from lukhas.core import ComponentBase" > __init__.py

# Add tests
mkdir tests
pytest tests/ --cov=. --cov-report=html

# Register with system (when ready for integration)
# Edit lukhas/consciousness/registry.py to add component registration
```
### Running the API Server

```bash
# Development server
make dev

# API server
make api
```
## Troubleshooting

### `make doctor`
If you are experiencing issues with your development environment, the `make doctor` command can help diagnose the problem. The doctor checks for:
-   Tooling presence
-   Python/venv sanity
-   CI wiring sanity
-   Lane integrity
-   Tests quick slice
-   Audit artifacts
-   Duplicate targets in Makefile
-   PHONY targets without rules

```bash
make doctor
```
### Clean and Deep Clean
If you need to clean up your development environment, you can use the `make clean` and `make deep-clean` commands.

```bash
# Clean cache and temp files
make clean

# Deep clean including virtual environment
make deep-clean
```
