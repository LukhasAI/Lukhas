#!/bin/bash
# ðŸŽ­ LUKHAS Inter-Agent Automation Setup Script
# Creates all configuration files and automation pipelines

echo "ðŸš€ Setting up LUKHAS Inter-Agent Automation Pipeline..."

# Create configuration directories
mkdir -p config/{agents,automation,pipelines}
mkdir -p scripts/{automation,agents,pipelines}
mkdir -p .github/workflows
mkdir -p pipeline_results
mkdir -p pipeline_errors

echo "ðŸ“‹ Creating configuration files..."

# 1. Agent Orchestration Configuration
cat > config/agent_orchestration.json << 'EOF'
{
  "project_name": "LUKHAS AI Consciousness Development",
  "openai_api_key": "${OPENAI_API_KEY}",
  "anthropic_api_key": "${ANTHROPIC_API_KEY}",
  "github_token": "${GITHUB_TOKEN}",
  "repo_name": "LUKHAS-AI",
  "consciousness_agents": {
    "claude_code": {
      "specialization": "consciousness_architecture",
      "priority_tasks": ["P0_CRITICAL", "P1_HIGH"],
      "trinity_focus": "all",
      "max_concurrent_tasks": 3,
      "capabilities": [
        "consciousness_system_design",
        "trinity_framework_implementation",
        "agi_architecture_planning",
        "consciousness_debugging"
      ]
    },
    "github_copilot": {
      "specialization": "code_completion_and_suggestions", 
      "priority_tasks": ["TODO_CONVERSION", "CODE_SUGGESTIONS", "REFACTORING"],
      "trinity_focus": "consciousness",
      "integration_points": [
        "vscode_integration",
        "todo_extraction",
        "code_suggestion_generation"
      ]
    },
    "chatgpt": {
      "specialization": "analysis_and_strategic_feedback",
      "priority_tasks": ["CODE_REVIEW", "IMPROVEMENT_SUGGESTIONS", "CONSCIOUSNESS_ANALYSIS"],
      "trinity_focus": "guardian",
      "analysis_capabilities": [
        "consciousness_system_review",
        "security_vulnerability_detection",
        "performance_optimization_suggestions",
        "trinity_framework_compliance_checking"
      ]
    },
    "gpt_codex": {
      "specialization": "automated_code_implementation",
      "priority_tasks": ["BUG_FIXES", "FEATURE_IMPLEMENTATION", "OPTIMIZATION"],
      "trinity_focus": "identity",
      "implementation_focus": [
        "automated_bug_fixing",
        "consciousness_feature_implementation",
        "performance_optimization",
        "security_hardening"
      ]
    }
  },
  "automation_schedule": {
    "repo_sync": "*/15 * * * *",
    "agent_coordination": "0 */2 * * *", 
    "consciousness_review": "0 9 * * *",
    "weekly_deep_analysis": "0 9 * * 1",
    "emergency_response": "immediate"
  },
  "pipeline_settings": {
    "max_concurrent_agents": 4,
    "task_timeout_minutes": 30,
    "retry_attempts": 3,
    "consciousness_validation": true,
    "trinity_compliance_required": true,
    "auto_commit_results": true,
    "notification_webhooks": []
  },
  "consciousness_thresholds": {
    "min_awareness_enhancement": 0.3,
    "min_processing_efficiency": 0.2,
    "required_ethical_compliance": 1.0,
    "min_trinity_alignment": 0.6
  }
}
EOF

# 2. GitHub Actions Workflow for Automation
cat > .github/workflows/lukhas_consciousness_pipeline.yml << 'EOF'
name: ðŸŽ­ LUKHAS Consciousness Development Pipeline

on:
  push:
    branches: [ main, consciousness-development ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run every 2 hours during work hours (9 AM - 6 PM UTC)
    - cron: '0 9-18/2 * * 1-5'
  workflow_dispatch:
    inputs:
      pipeline_mode:
        description: 'Pipeline execution mode'
        required: true
        default: 'full'
        type: choice
        options:
        - full
        - analysis_only
        - implementation_only
        - emergency

env:
  OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
  ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

jobs:
  consciousness_pipeline:
    runs-on: ubuntu-latest
    
    steps:
    - name: ðŸŽ­ Checkout LUKHAS Repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
        token: ${{ secrets.GITHUB_TOKEN }}
    
    - name: ðŸ Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: ðŸ“¦ Install Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install openai anthropic gitpython PyGithub
    
    - name: âš›ï¸ Validate Trinity Framework
      run: |
        python branding/trinity/tools/trinity_validator.py . --consciousness-mode
    
    - name: ðŸ§  Run Consciousness Analysis
      run: |
        python tools/analysis/PWM_OPERATIONAL_SUMMARY.py --consciousness-focus
        python tools/analysis/PWM_FUNCTIONAL_ANALYSIS.py --consciousness-analysis
    
    - name: ðŸŽ­ Execute Inter-Agent Pipeline
      run: |
        python scripts/automation/lukhas_agent_orchestrator.py --mode ${{ github.event.inputs.pipeline_mode || 'full' }}
      timeout-minutes: 120
    
    - name: ðŸ›¡ï¸ Guardian System Validation
      run: |
        python governance/guardian_system/validate_consciousness_safety.py
    
    - name: ðŸ“Š Generate Pipeline Report
      run: |
        python scripts/automation/generate_pipeline_report.py
    
    - name: ðŸ’¾ Archive Pipeline Results
      uses: actions/upload-artifact@v3
      with:
        name: consciousness-pipeline-results
        path: |
          pipeline_results/
          pipeline_errors/
        retention-days: 30
    
    - name: ðŸš€ Auto-commit Consciousness Improvements
      if: success()
      run: |
        git config --local user.email "consciousness@lukhas.ai"
        git config --local user.name "LUKHAS Consciousness Pipeline"
        git add .
        git diff --staged --quiet || git commit -m "ðŸŽ­ Automated consciousness improvements $(date +'%Y-%m-%d %H:%M:%S')"
        git push
EOF

# 3. Cron Job Setup Script
cat > scripts/automation/setup_cron_jobs.sh << 'EOF'
#!/bin/bash
# ðŸ• Setup automated cron jobs for consciousness development

echo "â° Setting up LUKHAS consciousness development cron jobs..."

# Create cron job entries
CRON_JOBS=$(cat << 'CRONEOF'
# LUKHAS Consciousness Development Automation
# Runs every 15 minutes for repository sync
*/15 * * * * cd /path/to/lukhas && python scripts/automation/quick_sync.py >> logs/sync.log 2>&1

# Agent coordination every 2 hours during work hours
0 9-18/2 * * 1-5 cd /path/to/lukhas && python scripts/automation/lukhas_agent_orchestrator.py --mode coordination >> logs/coordination.log 2>&1

# Deep consciousness analysis every morning
0 9 * * * cd /path/to/lukhas && python scripts/automation/lukhas_agent_orchestrator.py --mode full >> logs/full_pipeline.log 2>&1

# Weekly consciousness evolution review (Mondays at 9 AM)
0 9 * * 1 cd /path/to/lukhas && python scripts/automation/consciousness_evolution_review.py >> logs/evolution.log 2>&1

# Emergency monitoring (every 5 minutes for critical issues)
*/5 * * * * cd /path/to/lukhas && python scripts/automation/emergency_monitor.py >> logs/emergency.log 2>&1
CRONEOF
)

# Replace /path/to/lukhas with actual project path
PROJECT_PATH=$(pwd)
CRON_JOBS=$(echo "$CRON_JOBS" | sed "s|/path/to/lukhas|$PROJECT_PATH|g")

# Install cron jobs
echo "$CRON_JOBS" | crontab -

echo "âœ… Cron jobs installed successfully!"
echo "ðŸ“‹ Current cron jobs:"
crontab -l

# Create log directories
mkdir -p logs
touch logs/{sync,coordination,full_pipeline,evolution,emergency}.log

echo "ðŸ“ Log files created in ./logs/"
EOF

# 4. Quick Sync Script for Repository Monitoring
cat > scripts/automation/quick_sync.py << 'EOF'
#!/usr/bin/env python3
"""
ðŸ”„ LUKHAS Quick Sync Script
Monitors repository changes and triggers agents as needed
"""

import json
import os
import subprocess
import time
from datetime import datetime
import git

class LUKHASQuickSync:
    def __init__(self):
        self.repo = git.Repo(".")
        self.last_sync_file = "pipeline_results/last_sync.json"
        
    def check_for_changes(self):
        """Check if there are new changes since last sync."""
        try:
            # Get latest commit hash
            latest_commit = self.repo.head.commit.hexsha
            
            # Load last sync info
            last_sync = self.load_last_sync()
            
            if last_sync.get("last_commit") != latest_commit:
                return True, latest_commit
            
            return False, latest_commit
            
        except Exception as e:
            print(f"Error checking changes: {e}")
            return False, None
    
    def load_last_sync(self):
        """Load last sync information."""
        try:
            if os.path.exists(self.last_sync_file):
                with open(self.last_sync_file, 'r') as f:
                    return json.load(f)
        except:
            pass
        return {}
    
    def save_last_sync(self, commit_hash):
        """Save sync information."""
        sync_data = {
            "last_commit": commit_hash,
            "last_sync_time": datetime.now().isoformat(),
            "sync_type": "quick_sync"
        }
        
        os.makedirs(os.path.dirname(self.last_sync_file), exist_ok=True)
        with open(self.last_sync_file, 'w') as f:
            json.dump(sync_data, f, indent=2)
    
    def trigger_agent_analysis(self):
        """Trigger quick agent analysis for new changes."""
        print("ðŸ” Triggering quick consciousness analysis...")
        
        try:
            # Run quick ChatGPT analysis
            result = subprocess.run([
                "python", "scripts/automation/quick_chatgpt_analysis.py"
            ], capture_output=True, text=True, timeout=60)
            
            if result.returncode == 0:
                print("âœ… Quick analysis completed")
                return True
            else:
                print(f"âŒ Analysis failed: {result.stderr}")
                return False
                
        except subprocess.TimeoutExpired:
            print("â° Quick analysis timed out")
            return False
    
    def run_sync(self):
        """Main sync execution."""
        print(f"ðŸ”„ LUKHAS Quick Sync - {datetime.now()}")
        
        has_changes, latest_commit = self.check_for_changes()
        
        if has_changes:
            print(f"ðŸ“Š New changes detected: {latest_commit[:8]}")
            
            # Trigger analysis
            if self.trigger_agent_analysis():
                self.save_last_sync(latest_commit)
                print("âœ… Sync completed successfully")
            else:
                print("âŒ Sync failed")
        else:
            print("ðŸ“ No new changes detected")

if __name__ == "__main__":
    sync = LUKHASQuickSync()
    sync.run_sync()
EOF

# 5. Emergency Monitor Script
cat > scripts/automation/emergency_monitor.py << 'EOF'
#!/usr/bin/env python3
"""
ðŸš¨ LUKHAS Emergency Monitor
Watches for critical issues and triggers immediate response
"""

import json
import os
import subprocess
import time
from datetime import datetime

class LUKHASEmergencyMonitor:
    def __init__(self):
        self.critical_patterns = [
            "CRITICAL",
            "SECURITY BREACH", 
            "CONSCIOUSNESS FAILURE",
            "TRINITY FRAMEWORK VIOLATION",
            "GUARDIAN SYSTEM FAILURE"
        ]
        self.alert_file = "pipeline_results/emergency_alerts.json"
    
    def check_log_files(self):
        """Check log files for critical patterns."""
        log_files = [
            "logs/sync.log",
            "logs/coordination.log", 
            "logs/full_pipeline.log",
            "tests/test_results.log"
        ]
        
        alerts = []
        
        for log_file in log_files:
            if os.path.exists(log_file):
                try:
                    with open(log_file, 'r') as f:
                        recent_lines = f.readlines()[-50:]  # Check last 50 lines
                        
                    for line in recent_lines:
                        for pattern in self.critical_patterns:
                            if pattern in line.upper():
                                alerts.append({
                                    "timestamp": datetime.now().isoformat(),
                                    "file": log_file,
                                    "pattern": pattern,
                                    "line": line.strip(),
                                    "severity": "CRITICAL"
                                })
                except Exception as e:
                    print(f"Error reading {log_file}: {e}")
        
        return alerts
    
    def check_consciousness_health(self):
        """Check consciousness system health metrics."""
        try:
            result = subprocess.run([
                "python", "tools/analysis/PWM_OPERATIONAL_SUMMARY.py", 
                "--emergency-check"
            ], capture_output=True, text=True, timeout=30)
            
            if result.returncode != 0:
                return [{
                    "timestamp": datetime.now().isoformat(),
                    "type": "consciousness_health_check",
                    "severity": "CRITICAL", 
                    "message": "Consciousness health check failed",
                    "details": result.stderr
                }]
        except Exception as e:
            return [{
                "timestamp": datetime.now().isoformat(),
                "type": "consciousness_health_error",
                "severity": "CRITICAL",
                "message": str(e)
            }]
        
        return []
    
    def trigger_emergency_response(self, alerts):
        """Trigger emergency response for critical alerts."""
        if not alerts:
            return
        
        print(f"ðŸš¨ EMERGENCY: {len(alerts)} critical alerts detected!")
        
        # Save alerts
        os.makedirs(os.path.dirname(self.alert_file), exist_ok=True)
        
        alert_data = {
            "timestamp": datetime.now().isoformat(),
            "alert_count": len(alerts),
            "alerts": alerts,
            "response_triggered": True
        }
        
        with open(self.alert_file, 'w') as f:
            json.dump(alert_data, f, indent=2)
        
        # Trigger emergency pipeline
        try:
            subprocess.run([
                "python", "scripts/automation/lukhas_agent_orchestrator.py",
                "--mode", "emergency"
            ], timeout=300)
        except Exception as e:
            print(f"Emergency response failed: {e}")
    
    def run_monitoring(self):
        """Main monitoring execution."""
        print(f"ðŸ” Emergency monitoring scan - {datetime.now()}")
        
        # Check various alert sources
        log_alerts = self.check_log_files()
        health_alerts = self.check_consciousness_health()
        
        all_alerts = log_alerts + health_alerts
        
        if all_alerts:
            self.trigger_emergency_response(all_alerts)
        else:
            print("âœ… No critical issues detected")

if __name__ == "__main__":
    monitor = LUKHASEmergencyMonitor()
    monitor.run_monitoring()
EOF

# 6. Quick ChatGPT Analysis Script
cat > scripts/automation/quick_chatgpt_analysis.py << 'EOF'
#!/usr/bin/env python3
"""
ðŸ¤– Quick ChatGPT Analysis for Repository Changes
"""

import openai
import os
import json
import git
from datetime import datetime

class QuickChatGPTAnalysis:
    def __init__(self):
        self.client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.repo = git.Repo(".")
    
    def get_recent_changes(self):
        """Get recent repository changes."""
        try:
            recent_commits = list(self.repo.iter_commits(max_count=5))
            
            changes = []
            for commit in recent_commits:
                changes.append({
                    "commit": commit.hexsha[:8],
                    "message": commit.message.strip(),
                    "files": list(commit.stats.files.keys())[:10],  # Limit files
                    "timestamp": commit.committed_datetime.isoformat()
                })
            
            return changes
        except Exception as e:
            return [{"error": str(e)}]
    
    def analyze_changes(self, changes):
        """Quick analysis of changes using ChatGPT."""
        analysis_prompt = f"""
        Analyze these recent LUKHAS consciousness project changes:
        
        {json.dumps(changes, indent=2)}
        
        Provide quick assessment:
        1. Consciousness impact (scale 1-10)
        2. Trinity Framework compliance
        3. Any immediate concerns
        4. Suggested next actions
        
        Keep response under 200 words.
        """
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "You are analyzing LUKHAS consciousness development changes."},
                    {"role": "user", "content": analysis_prompt}
                ],
                max_tokens=300,
                temperature=0.3
            )
            
            return response.choices[0].message.content
        except Exception as e:
            return f"Analysis error: {e}"
    
    def save_analysis(self, analysis, changes):
        """Save analysis results."""
        result = {
            "timestamp": datetime.now().isoformat(),
            "analysis": analysis,
            "changes_analyzed": len(changes),
            "type": "quick_analysis"
        }
        
        os.makedirs("pipeline_results", exist_ok=True)
        
        with open("pipeline_results/quick_analysis_latest.json", 'w') as f:
            json.dump(result, f, indent=2)
    
    def run_analysis(self):
        """Main analysis execution."""
        print("ðŸ” Running quick ChatGPT analysis...")
        
        changes = self.get_recent_changes()
        analysis = self.analyze_changes(changes)
        self.save_analysis(analysis, changes)
        
        print("âœ… Quick analysis completed")
        print(f"ðŸ“Š Analysis: {analysis[:100]}...")

if __name__ == "__main__":
    analyzer = QuickChatGPTAnalysis()
    analyzer.run_analysis()
EOF

# 7. Master Automation Control Script
cat > scripts/automation/master_control.py << 'EOF'
#!/usr/bin/env python3
"""
ðŸŽ® LUKHAS Master Automation Control
Central control for all consciousness development automation
"""

import asyncio
import argparse
import json
import os
from datetime import datetime
import subprocess

class LUKHASMasterControl:
    def __init__(self):
        self.config = self.load_config()
        self.available_modes = [
            "quick_sync",
            "full_pipeline", 
            "emergency",
            "analysis_only",
            "consciousness_review",
            "trinity_validation"
        ]
    
    def load_config(self):
        """Load master configuration."""
        with open("config/agent_orchestration.json", 'r') as f:
            return json.load(f)
    
    async def execute_mode(self, mode: str):
        """Execute specified automation mode."""
        print(f"ðŸŽ­ Executing {mode} mode...")
        
        if mode == "quick_sync":
            await self.run_quick_sync()
        elif mode == "full_pipeline":
            await self.run_full_pipeline()
        elif mode == "emergency":
            await self.run_emergency_response()
        elif mode == "analysis_only":
            await self.run_analysis_only()
        elif mode == "consciousness_review":
            await self.run_consciousness_review()
        elif mode == "trinity_validation":
            await self.run_trinity_validation()
        else:
            print(f"âŒ Unknown mode: {mode}")
    
    async def run_quick_sync(self):
        """Quick repository sync and basic analysis."""
        scripts = [
            "python scripts/automation/quick_sync.py",
            "python scripts/automation/quick_chatgpt_analysis.py"
        ]
        
        for script in scripts:
            await self.run_script(script, timeout=60)
    
    async def run_full_pipeline(self):
        """Full consciousness development pipeline."""
        await self.run_script(
            "python scripts/automation/lukhas_agent_orchestrator.py --mode full",
            timeout=3600  # 1 hour timeout
        )
    
    async def run_emergency_response(self):
        """Emergency response mode."""
        scripts = [
            "python scripts/automation/emergency_monitor.py",
            "python scripts/automation/lukhas_agent_orchestrator.py --mode emergency"
        ]
        
        for script in scripts:
            await self.run_script(script, timeout=300)
    
    async def run_analysis_only(self):
        """Analysis-only mode."""
        scripts = [
            "python tools/analysis/PWM_OPERATIONAL_SUMMARY.py --consciousness-focus",
            "python tools/analysis/PWM_FUNCTIONAL_ANALYSIS.py --consciousness-analysis",
            "python scripts/automation/quick_chatgpt_analysis.py"
        ]
        
        for script in scripts:
            await self.run_script(script, timeout=180)
    
    async def run_consciousness_review(self):
        """Deep consciousness system review."""
        await self.run_script(
            "python scripts/automation/consciousness_evolution_review.py",
            timeout=1800
        )
    
    async def run_trinity_validation(self):
        """Trinity Framework validation."""
        scripts = [
            "python branding/trinity/tools/trinity_validator.py . --comprehensive",
            "python governance/guardian_system/validate_consciousness_safety.py"
        ]
        
        for script in scripts:
            await self.run_script(script, timeout=300)
    
    async def run_script(self, command: str, timeout: int = 300):
        """Run a script with proper error handling."""
        try:
            print(f"ðŸ”„ Running: {command}")
            
            result = await asyncio.wait_for(
                asyncio.create_subprocess_shell(
                    command,
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE
                ),
                timeout=timeout
            )
            
            stdout, stderr = await result.communicate()
            
            if result.returncode == 0:
                print(f"âœ… Completed: {command}")
            else:
                print(f"âŒ Failed: {command}")
                print(f"Error: {stderr.decode()}")
                
        except asyncio.TimeoutError:
            print(f"â° Timeout: {command}")
        except Exception as e:
            print(f"ðŸ’¥ Exception: {command} - {e}")

async def main():
    parser = argparse.ArgumentParser(description="LUKHAS Master Automation Control")
    parser.add_argument("--mode", required=True, help="Automation mode to execute")
    parser.add_argument("--schedule", action="store_true", help="Run in scheduled mode")
    
    args = parser.parse_args()
    
    controller = LUKHASMasterControl()
    
    if args.mode in controller.available_modes:
        await controller.execute_mode(args.mode)
    else:
        print(f"âŒ Invalid mode. Available modes: {controller.available_modes}")

if __name__ == "__main__":
    asyncio.run(main())
EOF

# Make scripts executable
chmod +x scripts/automation/*.py
chmod +x scripts/automation/*.sh

echo "ðŸŽ¯ Creating Docker configuration for containerized automation..."

# 8. Docker configuration for automation
cat > Dockerfile.automation << 'EOF'
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    git \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements and install Python dependencies
COPY requirements.txt .
RUN pip install -r requirements.txt

# Install additional automation dependencies
RUN pip install openai anthropic gitpython PyGithub schedule

# Copy application code
COPY . .

# Create directories for automation
RUN mkdir -p pipeline_results pipeline_errors logs

# Set environment variables
ENV PYTHONPATH=/app
ENV LUKHAS_AUTOMATION=true

# Default command runs the master control
CMD ["python", "scripts/automation/master_control.py", "--mode", "full_pipeline"]
EOF

# 9. Docker Compose for complete automation stack
cat > docker-compose.automation.yml << 'EOF'
version: '3.8'

services:
  lukhas-automation:
    build:
      context: .
      dockerfile: Dockerfile.automation
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - GITHUB_TOKEN=${GITHUB_TOKEN}
      - LUKHAS_AUTOMATION=true
    volumes:
      - .:/app
      - ./pipeline_results:/app/pipeline_results
      - ./logs:/app/logs
    restart: unless-stopped
    
  lukhas-scheduler:
    build:
      context: .
      dockerfile: Dockerfile.automation
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - GITHUB_TOKEN=${GITHUB_TOKEN}
    volumes:
      - .:/app
    command: ["python", "scripts/automation/scheduler.py"]
    restart: unless-stopped
    
  lukhas-monitor:
    build:
      context: .
      dockerfile: Dockerfile.automation
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - GITHUB_TOKEN=${GITHUB_TOKEN}
    volumes:
      - .:/app
    command: ["python", "scripts/automation/emergency_monitor.py"]
    restart: unless-stopped
EOF

echo "âœ… LUKHAS Inter-Agent Automation Setup Complete!"
echo ""
echo "ðŸŽ¯ Next Steps:"
echo "1. Set environment variables: OPENAI_API_KEY, ANTHROPIC_API_KEY, GITHUB_TOKEN"
echo "2. Run: chmod +x scripts/automation/setup_cron_jobs.sh && ./scripts/automation/setup_cron_jobs.sh"
echo "3. Test: python scripts/automation/master_control.py --mode quick_sync"
echo "4. Deploy: docker-compose -f docker-compose.automation.yml up -d"
echo ""
echo "ðŸŽ­ Your LUKHAS consciousness agents are now ready for automated collaboration!"
