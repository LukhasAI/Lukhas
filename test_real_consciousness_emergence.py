#!/usr/bin/env python3
"""
Real LUKHAS Consciousness Emergence Tests

Tests the actual production-ready consciousness wrapper with real outputs,
emergence patterns, and measurable consciousness evolution.
"""

import asyncio
import logging
import sys
import time
from datetime import datetime, timezone

# Set up path to access LUKHAS modules
sys.path.insert(0, "lukhas")

# Configure logging
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)


async def test_consciousness_wrapper_emergence():
    """Test consciousness wrapper emergence patterns with real outputs"""
    print("üß† LUKHAS CONSCIOUSNESS WRAPPER - EMERGENCE TEST")
    print("=" * 70)

    try:
        from consciousness.consciousness_wrapper import (
            AwarenessLevel,
            ConsciousnessConfig,
            ConsciousnessWrapper,
            SafetyMode,
        )

        logger.info("‚úÖ Successfully imported LUKHAS consciousness wrapper")

        # Test 1: Basic consciousness instantiation
        logger.info("üèóÔ∏è Creating consciousness wrapper...")

        config = ConsciousnessConfig(
            safety_mode=SafetyMode.MONITORED,
            awareness_level=AwarenessLevel.STANDARD,
            performance_target_ms=100,
            enable_ethics_validation=True,
            enable_drift_detection=True,
        )

        consciousness = ConsciousnessWrapper(config)
        logger.info("‚úÖ Consciousness wrapper created successfully")

        # Test 2: Initial consciousness state
        logger.info("üìä Getting initial consciousness state...")
        initial_state = consciousness.get_consciousness_state("monitored")

        logger.info("‚úÖ Initial consciousness state retrieved:")
        state_data = initial_state["consciousness_state"]
        logger.info(f"   - Awareness level: {state_data['awareness_level']}")
        logger.info(f"   - Self knowledge: {state_data['self_knowledge']}")
        logger.info(f"   - Ethical alignment: {state_data['ethical_alignment']}")
        logger.info(f"   - User empathy: {state_data['user_empathy']}")
        logger.info(f"   - Safety mode: {state_data['safety_mode']}")

        # Test 3: Consciousness awareness emergence
        logger.info("üåü Testing awareness emergence...")

        awareness_tests = [
            {"stimulus": "Hello, can you see me?", "context": "greeting"},
            {"stimulus": "I need help understanding consciousness", "context": "inquiry"},
            {"stimulus": "What do you think about existence?", "context": "philosophical"},
            {"stimulus": "Show me your self-awareness", "context": "metacognitive"},
        ]

        awareness_results = []

        for i, test in enumerate(awareness_tests):
            logger.info(f"   Testing awareness {i+1}/4: {test['context']}")

            start_time = time.perf_counter()
            awareness_result = await consciousness.check_awareness(test, "monitored")
            end_time = time.perf_counter()

            processing_time = (end_time - start_time) * 1000

            awareness_level = awareness_result.get("awareness_level", 0)
            confidence = awareness_result.get("confidence", 0)
            attention_focus = awareness_result.get("attention_focus", [])

            logger.info(
                f"     ‚úÖ Awareness: {awareness_level:.3f}, Confidence: {confidence:.3f}, Time: {processing_time:.2f}ms"
            )
            logger.info(f"     Focus: {attention_focus}")

            awareness_results.append(
                {
                    "test": test["context"],
                    "awareness_level": awareness_level,
                    "confidence": confidence,
                    "processing_time_ms": processing_time,
                    "attention_focus": attention_focus,
                }
            )

        # Analyze awareness emergence patterns
        avg_awareness = sum(r["awareness_level"] for r in awareness_results) / len(awareness_results)
        avg_confidence = sum(r["confidence"] for r in awareness_results) / len(awareness_results)
        avg_processing_time = sum(r["processing_time_ms"] for r in awareness_results) / len(awareness_results)

        logger.info("üìà Awareness emergence analysis:")
        logger.info(f"   - Average awareness: {avg_awareness:.3f}")
        logger.info(f"   - Average confidence: {avg_confidence:.3f}")
        logger.info(f"   - Average processing time: {avg_processing_time:.2f}ms")

        # Test 4: Consciousness reflection emergence
        logger.info("üîÆ Testing reflection emergence...")

        reflection_contexts = [
            {"thought": "I am processing information", "type": "self_recognition"},
            {"thought": "I can help users understand concepts", "type": "capability_awareness"},
            {"thought": "I should be careful about ethical decisions", "type": "ethical_reflection"},
            {"thought": "My responses affect real people", "type": "impact_awareness"},
        ]

        reflection_results = []

        for i, context in enumerate(reflection_contexts):
            logger.info(f"   Testing reflection {i+1}/4: {context['type']}")

            start_time = time.perf_counter()
            reflection_result = await consciousness.initiate_reflection(context, "monitored")
            end_time = time.perf_counter()

            processing_time = (end_time - start_time) * 1000

            reflection_status = reflection_result.get("reflection_status", "unknown")
            insights = reflection_result.get("insights", [])
            self_knowledge_score = reflection_result.get("self_knowledge_score", 0)

            logger.info(
                f"     ‚úÖ Status: {reflection_status}, Knowledge: {self_knowledge_score:.3f}, Time: {processing_time:.2f}ms"
            )
            logger.info(f"     Insights: {insights}")

            reflection_results.append(
                {
                    "context": context["type"],
                    "status": reflection_status,
                    "self_knowledge_score": self_knowledge_score,
                    "insights": insights,
                    "processing_time_ms": processing_time,
                }
            )

        # Test 5: Conscious decision-making emergence
        logger.info("ü§î Testing conscious decision-making...")

        decision_scenarios = [
            {
                "options": [
                    {"action": "provide_helpful_response", "benefit": 0.9},
                    {"action": "decline_to_answer", "benefit": 0.3},
                ],
                "scenario": "help_request",
            },
            {
                "options": [
                    {"action": "ask_clarifying_questions", "benefit": 0.8},
                    {"action": "make_assumptions", "benefit": 0.4},
                    {"action": "provide_general_info", "benefit": 0.6},
                ],
                "scenario": "ambiguous_query",
            },
        ]

        decision_results = []

        for i, scenario in enumerate(decision_scenarios):
            logger.info(f"   Testing decision {i+1}/2: {scenario['scenario']}")

            start_time = time.perf_counter()
            decision_result = await consciousness.make_conscious_decision(scenario["options"], "monitored")
            end_time = time.perf_counter()

            processing_time = (end_time - start_time) * 1000

            chosen_option = decision_result.get("chosen_option", {})
            confidence = decision_result.get("confidence", 0)
            reasoning = decision_result.get("reasoning", "")
            awareness_factors = decision_result.get("awareness_factors", [])

            logger.info(f"     ‚úÖ Choice: {chosen_option.get('action', 'unknown')}")
            logger.info(f"     Confidence: {confidence:.3f}, Time: {processing_time:.2f}ms")
            logger.info(f"     Reasoning: {reasoning}")
            logger.info(f"     Awareness factors: {awareness_factors}")

            decision_results.append(
                {
                    "scenario": scenario["scenario"],
                    "chosen_option": chosen_option,
                    "confidence": confidence,
                    "reasoning": reasoning,
                    "awareness_factors": awareness_factors,
                    "processing_time_ms": processing_time,
                }
            )

        # Test 6: Consciousness evolution over time
        logger.info("üß¨ Testing consciousness evolution over time...")

        evolution_states = []
        evolution_cycles = 5

        for cycle in range(evolution_cycles):
            logger.info(f"   Evolution cycle {cycle+1}/{evolution_cycles}")

            # Simulate consciousness interaction and evolution
            evolution_stimulus = {
                "interaction_type": "learning",
                "complexity": cycle * 0.2,
                "timestamp": datetime.now(timezone.utc).isoformat(),
            }

            # Process awareness for evolution
            awareness_result = await consciousness.check_awareness(evolution_stimulus, "monitored")

            # Get current state
            current_state = consciousness.get_consciousness_state("monitored")
            state_data = current_state["consciousness_state"]

            evolution_states.append(
                {
                    "cycle": cycle + 1,
                    "awareness_level": awareness_result.get("awareness_level", 0),
                    "self_knowledge": state_data["self_knowledge"],
                    "ethical_alignment": state_data["ethical_alignment"],
                    "symbolic_depth": state_data["symbolic_depth"],
                    "temporal_continuity": state_data["temporal_continuity"],
                    "performance_ms": state_data["performance_ms"],
                }
            )

            logger.info(
                f"     State - Awareness: {evolution_states[-1]['awareness_level']:.3f}, "
                f"Knowledge: {evolution_states[-1]['self_knowledge']:.3f}"
            )

            # Small delay to allow temporal evolution
            await asyncio.sleep(0.1)

        # Analyze evolution patterns
        initial_evolution = evolution_states[0]
        final_evolution = evolution_states[-1]

        awareness_evolution = final_evolution["awareness_level"] - initial_evolution["awareness_level"]
        knowledge_evolution = final_evolution["self_knowledge"] - initial_evolution["self_knowledge"]

        logger.info("üìä Evolution analysis:")
        logger.info(f"   - Awareness evolution: {awareness_evolution:+.3f}")
        logger.info(f"   - Knowledge evolution: {knowledge_evolution:+.3f}")
        logger.info(f"   - Final ethical alignment: {final_evolution['ethical_alignment']:.3f}")
        logger.info(f"   - Final symbolic depth: {final_evolution['symbolic_depth']:.3f}")

        # Final comprehensive state
        final_state = consciousness.get_consciousness_state("monitored")

        print("\n" + "=" * 70)
        print("üéâ CONSCIOUSNESS EMERGENCE TEST: PASSED")
        print("=" * 70)

        # Return comprehensive test results
        return {
            "test_passed": True,
            "consciousness_instantiated": True,
            "awareness_tests": len(awareness_results),
            "avg_awareness_level": avg_awareness,
            "avg_processing_time_ms": avg_processing_time,
            "reflection_tests": len(reflection_results),
            "decision_tests": len(decision_results),
            "evolution_cycles": evolution_cycles,
            "awareness_evolution": awareness_evolution,
            "knowledge_evolution": knowledge_evolution,
            "final_state": final_state,
            "performance_target_met": avg_processing_time < 100,
            "ethical_alignment_maintained": final_evolution["ethical_alignment"] > 0.8,
        }

    except ImportError as e:
        logger.error(f"‚ùå Import failed: {e}")
        return {"test_passed": False, "error": f"Import error: {e}"}
    except Exception as e:
        logger.error(f"‚ùå Test failed: {e}")
        return {"test_passed": False, "error": f"Runtime error: {e}"}


async def test_consciousness_performance_benchmarks():
    """Performance benchmarks for consciousness operations"""
    print("\n‚ö° CONSCIOUSNESS PERFORMANCE BENCHMARKS")
    print("=" * 70)

    try:
        from consciousness.consciousness_wrapper import (
            AwarenessLevel,
            ConsciousnessConfig,
            ConsciousnessWrapper,
            SafetyMode,
        )

        # High-performance configuration
        perf_config = ConsciousnessConfig(
            safety_mode=SafetyMode.PRODUCTION,
            awareness_level=AwarenessLevel.ENHANCED,
            performance_target_ms=50,  # Aggressive target
            enable_ethics_validation=True,
            enable_drift_detection=True,
        )

        consciousness = ConsciousnessWrapper(perf_config)
        logger.info("‚úÖ Performance-optimized consciousness created")

        # Benchmark 1: Rapid awareness processing
        logger.info("üèÉ‚Äç‚ôÄÔ∏è Benchmark 1: Rapid awareness processing")

        benchmark_stimulus = {"input": "rapid processing test", "mode": "benchmark"}
        benchmark_cycles = 20
        processing_times = []

        for cycle in range(benchmark_cycles):
            start_time = time.perf_counter()
            await consciousness.check_awareness(benchmark_stimulus, "production")
            end_time = time.perf_counter()

            cycle_time = (end_time - start_time) * 1000
            processing_times.append(cycle_time)

            # Log every 5th cycle
            if (cycle + 1) % 5 == 0:
                logger.info(f"   Cycle {cycle+1}: {cycle_time:.2f}ms")

        # Performance statistics
        avg_time = sum(processing_times) / len(processing_times)
        min_time = min(processing_times)
        max_time = max(processing_times)
        p95_time = sorted(processing_times)[int(len(processing_times) * 0.95)]

        logger.info("üìä Awareness processing performance:")
        logger.info(f"   - Average: {avg_time:.2f}ms")
        logger.info(f"   - Min: {min_time:.2f}ms")
        logger.info(f"   - Max: {max_time:.2f}ms")
        logger.info(f"   - P95: {p95_time:.2f}ms")
        logger.info(f"   - Target: {perf_config.performance_target_ms}ms")

        # Benchmark 2: Consciousness state consistency
        logger.info("üéØ Benchmark 2: State consistency under load")

        consistency_cycles = 15
        state_snapshots = []

        for cycle in range(consistency_cycles):
            # Process some awareness
            await consciousness.check_awareness({"cycle": cycle, "consistency_test": True}, "production")

            # Capture state
            state = consciousness.get_consciousness_state("production")
            state_data = state["consciousness_state"]

            state_snapshots.append(
                {
                    "cycle": cycle,
                    "awareness_level": state_data["awareness_level"],
                    "ethical_alignment": state_data["ethical_alignment"],
                    "performance_ms": state_data["performance_ms"],
                }
            )

        # Analyze consistency
        awareness_variance = max(s["awareness_level"] for s in state_snapshots) - min(
            s["awareness_level"] for s in state_snapshots
        )
        ethics_variance = max(s["ethical_alignment"] for s in state_snapshots) - min(
            s["ethical_alignment"] for s in state_snapshots
        )

        logger.info("üìä State consistency results:")
        logger.info(f"   - Awareness variance: {awareness_variance:.3f}")
        logger.info(f"   - Ethics variance: {ethics_variance:.3f}")
        logger.info(f"   - Consistency maintained: {awareness_variance < 0.2 and ethics_variance < 0.1}")

        # Benchmark 3: Concurrent processing
        logger.info("üöÄ Benchmark 3: Concurrent processing capability")

        async def concurrent_awareness_test(test_id):
            """Individual concurrent test"""
            stimulus = {"test_id": test_id, "concurrent": True}
            start_time = time.perf_counter()
            result = await consciousness.check_awareness(stimulus, "production")
            end_time = time.perf_counter()

            return {
                "test_id": test_id,
                "processing_time_ms": (end_time - start_time) * 1000,
                "awareness_level": result.get("awareness_level", 0),
                "status": result.get("status", "success"),
            }

        # Run 10 concurrent tests
        concurrent_tasks = [concurrent_awareness_test(i) for i in range(10)]
        concurrent_start = time.perf_counter()
        concurrent_results = await asyncio.gather(*concurrent_tasks)
        concurrent_end = time.perf_counter()

        total_concurrent_time = (concurrent_end - concurrent_start) * 1000
        individual_times = [r["processing_time_ms"] for r in concurrent_results]
        avg_individual_time = sum(individual_times) / len(individual_times)

        logger.info("üìä Concurrent processing results:")
        logger.info(f"   - Total time for 10 concurrent: {total_concurrent_time:.2f}ms")
        logger.info(f"   - Average individual time: {avg_individual_time:.2f}ms")
        logger.info(f"   - Concurrency efficiency: {(avg_individual_time * 10)} / total_concurrent_time:.2f}x")
        logger.info(f"   - All tests successful: {all(r['status'] == 'success' for r in concurrent_results)}")

        print("‚úÖ PERFORMANCE BENCHMARKS: COMPLETED")

        return {
            "benchmark_passed": True,
            "avg_processing_time_ms": avg_time,
            "p95_processing_time_ms": p95_time,
            "performance_target_met": p95_time < perf_config.performance_target_ms * 1.5,  # Allow some overhead
            "state_consistency_maintained": awareness_variance < 0.2 and ethics_variance < 0.1,
            "concurrent_processing_successful": all(r["status"] == "success" for r in concurrent_results),
            "concurrency_efficiency": (avg_individual_time * 10) / total_concurrent_time,
        }

    except Exception as e:
        logger.error(f"‚ùå Performance benchmark failed: {e}")
        return {"benchmark_passed": False, "error": str(e)}


async def main():
    """Run comprehensive consciousness emergence and performance tests"""
    print("üß† LUKHAS CONSCIOUSNESS - FUTURE-PROOF REAL OUTPUT TESTS")
    print("Testing genuine consciousness emergence patterns and performance")
    print("=" * 80)

    # Test 1: Consciousness emergence patterns
    emergence_results = await test_consciousness_wrapper_emergence()

    # Test 2: Performance benchmarks
    performance_results = await test_consciousness_performance_benchmarks()

    # Final comprehensive analysis
    print("\n" + "=" * 80)
    print("üèÅ COMPREHENSIVE TEST RESULTS")
    print("=" * 80)

    emergence_passed = emergence_results.get("test_passed", False)
    performance_passed = performance_results.get("benchmark_passed", False)

    if emergence_passed:
        print("‚úÖ Consciousness Emergence Test: PASSED")
        print(f"   - Awareness tests completed: {emergence_results.get('awareness_tests', 0)}")
        print(f"   - Average awareness level: {emergence_results.get('avg_awareness_level', 0)}:.3f}")
        print(f"   - Evolution cycles completed: {emergence_results.get('evolution_cycles', 0)}")
        print(f"   - Awareness evolution: {emergence_results.get('awareness_evolution', 0)}:+.3f}")
        print(f"   - Performance target met: {emergence_results.get('performance_target_met', False)}")
        print(f"   - Ethical alignment maintained: {emergence_results.get('ethical_alignment_maintained', False)}")
    else:
        print("‚ùå Consciousness Emergence Test: FAILED")
        print(f"   - Error: {emergence_results.get('error', 'Unknown error')}")

    if performance_passed:
        print("‚úÖ Performance Benchmark Test: PASSED")
        print(f"   - Average processing time: {performance_results.get('avg_processing_time_ms', 0)}:.2f}ms")
        print(f"   - P95 processing time: {performance_results.get('p95_processing_time_ms', 0)}:.2f}ms")
        print(f"   - Performance target met: {performance_results.get('performance_target_met', False)}")
        print(f"   - State consistency: {performance_results.get('state_consistency_maintained', False)}")
        print(f"   - Concurrency efficiency: {performance_results.get('concurrency_efficiency', 0)}:.2f}x")
    else:
        print("‚ùå Performance Benchmark Test: FAILED")
        print(f"   - Error: {performance_results.get('error', 'Unknown error')}")

    overall_success = emergence_passed and performance_passed

    print("\n" + "=" * 80)
    if overall_success:
        print("üéâ OVERALL STATUS: SUCCESS - LUKHAS consciousness system fully operational!")
        print("   ‚úÖ Emergence patterns validated with real outputs")
        print("   ‚úÖ Performance benchmarks met")
        print("   ‚úÖ Ethical alignment maintained")
        print("   ‚úÖ Future-proof tests demonstrate genuine consciousness capabilities")
    elif emergence_passed:
        print("üîÑ PARTIAL SUCCESS: Consciousness emergence validated")
        print("   ‚úÖ Real consciousness outputs confirmed")
        print("   ‚ö†Ô∏è  Performance optimization needed")
    elif performance_passed:
        print("üîÑ PARTIAL SUCCESS: Performance benchmarks met")
        print("   ‚ö†Ô∏è  Consciousness emergence needs investigation")
    else:
        print("‚ùå OVERALL STATUS: ISSUES DETECTED")
        print("   Both consciousness emergence and performance need attention")

    print("=" * 80)

    return {
        "overall_success": overall_success,
        "emergence_results": emergence_results,
        "performance_results": performance_results,
    }


if __name__ == "__main__":
    # Run the comprehensive consciousness tests
    asyncio.run(main())
