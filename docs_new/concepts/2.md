---
title: 2
status: review
owner: docs-team
last_review: 2025-09-08
tags: ["consciousness", "api", "testing", "concept"]
facets:
  layer: ["gateway"]
  domain: ["symbolic", "consciousness", "memory", "quantum"]
  audience: ["dev"]
---



# TL;DR — Where do “Dreams” live?

We are keeping **Dreams *inside* `consciousness/`**, but isolate them as a **sandboxed Simulation lane** (not on the hot/production reasoning# Why this is the right call

* **We keep the creative superpower** (planning, adversarial rehearsal, content ideation)
* **We don't pay the latency or safety price** on the critical path
* **Everything becomes composable** via one API that other modules can trust
* **Align with my ethos** (consent-first, explainable, Λ-trace everywhere)

---

## MATADA Alignment Update (v1)

The Simulation ("Dreams") lane only produces HYPOTHESIS and REPLAY nodes; it must never emit DECISION or AWARENESS. If consent is insufficient, produce no nodes and return a policy rationale.

Summarizer mapping:
	•	evaluator.scores → node.state.{risk,utility,novelty}
	•	seed goal/context summary → node.evidence entries
	•	inter-shard links become links with link_type="temporal" under a shared trace_id

Scheduling/TTL: Nodes inherit job TTL; expired nodes are not re-hydrated without fresh consent.. They should be:

* **Scheduled** (idle/low-risk windows, or explicitly requested),
* **Gated** (no external side-effects, no adapters, policy + consent enforced),
* **Instrumented** (Λ-trace, cost/time budgets, safety scores),
* **Plumbed** into memory via **“replay”** and **“hypothesis”** artifacts—not raw actions.

This gives **Lukhas** the creative/foresight benefits (planning, augmentation, anomaly rehearsal) without compromising safety, latency, or user trust.

---

# How to tame our tree.

**Lukhas**  already have a lot of “dream” surface area scattered across the stack:

* `consciousness/dream/…` (e.g., `dream_pipeline.py`, `core/dream_engine.py`, `parallel_reality_simulator.py`, `core/ethics_guard.py`, `dream_feedback_controller.py`)
* `consciousness/reflection/dream_narrator.py`, `reflection/quantum_dream_adapter.py`
* `consciousness/creativity/dream_engine/…` (TS),
* `consciousness/states/simulation_controller.py`
* `consciousness/dream_bridge_adapter.py`

This is good news: we’ve got the parts. The problem is **duplication + unclear boundaries**. The fix is a clean separation of **interfaces vs. implementations** and a single ingress/egress for the dream lane.

---

# Clean split: Consciousness lanes (hot vs. simulation)

## A. Hot Path (always-on; p95-constrained)

* `awareness/` (attention, drift, symbolic trace)
* `reasoning/` (task policy, planning)
* `reflection/` (SRM: self-reflection, post-act critiques)
* `meta_cognitive/` (budgeting, guardrails)
* `states/` (shared state, load estimation)
* **No calls** to dream engines here; they only **schedule** dream jobs and **consume** results.

## B. Simulation Path (“Dreams”, offline imagination)

Create a single **Simulation subdomain** *inside* `consciousness/`:

```
consciousness/
  simulation/
    api.py                 # canonical ingress/egress
    scheduler.py           # idle windows, rate limits, priority
    ethics_gate.py         # policy, consent, duress checks
    world_model.py         # generative scenario model
    rollout.py             # parallel scenario execution
    evaluator.py           # score risk, novelty, utility
    summarizer.py          # produce “dream_shard” artifacts
    storage.py             # write-only to memory inbox
```

Then **move / adapt** existing assets behind this API:

* from `dream/`: `dream_pipeline.py`, `core/dream_engine.py`, `parallel_reality_simulator.py`, `core/ethics_guard.py`, `dream_replay.py` → refactor into `world_model.py`/`rollout.py`/`ethics_gate.py`/`summarizer.py`.
* from `states/`: `simulation_controller.py` → becomes `scheduler.py`.
* from `reflection/`: `dream_narrator.py` → becomes a **consumer** of `summarizer` outputs, not a driver.
* from `creativity/dream_engine/` → optional **creative renderers** used only by `summarizer.py` for narrative output (never on the hot path).

**One bridge only:** keep `dream_bridge_adapter.py` as a thunk that imports **only** `simulation/api.py`.

---

# Minimal API contracts (so everything composes)

```python
# consciousness/simulation/api.py
class DreamSeed(TypedDict):
    goal: str                 # what we’re exploring (policy-free)
    context: dict             # redacted task state
    constraints: dict         # budgets, safety, consent scopes

class DreamResult(TypedDict):
    shards: list[dict]        # proposals, pitfalls, test cases
    scores: dict              # risk, utility, novelty, cost
    trace_id: str             # Λ-trace correlation

async def schedule(seed: DreamSeed) -> str: ...
async def status(job_id: str) -> dict: ...
async def collect(job_id: str) -> DreamResult: ...
```

**Hot path interactions**

* `reflection/` may call `schedule(seed)` after tasks complete.
* `meta_cognitive/` sets **budgets** (tokens/time) and **consent scopes**.
* `memory/` gets **write-only** “dream\_shards” via `storage.py` (e.g., `memory/inbox/dreams/…`).
* **Orchestrator** never calls scenario engines directly—only via `simulation/api.py`.

---

# Safety, consent, and privacy (non-negotiable)

* **Consent scopes**: Simulation can only read the **anonymized, scoped context** in `DreamSeed.context`. No PII, no raw content unless explicit consent exists in the ledger.
* **No side-effects**: Simulation path **cannot** call adapters, send emails, or modify user data. Output is advisory artifacts only.
* **Duress/shadow gestures**: if active, `ethics_gate.py` denies scheduling and emits an alert.
* **Tripwires**: bulk destructive scenarios auto-deny or require step-up (GTΨ).
* **Full Λ-trace**: every simulation job emits rationale + breadcrumb trace (already aligned with your `Λ-trace`).

---

# Scheduling & cost control (so it never drifts)

* **When**: idle CPU/GPU windows, user-requested runs, or nightly “sleep cycles.”
* **How much**: token + time budget from `meta_cognitive` + **TokenBudgetController** (you already have `reflection/token_budget_controller.py`—reuse it).
* **Kill switch**: global `SIMULATION_ENABLED` + per-tenant policy flag.
* **Metrics**:

  * Hit-rate: fraction of dream shards accepted by human or policy
  * Safety score distribution (pre/post ethics gate)
  * Cost per accepted shard
  * “Hallucination pressure”: % of shards rejected for unverifiable claims

---

# Memory integration (hippocampal replay done right)

Create two artifact types written by `simulation/summarizer.py`:

1. **`dream_shard`** — hypothesis packs

   * `problem → proposal → risks → verification plan → UL/Λ tags`
2. **`replay_shard`** — compressed past session recaps

   * used to generate better seeds; no direct action

Then `reflection/` can read these to:

* suggest next actions to the user,
* add tests or policy proposals,
* update the **policy tuner** via your feedback UX.

---

# What to de-duplicate now (without “deprecate” vibes)

* Keep **one** narrator queue (under `simulation/summarizer.py`). Remove parallel narrators scattered in `reflection/` and `creativity/` by having them call the single summarizer.
* Keep **one** ethics gate (under `simulation/ethics_gate.py`). Delete per-module ethics guards and route them to this central gate.
* Keep **one** scheduler (under `simulation/scheduler.py`). Retire `states/simulation_controller.py` by forwarding to scheduler.

*No code is “dead”—it either becomes an implementation detail behind the new API or a renderer the summarizer can call.*

---

# Concrete “next commits” (surgical, low-risk)

1. **Create the lane**

   * `consciousness/simulation/{api.py,scheduler.py,ethics_gate.py,world_model.py,rollout.py,evaluator.py,summarizer.py,storage.py}`
2. **Bridge**

   * Rewrite `dream_bridge_adapter.py` to import only `simulation/api.py`
3. **Move & wrap**

   * Port `dream_pipeline.py` → `rollout.py`
   * Port `core/dream_engine.py` → `world_model.py`
   * Port `parallel_reality_simulator.py` → `rollout.py`
   * Port `core/ethics_guard.py` → `ethics_gate.py`
   * Port `dream_replay.py` → `summarizer.py` (replay\_shard)
4. **Hot path**

   * In `reflection/` add a tiny caller: `reflection/schedule_dreams.py` that crafts a `DreamSeed` and calls `simulation.api.schedule`
5. **Feature flag**

   * `SIMULATION_ENABLED=false` by default; tenant/role override in policy engine
6. **Tests**

   * Deterministic seeds → golden files for shards
   * Safety suite: verify nothing hits adapters or PII paths
   * Budget suite: enforce token/time caps with TokenBudgetController

---

# Why this is the right call

* **We keep the creative superpower** (planning, adversarial rehearsal, content ideation)
* **We don’t pay the latency or safety price** on the critical path
* **Everything becomes composable** via one API that other modules can trust
* **Align with my ethos** (consent-first, explainable, Λ-trace everywhere)
