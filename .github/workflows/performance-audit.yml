# T4/0.01% Excellence Performance Audit Pipeline
# Independent validation in CI environment

name: Performance Audit

on:
  workflow_dispatch:
    inputs:
      audit_id:
        description: 'Audit Run ID'
        required: true
        type: string
      baseline_hash:
        description: 'Baseline Git Hash'
        required: true
        type: string

  schedule:
    # Run nightly audit at 02:00 UTC
    - cron: '0 2 * * *'

  push:
    branches: [main]
    paths:
      - 'governance/**'
      - 'memory/**'
      - 'ai_orchestration/**'
      - 'scripts/bench_*.py'

env:
  PYTHONHASHSEED: 0
  LUKHAS_MODE: release
  PYTHONDONTWRITEBYTECODE: 1

jobs:
  performance-audit:
    name: T4/0.01% Performance Audit
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9.6'
        cache: 'pip'

    - name: Install dependencies
      run: |
        pip install --upgrade pip
        pip install psutil numpy hypothesis pytest-benchmark
        pip install -r requirements.txt

    - name: Capture CI environment
      run: |
        echo "üîß CI Environment Capture"
        cat > ci_environment.json << EOF
        {
          "audit_id": "${{ github.event.inputs.audit_id || github.run_id }}",
          "run_id": "${{ github.run_id }}",
          "run_number": "${{ github.run_number }}",
          "run_attempt": "${{ github.run_attempt }}",
          "actor": "${{ github.actor }}",
          "ref": "${{ github.ref }}",
          "sha": "${{ github.sha }}",
          "baseline_hash": "${{ github.event.inputs.baseline_hash || github.sha }}",
          "runner_os": "${{ runner.os }}",
          "runner_arch": "${{ runner.arch }}",
          "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
          "python_version": "$(python --version)",
          "cpu_count": "$(nproc)",
          "memory_gb": "$(free -g | awk '/^Mem:/{print \$2}')"
        }
        EOF

    - name: Run performance audit
      id: audit
      run: |
        echo "üöÄ Starting T4/0.01% Performance Audit"

        # Set audit environment
        export AUDIT_RUN_ID="${{ github.event.inputs.audit_id || github.run_id }}"
        export CI_AUDIT=true

        # Create artifacts directory
        mkdir -p artifacts

        # Run simplified performance audit for CI
        python3 -c "
        import sys, os, time, json, statistics
        sys.path.insert(0, '.')

        def percentile(data, p):
            if not data: return 0.0
            sorted_data = sorted(data)
            n = len(sorted_data)
            idx = p * (n - 1)
            lower = int(idx)
            upper = min(lower + 1, n - 1)
            weight = idx - lower
            return sorted_data[lower] * (1 - weight) + sorted_data[upper] * weight

        def benchmark_ci(func, name, samples=1000):
            print(f'üî¨ CI Benchmark: {name}')

            # Warmup
            for _ in range(50):
                func()

            # Collect
            times = []
            for i in range(samples):
                t0 = time.perf_counter_ns()
                func()
                t1 = time.perf_counter_ns()
                times.append((t1 - t0) / 1000)  # Œºs

            result = {
                'name': name,
                'samples': samples,
                'p50': percentile(times, 0.50),
                'p95': percentile(times, 0.95),
                'p99': percentile(times, 0.99),
                'mean': statistics.mean(times),
                'cv': statistics.stdev(times) / statistics.mean(times) * 100 if statistics.mean(times) > 0 else 0
            }

            print(f'  p50={result[\"p50\"]:.2f}Œºs, p95={result[\"p95\"]:.2f}Œºs, CV={result[\"cv\"]:.1f}%')
            return result

        # Import components
        try:
            from governance.guardian_system import GuardianSystem
            from memory.memory_event import MemoryEventFactory

            guardian = GuardianSystem()
            memory_factory = MemoryEventFactory()

            results = {}

            # Run benchmarks
            results['guardian_ci'] = benchmark_ci(
                lambda: guardian.validate_safety({'ci_test': True}),
                'Guardian CI'
            )

            results['memory_ci'] = benchmark_ci(
                lambda: memory_factory.create({'ci_test': True}, {'affect_delta': 0.5}),
                'Memory CI'
            )

            # Save results
            audit_data = {
                'audit_id': os.environ.get('AUDIT_RUN_ID', 'unknown'),
                'environment': 'ci',
                'timestamp': time.strftime('%Y-%m-%dT%H:%M:%SZ', time.gmtime()),
                'results': results
            }

            with open('artifacts/audit_ci_results.json', 'w') as f:
                json.dump(audit_data, f, indent=2)

            # Check SLA compliance
            guardian_sla = results['guardian_ci']['p95'] < 100000  # 100ms
            memory_sla = results['memory_ci']['p95'] < 1000      # 1ms

            print(f'\\nüìä CI Audit Results:')
            print(f'  Guardian p95: {results[\"guardian_ci\"][\"p95\"]:.2f}Œºs (SLA: <100ms) {\"‚úÖ\" if guardian_sla else \"‚ùå\"}')
            print(f'  Memory p95: {results[\"memory_ci\"][\"p95\"]:.2f}Œºs (SLA: <1ms) {\"‚úÖ\" if memory_sla else \"‚ùå\"}')

            if guardian_sla and memory_sla:
                print('\\nüéâ CI Audit: All SLAs passed!')
                sys.exit(0)
            else:
                print('\\n‚ö†Ô∏è  CI Audit: Some SLAs failed!')
                sys.exit(1)

        except Exception as e:
            print(f'‚ùå CI Audit failed: {e}')
            sys.exit(1)
        "

    - name: Verify audit results
      run: |
        echo "üîç Verifying CI Audit Results"

        if [ -f "artifacts/audit_ci_results.json" ]; then
          echo "‚úÖ Audit results file exists"

          # Extract key metrics
          guardian_p95=$(jq -r '.results.guardian_ci.p95' artifacts/audit_ci_results.json)
          memory_p95=$(jq -r '.results.memory_ci.p95' artifacts/audit_ci_results.json)

          echo "üìä CI Results Summary:"
          echo "  Guardian p95: ${guardian_p95}Œºs"
          echo "  Memory p95: ${memory_p95}Œºs"

          # Set outputs for downstream jobs
          echo "guardian_p95=${guardian_p95}" >> $GITHUB_OUTPUT
          echo "memory_p95=${memory_p95}" >> $GITHUB_OUTPUT

        else
          echo "‚ùå Audit results file missing"
          exit 1
        fi

    - name: Upload audit artifacts
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: performance-audit-${{ github.run_id }}
        path: |
          artifacts/
          ci_environment.json
        retention-days: 30

    - name: Comment PR with results
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          const results = JSON.parse(fs.readFileSync('artifacts/audit_ci_results.json', 'utf8'));

          const guardian = results.results.guardian_ci;
          const memory = results.results.memory_ci;

          const guardianStatus = guardian.p95 < 100000 ? '‚úÖ' : '‚ùå';
          const memoryStatus = memory.p95 < 1000 ? '‚úÖ' : '‚ùå';

          const body = `## üî¨ T4/0.01% Performance Audit Results

          | Component | p95 Latency | SLA | Status |
          |-----------|-------------|-----|---------|
          | Guardian | ${guardian.p95.toFixed(2)}Œºs | <100ms | ${guardianStatus} |
          | Memory | ${memory.p95.toFixed(2)}Œºs | <1ms | ${memoryStatus} |

          **Audit ID:** ${results.audit_id}
          **Environment:** CI (${process.env.RUNNER_OS})
          **Samples:** ${guardian.samples} per component

          ${guardianStatus === '‚úÖ' && memoryStatus === '‚úÖ' ?
            'üéâ **All performance SLAs passed!**' :
            '‚ö†Ô∏è **Some SLAs failed - review performance impact**'}
          `;

          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: body
          });

  audit-summary:
    name: Audit Summary
    runs-on: ubuntu-latest
    needs: performance-audit
    if: always()

    steps:
    - name: Download audit artifacts
      uses: actions/download-artifact@v3
      with:
        name: performance-audit-${{ github.run_id }}
        path: audit-results/

    - name: Generate audit summary
      run: |
        echo "üìä T4/0.01% Excellence Audit Summary"
        echo "=================================="
        echo "Run ID: ${{ github.run_id }}"
        echo "Audit ID: ${{ github.event.inputs.audit_id || github.run_id }}"
        echo "Timestamp: $(date -u +%Y-%m-%dT%H:%M:%SZ)"
        echo ""

        if [ -f "audit-results/audit_ci_results.json" ]; then
          echo "üìà Performance Results:"
          jq -r '
            "  Guardian p95: " + (.results.guardian_ci.p95 | tostring) + "Œºs (CV: " + (.results.guardian_ci.cv | tostring | .[0:4]) + "%)" +
            "\n  Memory p95: " + (.results.memory_ci.p95 | tostring) + "Œºs (CV: " + (.results.memory_ci.cv | tostring | .[0:4]) + "%)"
          ' audit-results/audit_ci_results.json

          echo ""
          echo "üéØ SLA Compliance:"
          guardian_sla=$(jq -r 'if .results.guardian_ci.p95 < 100000 then "‚úÖ PASS" else "‚ùå FAIL" end' audit-results/audit_ci_results.json)
          memory_sla=$(jq -r 'if .results.memory_ci.p95 < 1000 then "‚úÖ PASS" else "‚ùå FAIL" end' audit-results/audit_ci_results.json)

          echo "  Guardian (<100ms): $guardian_sla"
          echo "  Memory (<1ms): $memory_sla"

          if [[ "$guardian_sla" == *"PASS"* && "$memory_sla" == *"PASS"* ]]; then
            echo ""
            echo "üèÜ OVERALL RESULT: T4/0.01% EXCELLENCE MAINTAINED"
          else
            echo ""
            echo "‚ö†Ô∏è  OVERALL RESULT: PERFORMANCE REGRESSION DETECTED"
          fi
        else
          echo "‚ùå No audit results found"
        fi