# T4/0.01% Excellence Pipeline
# Comprehensive CI/CD with performance gates and quality enforcement

name: T4 Excellence Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

env:
  PYTHON_VERSION: "3.11"
  NODE_VERSION: "18"

jobs:
  # Gate 1: Unit Tests with Performance Requirements
  unit_tests:
    name: Unit Tests (<100ms avg)
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
    - uses: actions/checkout@692973e3d937129bcbf40652eb9f2f61becf3332  # v4

    - name: Setup Python
      uses: actions/setup-python@65d7f2d534ac1bc67fcd62888c5f4f3d2cb2b236  # v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'

    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install pytest pytest-benchmark pytest-cov pytest-xdist

    - name: Run unit tests with performance gates
      run: |
        pytest tests/unit/ \
          --benchmark-only \
          --benchmark-max-time=0.1 \
          --cov=. \
          --cov-report=xml \
          --cov-fail-under=85 \
          -n auto

    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml

  # Gate 2: Integration Tests with System-Level Performance
  integration_tests:
    name: Integration Tests (<250ms SLA)
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: unit_tests

    services:
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
    - uses: actions/checkout@692973e3d937129bcbf40652eb9f2f61becf3332  # v4

    - name: Setup Python
      uses: actions/setup-python@65d7f2d534ac1bc67fcd62888c5f4f3d2cb2b236  # v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install pytest-asyncio pytest-timeout

    - name: Run integration tests with SLA validation
      env:
        REDIS_URL: redis://localhost:6379
        PERFORMANCE_SLA_MS: 250
      run: |
        pytest tests/integration/ \
          --timeout=30 \
          --capture=no \
          -v

  # Gate 3: Property Tests with Chaos Engineering
  property_tests:
    name: Property Tests + Chaos
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs: unit_tests

    steps:
    - uses: actions/checkout@692973e3d937129bcbf40652eb9f2f61becf3332  # v4

    - name: Setup Python
      uses: actions/setup-python@65d7f2d534ac1bc67fcd62888c5f4f3d2cb2b236  # v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install hypothesis pytest-randomly pytest-repeat

    - name: Run property-based tests
      run: |
        pytest tests/unit/ \
          -m "property" \
          --hypothesis-show-statistics \
          --randomly-seed=12345

    - name: Run chaos engineering tests
      run: |
        pytest tests/unit/ \
          -m "chaos" \
          --repeat-count=5 \
          -v

  # Gate 4: Security Scanning
  security_scan:
    name: Security Scanning
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
    - uses: actions/checkout@692973e3d937129bcbf40652eb9f2f61becf3332  # v4

    - name: Setup Python
      uses: actions/setup-python@65d7f2d534ac1bc67fcd62888c5f4f3d2cb2b236  # v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install security tools
      run: |
        pip install bandit safety semgrep
        pip install -r requirements.txt

    - name: Run Bandit security linting
      run: |
        bandit -r . -f json -o bandit-report.json
        bandit -r . --severity-level medium

    - name: Check dependencies for vulnerabilities
      run: |
        safety check --json --output safety-report.json
        safety check

    - name: Run Semgrep security analysis
      run: |
        semgrep --config=auto --json --output=semgrep-report.json .
        semgrep --config=auto --error .

    - name: Upload security reports
      if: always()
      uses: actions/upload-artifact@a8a3f3ad30e3422c9c7b888a15615d19a852ae32  # v3
      with:
        name: security-reports
        path: |
          bandit-report.json
          safety-report.json
          semgrep-report.json

  # Gate 5: Performance & Load Testing
  performance_tests:
    name: Performance & Load Tests
    runs-on: ubuntu-latest
    timeout-minutes: 25
    needs: [unit_tests, integration_tests]

    steps:
    - uses: actions/checkout@692973e3d937129bcbf40652eb9f2f61becf3332  # v4

    - name: Setup Python
      uses: actions/setup-python@65d7f2d534ac1bc67fcd62888c5f4f3d2cb2b236  # v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install pytest-benchmark locust

    - name: Run performance benchmarks
      run: |
        pytest tests/unit/ \
          -m "performance" \
          --benchmark-json=benchmark-results.json

    - name: Run load tests
      run: |
        pytest tests/unit/ \
          -m "load" \
          --capture=no

    - name: Validate performance SLAs
      run: |
        python scripts/validate_performance_slas.py benchmark-results.json

  # Observability & Metrics Collection
  observability:
    name: Observability Setup
    runs-on: ubuntu-latest
    needs: [unit_tests, integration_tests, property_tests]

    steps:
    - uses: actions/checkout@692973e3d937129bcbf40652eb9f2f61becf3332  # v4

    - name: Setup monitoring stack
      run: |
        docker-compose -f docker/monitoring-stack.yml up -d
        sleep 30

    - name: Test metrics endpoints
      run: |
        curl -f http://localhost:8080/metrics || exit 1
        curl -f http://localhost:9090/api/v1/query?query=up || exit 1

    - name: Validate Grafana dashboards
      run: |
        python scripts/validate_dashboards.py

    - name: Cleanup
      if: always()
      run: |
        docker-compose -f docker/monitoring-stack.yml down

  # Final Quality Gate
  quality_gate:
    name: T4 Quality Gate
    runs-on: ubuntu-latest
    needs: [unit_tests, integration_tests, property_tests, security_scan, performance_tests]
    if: always()

    steps:
    - name: Check all gates passed
      run: |
        if [[ "${{ needs.unit_tests.result }}" != "success" ]]; then
          echo "❌ Unit tests failed"
          exit 1
        fi
        if [[ "${{ needs.integration_tests.result }}" != "success" ]]; then
          echo "❌ Integration tests failed"
          exit 1
        fi
        if [[ "${{ needs.property_tests.result }}" != "success" ]]; then
          echo "❌ Property tests failed"
          exit 1
        fi
        if [[ "${{ needs.security_scan.result }}" != "success" ]]; then
          echo "❌ Security scan failed"
          exit 1
        fi
        if [[ "${{ needs.performance_tests.result }}" != "success" ]]; then
          echo "❌ Performance tests failed"
          exit 1
        fi
        echo "✅ All T4/0.01% Excellence gates passed"