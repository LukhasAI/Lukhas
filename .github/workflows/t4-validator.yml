name: T4 Unified Platform Validator

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:

jobs:
  t4-validate:
    name: T4 Quality Validation
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for git blame integration
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install ruff
      
      - name: Run T4 Unified Validator
        id: validate
        run: |
          python tools/ci/check_t4_issues.py \
            --paths lukhas core api consciousness memory identity MATRIZ \
            --output reports/t4_validation_results.json
        continue-on-error: true
      
      - name: Parse validation results
        id: results
        run: |
          TOTAL=$(jq -r '.summary.total_findings' reports/t4_validation_results.json)
          QUALITY=$(jq -r '.metrics.annotation_quality_score' reports/t4_validation_results.json)
          ANNOTATED=$(jq -r '.summary.annotated' reports/t4_validation_results.json)
          UNANNOTATED=$(jq -r '.summary.unannotated' reports/t4_validation_results.json)
          
          echo "total_violations=$TOTAL" >> $GITHUB_OUTPUT
          echo "quality_score=$QUALITY" >> $GITHUB_OUTPUT
          echo "annotated=$ANNOTATED" >> $GITHUB_OUTPUT
          echo "unannotated=$UNANNOTATED" >> $GITHUB_OUTPUT
          
          # Set status
          if [ "$UNANNOTATED" -gt 50 ]; then
            echo "status=âŒ CRITICAL" >> $GITHUB_OUTPUT
            exit 1
          elif [ "$UNANNOTATED" -gt 0 ]; then
            echo "status=âš ï¸ WARNING" >> $GITHUB_OUTPUT
          else
            echo "status=âœ… PASSING" >> $GITHUB_OUTPUT
          fi
      
      - name: Generate T4 Dashboard
        if: always()
        run: |
          python tools/ci/t4_dashboard.py \
            --output reports/t4_dashboard.html \
            --history reports/t4_metrics_history.json
      
      - name: Upload T4 Dashboard
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: t4-dashboard
          path: reports/t4_dashboard.html
          retention-days: 30
      
      - name: Upload T4 Validation Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: t4-validation-results
          path: reports/t4_validation_results.json
          retention-days: 30
      
      - name: Comment PR with T4 Results
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const results = JSON.parse(fs.readFileSync('reports/t4_validation_results.json', 'utf8'));
            
            const body = `## ðŸ›¡ï¸ T4 Unified Platform Validation
            
            **Status**: ${{ steps.results.outputs.status }}
            
            ### ðŸ“Š Metrics
            - **Total Violations**: ${results.summary.total_findings}
            - **Annotated**: ${results.summary.annotated}
            - **Unannotated**: ${results.summary.unannotated}
            - **Quality Score**: ${results.metrics.annotation_quality_score}%
            
            ### ðŸ” Top Violation Codes
            ${Object.entries(results.metrics.counts_by_code)
              .sort((a, b) => b[1] - a[1])
              .slice(0, 5)
              .map(([code, count]) => `- **${code}**: ${count}`)
              .join('\n')}
            
            ### ðŸ“ˆ Dashboard
            View the [T4 Dashboard artifact](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}) for detailed visualizations.
            
            ---
            *Generated by T4 Unified Platform v2.0*`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            });
      
      - name: Check quality threshold
        if: always()
        run: |
          QUALITY=${{ steps.results.outputs.quality_score }}
          THRESHOLD=$(python -c "import tomllib; print(tomllib.load(open('pyproject.toml', 'rb'))['tool']['t4']['quality_threshold'])")
          
          echo "Quality Score: $QUALITY%"
          echo "Threshold: $THRESHOLD%"
          
          if (( $(echo "$QUALITY < $THRESHOLD" | bc -l) )); then
            echo "âŒ Quality score below threshold!"
            exit 1
          else
            echo "âœ… Quality score meets threshold"
          fi
