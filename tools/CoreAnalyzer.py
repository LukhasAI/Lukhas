#!/usr/bin/env python3
"""
lukhas Core Analyzer: Identify actual lukhas AI components vs external packages
Recognizes legitimate lukhas functionality vs third-party libraries.
"""

import os
import re
from collections import defaultdict
from datetime import datetime


class CoreAnalyzer:
    def __init__(self, workspace_path: str):
        self.workspace_path = workspace_path
        self.Î›_path = os.path.join(workspace_path, "lukhas")
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # Define Î› AI keywords that indicate legitimate core functionality
        self.Î›_keywords = {
            "core_agi": [
                "lukhas",
                "lukhas",
                "ai",
                "symbolic",
                "neural",
                "adaptive",
                "cognitive",
            ],
            "memory_system": ["memory", "memoria", "fold", "dreams", "consciousness"],
            "architecture": ["mapper", "nodes", "orchestrator", "brain", "enhancement"],
            "functions": [
                "web_formatter",
                "widgets",
                "interface",
                "modulation",
                "guardian",
            ],
            "ai_concepts": [
                "learning",
                "intelligence",
                "reasoning",
                "ethics",
                "quantum",
            ],
        }

        # External packages to exclude
        self.external_packages = {
            "video_gen": ["open-sora", "hunyuanvideo", "sora", "video"],
            "audio_ml": ["tts", "whisper", "bark", "tortoise", "vits"],
            "general_ml": ["torch", "tensorflow", "numpy", "sklearn"],
            "web_deps": ["node_modules", "package-lock", "yarn.lock"],
        }

        self.analysis = {
            "core_agi_files": [],
            "legitimate_components": [],
            "external_packages": [],
            "questionable_files": [],
            "stats": {
                "total_files": 0,
                "core_agi_count": 0,
                "external_count": 0,
                "questionable_count": 0,
            },
        }

    def analyze_lukhas_structure(self):
        """Analyze what's actually Î› AI vs external packages"""
        if not os.path.exists(self.Î›_path):
            print("âŒ ERROR: lukhas/ directory not found")
            return

        print("ðŸ” Analyzing Î› AI components vs external packages...")

        for root, dirs, files in os.walk(self.Î›_path):
            # Skip hidden directories
            dirs[:] = [d for d in dirs if not d.startswith(".")]

            for file in files:
                if file.startswith("."):
                    continue

                file_path = os.path.join(root, file)
                rel_path = os.path.relpath(file_path, self.lukhas_path)

                self.analysis["stats"]["total_files"] += 1
                self._categorize_file(file_path, rel_path)

    def _categorize_file(self, file_path: str, rel_path: str):
        """Categorize file as core AI, legitimate component, or external"""
        file_name = os.path.basename(file_path)
        dir_path = os.path.dirname(rel_path)

        # Check file content if it's a Python file
        content_analysis = ""
        if file_name.endswith(".py"):
            content_analysis = self._analyze_python_content(file_path)

        # Determine category
        category = self._determine_category(file_name, rel_path, content_analysis)

        file_info = {
            "path": rel_path,
            "file": file_name,
            "directory": dir_path,
            "size": os.path.getsize(file_path),
            "content_hints": content_analysis,
        }

        if category == "core_agi":
            self.analysis["core_agi_files"].append(file_info)
            self.analysis["stats"]["core_agi_count"] += 1
        elif category == "legitimate":
            self.analysis["legitimate_components"].append(file_info)
        elif category == "external":
            self.analysis["external_packages"].append(file_info)
            self.analysis["stats"]["external_count"] += 1
        else:
            self.analysis["questionable_files"].append(file_info)
            self.analysis["stats"]["questionable_count"] += 1

    def _analyze_python_content(self, file_path: str) -> str:
        """Analyze Python file content for lukhas indicators"""
        try:
            with open(file_path, encoding="utf-8") as f:
                content = f.read()[:2000]  # First 2KB

            hints = []
            content_lower = content.lower()

            # Check for lukhas AI concepts
            for category, keywords in self.lukhas_keywords.items():
                found_keywords = [kw for kw in keywords if kw in content_lower]
                if found_keywords:
                    hints.append(f"{category}: {', '.join(found_keywords)}")

            # Check for class/function names
            classes = re.findall(r"class\s+(\w+)", content)
            functions = re.findall(r"def\s+(\w+)", content)

            if classes:
                hints.append(f"classes: {', '.join(classes[:3])}")
            if functions:
                hints.append(f"functions: {', '.join(functions[:3])}")

            return "; ".join(hints) if hints else ""

        except Exception:
            return ""

    def _determine_category(self, file_name: str, rel_path: str, content_analysis: str) -> str:
        """Determine if file is core AI, legitimate, external, or questionable"""
        file_lower = file_name.lower()
        path_lower = rel_path.lower()
        content_lower = content_analysis.lower()

        # Core AI indicators
        core_indicators = [
            any(kw in file_lower for kw in ["lukhas", "lukhas", "ai"]),
            any(kw in path_lower for kw in ["lukhas", "lukhas", "ai", "symbolic", "neural"]),
            any(kw in content_lower for kw in ["lukhas", "lukhas", "ai"]),
            "web_formatter" in file_lower,  # User mentioned this specifically
            "widgets" in file_lower,  # User mentioned this specifically
        ]

        if any(core_indicators):
            return "core_agi"

        # Legitimate lukhas components
        legitimate_indicators = [
            any(kw in file_lower for kw in ["memory", "memoria", "fold", "dreams", "mapper", "nodes"]),
            any(kw in path_lower for kw in ["memory", "dreams", "brain", "cognitive", "intelligence"]),
            any(kw in content_lower for kw in ["memory", "dreams", "cognitive", "intelligence"]),
            "guardian" in file_lower or "guardian" in path_lower,
            "enhancement" in file_lower or "enhancement" in path_lower,
        ]

        if any(legitimate_indicators):
            return "legitimate"

        # External package indicators
        external_indicators = [
            any(pkg in path_lower for pkg_list in self.external_packages.values() for pkg in pkg_list),
            file_name in ["requirements.txt", "package.json", "setup.py", "Dockerfile"],
            ".git" in path_lower or "node_modules" in path_lower,
            path_lower.startswith("external/"),
            "main" in file_lower and any(pkg in path_lower for pkg in ["sora", "tts", "whisper"]),
        ]

        if any(external_indicators):
            return "external"

        return "questionable"

    def generate_analysis_report(self):
        """Generate comprehensive analysis report"""
        report_path = f"{self.workspace_path}/lukhas_CORE_ANALYSIS_{self.timestamp}.md"

        with open(report_path, "w") as f:
            f.write("# lukhas Core AI Analysis Report\n")
            f.write(f"**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("**Purpose:** Identify actual lukhas AI components vs external packages\n\n")

            # Executive Summary
            f.write("## ðŸ“Š Executive Summary\n\n")
            total = self.analysis["stats"]["total_files"]
            core = self.analysis["stats"]["core_agi_count"]
            external = self.analysis["stats"]["external_count"]
            questionable = self.analysis["stats"]["questionable_count"]
            legitimate = len(self.analysis["legitimate_components"])

            f.write(f"- **Total Files Analyzed:** {total}\n")
            f.write(f"- **Core AI Components:** {core} ({core / total * 100:.1f}%)\n")
            f.write(f"- **Legitimate lukhas Components:** {legitimate} ({legitimate / total * 100:.1f}%)\n")
            f.write(f"- **External Packages:** {external} ({external / total * 100:.1f}%)\n")
            f.write(f"- **Questionable/Unknown:** {questionable} ({questionable / total * 100:.1f}%)\n\n")

            actual_lukhas = core + legitimate
            f.write(f"### **Actual lukhas System: {actual_lukhas} files ({actual_lukhas / total * 100:.1f}%)**\n\n")

            # Core AI Files
            if self.analysis["core_agi_files"]:
                f.write("## ðŸ§  Core AI Components\n\n")
                f.write(f"**Count:** {len(self.analysis['core_agi_files'])}\n\n")

                for i, file_info in enumerate(self.analysis["core_agi_files"][:20], 1):
                    f.write(f"### {i}. `{file_info['file']}`\n")
                    f.write(f"- **Path:** `{file_info['path']}`\n")
                    f.write(f"- **Size:** {file_info['size']} bytes\n")
                    if file_info["content_hints"]:
                        f.write(f"- **Contains:** {file_info['content_hints']}\n")
                    f.write("\n")

                if len(self.analysis["core_agi_files"]) > 20:
                    f.write(f"*... and {len(self.analysis['core_agi_files']) - 20} more core AI files*\n\n")

            # Legitimate Components
            if self.analysis["legitimate_components"]:
                f.write("## âš™ï¸ Legitimate lukhas Components\n\n")
                f.write(f"**Count:** {len(self.analysis['legitimate_components'])}\n\n")

                # Group by category
                by_category = defaultdict(list)
                for file_info in self.analysis["legitimate_components"]:
                    category = file_info["path"].split("/")[0] if "/" in file_info["path"] else "root"
                    by_category[category].append(file_info)

                for category, files in by_category.items():
                    f.write(f"### {category}\n")
                    for file_info in files[:5]:
                        f.write(f"- `{file_info['file']}` ({file_info['size']} bytes)\n")
                    if len(files) > 5:
                        f.write(f"  *... and {len(files) - 5} more files*\n")
                    f.write("\n")

            # External Packages (top offenders)
            if self.analysis["external_packages"]:
                f.write("## ðŸ“¦ External Packages (Should be moved out)\n\n")
                f.write(f"**Count:** {len(self.analysis['external_packages'])}\n\n")

                # Group by directory
                by_dir = defaultdict(list)
                for file_info in self.analysis["external_packages"]:
                    main_dir = file_info["path"].split("/")[0] if "/" in file_info["path"] else "root"
                    by_dir[main_dir].append(file_info)

                # Sort by file count
                sorted_dirs = sorted(by_dir.items(), key=lambda x: len(x[1]), reverse=True)

                for dir_name, files in sorted_dirs[:10]:
                    total_size = sum(f["size"] for f in files)
                    f.write(f"### {dir_name} ({len(files)} files, {total_size / 1024:.1f} KB)\n")
                    f.write("**Recommendation:** Move to workspace dependencies or external/\n\n")

            # Action Plan
            f.write("## ðŸŽ¯ Recommended Actions\n\n")
            f.write("### 1. Keep Core AI System\n")
            f.write(f"- **{core} core AI files** - These are your Î› AI system\n")
            f.write(f"- **{legitimate} legitimate components ** - Memory, dreams, mappers, etc.\n")
            f.write(f"- **Total Î› system: {actual_lukhas} files**\n\n")

            f.write("### 2. Move External Packages\n")
            f.write(f"- **{external} external files** should be moved to workspace dependencies\n")
            f.write("- Create `external_dependencies/` or `third_party/` directory\n")
            f.write("- Update import paths and requirements\n\n")

            f.write("### 3. Review Questionable Files\n")
            f.write(f"- **{questionable} questionable files** need manual review\n")
            f.write("- Determine if they're part of lukhas AI or external dependencies\n\n")

            # Final Assessment
            f.write("## âœ… Final Assessment\n\n")
            if actual_lukhas < 500:
                f.write(f"ðŸŽ‰ **EXCELLENT** - Your actual Î› AI system is {actual_lukhas} files\n")
                f.write("ðŸ“¦ The extra files are external packages that can be moved out\n")
                f.write("ðŸ§  You have a clean, focused AI system ready for development\n")
            else:
                f.write(f"âš ï¸ **REVIEW NEEDED** - {actual_lukhas} files seems high for core AI\n")
                f.write("ðŸ” Consider further modularization of legitimate components\n")

        return report_path


def main():
    workspace_path = "/Users/A_G_I/CodexGPT_Lukhas"

    print("ðŸš€ lukhas Core AI Analysis")
    print("ðŸŽ¯ Identifying actual lukhas components vs external packages")

    analyzer = lukhasCoreAnalyzer(workspace_path)
    analyzer.analyze_lukhas_structure()
    report_path = analyzer.generate_analysis_report()

    stats = analyzer.analysis["stats"]
    legitimate = len(analyzer.analysis["legitimate_components"])
    actual_lukhas = stats["core_agi_count"] + legitimate

    print("\nâœ… Analysis complete!")
    print(f"ðŸ“‹ Report: {report_path}")
    print(f"ðŸ§  Actual Î› AI system: {actual_lukhas} files")
    print(f"ðŸ“¦ External packages: {stats['external_count']} files")
    print(f"â“ Need review: {stats['questionable_count']} files")

    if actual_lukhas < 500:
        print("ðŸŽ‰ Your lukhas AI system is appropriately sized!")
    else:
        print("âš ï¸ Consider further modularization")


if __name__ == "__main__":
    main()

# Î› Systems 2025 www.lukhas.ai
