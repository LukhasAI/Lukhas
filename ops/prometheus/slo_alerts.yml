groups:
- name: lukhas_slo_recording_rules
  interval: 30s
  rules:
  # Recording rules for SLI calculations
  - record: lukhas:api_availability_rate5m
    expr: |
      sum(rate(http_requests_total{status!~"5.."}[5m])) /
      sum(rate(http_requests_total[5m]))

  - record: lukhas:memory_latency_p95_5m
    expr: |
      histogram_quantile(0.95,
        sum(rate(lukhas_memory_recall_duration_seconds_bucket[5m])) by (le)
      )

  - record: lukhas:pipeline_latency_p95_5m
    expr: |
      histogram_quantile(0.95,
        sum(rate(lukhas_matriz_pipeline_duration_seconds_bucket[5m])) by (le)
      )

  - record: lukhas:guardian_latency_p95_5m
    expr: |
      histogram_quantile(0.95,
        sum(rate(lukhas_guardian_decision_duration_seconds_bucket[5m])) by (le)
      )

  - record: lukhas:memory_search_latency_p95_5m
    expr: |
      histogram_quantile(0.95,
        sum(rate(lukhas_memory_search_seconds_bucket[5m])) by (le)
      )

  - record: lukhas:orchestrator_routing_latency_p95_5m
    expr: |
      histogram_quantile(0.95,
        sum(rate(orchestrator_routing_latency_seconds_bucket[5m])) by (le)
      )

  - record: lukhas:memory_upsert_latency_p95_5m
    expr: |
      histogram_quantile(0.95,
        sum(rate(lukhas_memory_upsert_seconds_bucket[5m])) by (le)
      )

  - record: lukhas:memory_lifecycle_archive_latency_p95_5m
    expr: |
      histogram_quantile(0.95,
        sum(rate(lukhas_memory_lifecycle_seconds_bucket{operation="archive"}[5m])) by (le)
      )

  - record: lukhas:memory_lifecycle_gdpr_latency_p95_5m
    expr: |
      histogram_quantile(0.95,
        sum(rate(lukhas_memory_lifecycle_seconds_bucket{operation="gdpr_deletion"}[5m])) by (le)
      )

  - record: lukhas:memory_lifecycle_error_rate_1h
    expr: |
      sum(rate(lukhas_memory_lifecycle_errors_total[1h])) by (lane, operation) /
      sum(rate(lukhas_memory_lifecycle_operations_total[1h])) by (lane, operation)

  - record: lukhas:memory_lifecycle_error_rate_6h
    expr: |
      sum(rate(lukhas_memory_lifecycle_errors_total[6h])) by (lane, operation) /
      sum(rate(lukhas_memory_lifecycle_operations_total[6h])) by (lane, operation)

- name: lukhas_slo_critical
  interval: 30s
  rules:
  - alert: LUKHASAPIAvailabilityBelowSLO
    expr: |
      (
        sum(rate(http_requests_total{status!~"5.."}[5m])) /
        sum(rate(http_requests_total[5m]))
      ) < 0.999
    for: 2m
    labels:
      severity: critical
      service: lukhas-api
      slo: availability
      team: platform
    annotations:
      summary: "LUKHAS API availability below 99.9% SLO"
      description: "API availability is {{ $value | humanizePercentage }} over the last 5 minutes, below the 99.9% SLO target"
      runbook_url: "https://docs.lukhas.ai/runbooks/api-availability"

  - alert: LUKHASMemoryRecallLatencyBelowSLO
    expr: |
      histogram_quantile(0.95,
        rate(memory_recall_duration_seconds_bucket{lane=~"prod|candidate"}[5m])
      ) > 0.1
    for: 1m
    labels:
      severity: critical
      service: lukhas-memory
      slo: latency
      team: core
    annotations:
      summary: "Memory recall P95 latency above 100ms SLO"
      description: "Memory recall P95 latency is {{ $value }}s, above the 100ms SLO target"
      runbook_url: "https://docs.lukhas.ai/runbooks/memory-performance"

  - alert: LUKHASMATRIZPipelineLatencyBelowSLO
    expr: |
      histogram_quantile(0.95,
        rate(matriz_pipeline_duration_seconds_bucket{lane=~"prod|candidate"}[5m])
      ) > 0.25
    for: 1m
    labels:
      severity: critical
      service: lukhas-matriz
      slo: latency
      team: core
    annotations:
      summary: "MATRIZ pipeline P95 latency above 250ms SLO"
      description: "MATRIZ pipeline P95 latency is {{ $value }}s, above the 250ms SLO target"
      runbook_url: "https://docs.lukhas.ai/runbooks/matriz-performance"

  - alert: LUKHASGuardianDecisionLatencyBelowSLO
    expr: |
      histogram_quantile(0.99,
        rate(guardian_decision_duration_seconds_bucket{lane=~"prod|candidate"}[5m])
      ) > 0.005
    for: 30s
    labels:
      severity: critical
      service: lukhas-guardian
      slo: latency
      team: governance
    annotations:
      summary: "Guardian decision P99 latency above 5ms SLO"
      description: "Guardian decision P99 latency is {{ $value }}s, above the 5ms SLO target"
      runbook_url: "https://docs.lukhas.ai/runbooks/guardian-performance"

  - alert: LUKHASMemorySearchLatencyBelowSLO
    expr: |
      histogram_quantile(0.95,
        rate(lukhas_memory_search_seconds_bucket{lane=~"prod|candidate"}[5m])
      ) > 0.1
    for: 2m
    labels:
      severity: critical
      service: lukhas-memory
      slo: search_latency
      team: core
    annotations:
      summary: "Memory search P95 latency above 100ms SLO"
      description: "Memory search P95 latency is {{ $value }}s, above the 100ms SLO target"
      runbook_url: "https://docs.lukhas.ai/runbooks/memory-search-performance"

  - alert: LUKHASOrchestratorRoutingLatencyBelowSLO
    expr: |
      histogram_quantile(0.95,
        rate(orchestrator_routing_latency_seconds_bucket{lane=~"prod|candidate"}[5m])
      ) > 0.25
    for: 2m
    labels:
      severity: critical
      service: lukhas-orchestrator
      slo: routing_latency
      team: platform
    annotations:
      summary: "Orchestrator routing P95 latency above 250ms SLO"
      description: "Orchestrator routing P95 latency is {{ $value }}s, above the 250ms SLO target"
      runbook_url: "https://docs.lukhas.ai/runbooks/orchestrator-routing-performance"

  - alert: LUKHASMemoryUpsertLatencyBelowSLO
    expr: |
      histogram_quantile(0.95,
        rate(lukhas_memory_upsert_seconds_bucket{lane=~"prod|candidate"}[5m])
      ) > 0.1
    for: 2m
    labels:
      severity: critical
      service: lukhas-memory
      slo: upsert_latency
      team: core
    annotations:
      summary: "Memory upsert P95 latency above 100ms SLO"
      description: "Memory upsert P95 latency is {{ $value }}s, above the 100ms SLO target"
      runbook_url: "https://docs.lukhas.ai/runbooks/memory-upsert-performance"

  - alert: LUKHASMemoryLifecycleArchiveLatencyBelowSLO
    expr: |
      histogram_quantile(0.95,
        rate(lukhas_memory_lifecycle_seconds_bucket{operation="archive",lane=~"prod|candidate"}[5m])
      ) > 5
    for: 2m
    labels:
      severity: warning
      service: lukhas-memory
      slo: lifecycle_archive_latency
      team: core
    annotations:
      summary: "Memory lifecycle archive P95 latency above 5s SLO"
      description: "Memory archive operations P95 latency is {{ $value }}s, above the 5s SLO target"
      runbook_url: "https://docs.lukhas.ai/runbooks/memory-lifecycle-performance"

  - alert: LUKHASMemoryLifecycleGDPRLatencyBelowSLO
    expr: |
      histogram_quantile(0.95,
        rate(lukhas_memory_lifecycle_seconds_bucket{operation="gdpr_deletion",lane=~"prod|candidate"}[5m])
      ) > 5
    for: 2m
    labels:
      severity: critical
      service: lukhas-memory
      slo: lifecycle_gdpr_latency
      team: core
    annotations:
      summary: "Memory lifecycle GDPR deletion P95 latency above 5s SLO"
      description: "Memory GDPR deletion operations P95 latency is {{ $value }}s, above the 5s SLO target"
      runbook_url: "https://docs.lukhas.ai/runbooks/memory-gdpr-performance"

- name: lukhas_slo_warning
  interval: 1m
  rules:
  - alert: LUKHASErrorBudgetBurnRateHigh
    expr: |
      (
        rate(http_requests_total{status=~"5.."}[1h]) >
        (0.001 * 2)  # 2x normal error budget burn rate
      )
    for: 5m
    labels:
      severity: warning
      service: lukhas-api
      slo: error_budget
      team: platform
    annotations:
      summary: "LUKHAS API error budget burning too fast"
      description: "Error budget burn rate is {{ $value | humanizePercentage }}/hour, above sustainable rate"
      runbook_url: "https://docs.lukhas.ai/runbooks/error-budget-management"

  - alert: LUKHASErrorBudgetBurnRate1h
    expr: |
      (
        increase(http_requests_total{status=~"5.."}[1h]) >= 4
      )
    for: 1h
    labels:
      severity: warning
      service: lukhas-api
      slo: burn_rate
      window: 1h
      team: platform
    annotations:
      summary: "LUKHAS API error budget burn rate exceeded (1h window)"
      description: "{{ $value }} errors in 1 hour window, exceeding 4-error threshold"
      runbook_url: "https://docs.lukhas.ai/runbooks/error-budget-burn-rate"

  - alert: LUKHASErrorBudgetBurnRate6h
    expr: |
      (
        increase(http_requests_total{status=~"5.."}[6h]) >= 2
      )
    for: 6h
    labels:
      severity: critical
      service: lukhas-api
      slo: burn_rate
      window: 6h
      team: platform
    annotations:
      summary: "LUKHAS API error budget burn rate exceeded (6h window)"
      description: "{{ $value }} errors in 6 hour window, exceeding 2-error threshold"
      runbook_url: "https://docs.lukhas.ai/runbooks/error-budget-burn-rate"

  - alert: LUKHASConsciousnessSuccessRateBelowSLO
    expr: |
      (
        sum(rate(consciousness_queries_total{status="success"}[5m])) /
        sum(rate(consciousness_queries_total[5m]))
      ) < 0.90
    for: 3m
    labels:
      severity: warning
      service: lukhas-consciousness
      slo: success_rate
      team: core
    annotations:
      summary: "Consciousness processing success rate below 90% SLO"
      description: "Consciousness success rate is {{ $value | humanizePercentage }}, below 90% SLO target"
      runbook_url: "https://docs.lukhas.ai/runbooks/consciousness-reliability"

  - alert: LUKHASMemoryLifecycleErrorBurnRate1h
    expr: |
      (
        increase(lukhas_memory_lifecycle_errors_total{lane=~"prod|candidate"}[1h]) >= 4
      )
    for: 1h
    labels:
      severity: warning
      service: lukhas-memory
      slo: lifecycle_error_burn_rate
      window: 1h
      team: core
    annotations:
      summary: "Memory lifecycle error budget burn rate exceeded (1h window)"
      description: "{{ $value }} memory lifecycle errors in 1 hour window, exceeding 4-error threshold"
      runbook_url: "https://docs.lukhas.ai/runbooks/memory-lifecycle-error-budget"

  - alert: LUKHASMemoryLifecycleErrorBurnRate6h
    expr: |
      (
        increase(lukhas_memory_lifecycle_errors_total{lane=~"prod|candidate"}[6h]) >= 2
      )
    for: 6h
    labels:
      severity: critical
      service: lukhas-memory
      slo: lifecycle_error_burn_rate
      window: 6h
      team: core
    annotations:
      summary: "Memory lifecycle error budget burn rate exceeded (6h window)"
      description: "{{ $value }} memory lifecycle errors in 6 hour window, exceeding 2-error threshold"
      runbook_url: "https://docs.lukhas.ai/runbooks/memory-lifecycle-error-budget"

  - alert: LUKHASErrorBudgetExhaustion
    expr: |
      (
        1 - (
          increase(http_requests_total{status=~"5.."}[30d]) /
          increase(http_requests_total[30d])
        )
      ) < 0.2  # 20% error budget remaining
    for: 1m
    labels:
      severity: warning
      service: lukhas-api
      slo: error_budget
      team: platform
    annotations:
      summary: "LUKHAS API error budget running low"
      description: "Only {{ $value | humanizePercentage }} error budget remaining for this month"
      runbook_url: "https://docs.lukhas.ai/runbooks/error-budget-policy"

- name: lukhas_slo_recording_rules
  interval: 30s
  rules:
  # API Availability SLI
  - record: lukhas:api_availability:rate5m
    expr: |
      sum(rate(http_requests_total{status!~"5.."}[5m])) /
      sum(rate(http_requests_total[5m]))

  # Memory Recall Latency SLI
  - record: lukhas:memory_recall_latency:p95_5m
    expr: |
      histogram_quantile(0.95,
        rate(memory_recall_duration_seconds_bucket{lane=~"prod|candidate"}[5m])
      )

  # MATRIZ Pipeline Latency SLI
  - record: lukhas:matriz_pipeline_latency:p95_5m
    expr: |
      histogram_quantile(0.95,
        rate(matriz_pipeline_duration_seconds_bucket{lane=~"prod|candidate"}[5m])
      )

  # Guardian Decision Latency SLI
  - record: lukhas:guardian_decision_latency:p99_5m
    expr: |
      histogram_quantile(0.99,
        rate(guardian_decision_duration_seconds_bucket{lane=~"prod|candidate"}[5m])
      )

  # Error Budget Burn Rate (hourly)
  - record: lukhas:error_budget_burn_rate:1h
    expr: |
      rate(http_requests_total{status=~"5.."}[1h]) /
      (0.001 / 24)  # SLO allows 0.1% errors per month = ~0.0042% per day = ~0.000175% per hour

  # Monthly Error Budget Remaining
  - record: lukhas:error_budget_remaining:30d
    expr: |
      1 - (
        increase(http_requests_total{status=~"5.."}[30d]) /
        increase(http_requests_total[30d])
      ) / 0.001  # 0.1% monthly error budget