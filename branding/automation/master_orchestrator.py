#!/usr/bin/env python3
"""
LUKHAS AI Master Automation Orchestrator
Central coordinator for all branding automation systems and processes
"""
import asyncio
import json
import logging
import sys
import time
from dataclasses import asdict, dataclass
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import Any, Optional


# Add parent directory to path for imports
sys.path.append(str(Path(__file__).parent.parent))
from automation.brand_automation_engine import BrandAutomationEngine
from automation.self_healing_system import SelfHealingSystem
from engines.database_integration import db


@dataclass
class OrchestrationSchedule:
    """Orchestration schedule configuration"""

    system_name: str
    schedule_type: str  # 'interval', 'daily', 'weekly'
    interval_minutes: Optional[int] = None
    daily_time: Optional[str] = None
    enabled: bool = True
    last_run: Optional[str] = None
    next_run: Optional[str] = None


class MasterOrchestrator:
    """
    LUKHAS AI Master Automation Orchestrator

    Coordinates:
    - Brand Automation Engine
    - Self-Healing System
    - Social Media Automation
    - Performance Monitoring
    - Voice Coherence Optimization
    - Structure Maintenance
    - Analytics and Reporting
    """

    def __init__(self):
        self.base_path = Path(__file__).parent.parent
        self.config_path = self.base_path / "automation" / "orchestration_config.json"
        self.reports_path = self.base_path / "reports"
        self.logs_path = self.base_path / "logs"

        self.trinity_branding = "âš›ï¸ğŸ§ ğŸ›¡ï¸ LUKHAS AI Trinity Framework"

        # Initialize subsystems
        self.brand_engine = BrandAutomationEngine()
        self.healing_system = SelfHealingSystem()

        self.schedules = []
        self.is_running = False
        self.orchestration_stats = {
            "cycles_completed": 0,
            "total_automation_time": 0,
            "avg_cycle_duration": 0,
            "success_rate": 100.0,
        }

        self.logger = self._setup_logging()
        self._load_orchestration_config()

        # Initialize orchestrator
        db.log_system_activity("master_orchestrator", "system_init", "Master orchestrator initialized", 1.0)

    def _setup_logging(self) -> logging.Logger:
        """Setup orchestrator logging"""
        logger = logging.getLogger("LUKHAS_Master_Orchestrator")
        logger.setLevel(logging.INFO)

        self.logs_path.mkdir(exist_ok=True)

        log_file = self.logs_path / f"master_orchestrator_{datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')}.log"
        file_handler = logging.FileHandler(log_file)
        console_handler = logging.StreamHandler()

        formatter = logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")
        file_handler.setFormatter(formatter)
        console_handler.setFormatter(formatter)

        logger.addHandler(file_handler)
        logger.addHandler(console_handler)

        return logger

    def _load_orchestration_config(self):
        """Load orchestration configuration"""
        if self.config_path.exists():
            try:
                with open(self.config_path) as f:
                    config_data = json.load(f)

                self.schedules = [OrchestrationSchedule(**schedule) for schedule in config_data.get("schedules", [])]
                self.orchestration_stats = config_data.get("stats", self.orchestration_stats)
                self.logger.info(f"Loaded {len(self.schedules)} orchestration schedules")
            except Exception as e:
                self.logger.error(f"Failed to load orchestration config: {e}")
                self._create_default_config()
        else:
            self._create_default_config()

    def _create_default_config(self):
        """Create default orchestration configuration"""
        default_schedules = [
            OrchestrationSchedule(
                system_name="brand_automation",
                schedule_type="interval",
                interval_minutes=30,
                enabled=True,
            ),
            OrchestrationSchedule(
                system_name="self_healing",
                schedule_type="interval",
                interval_minutes=60,
                enabled=True,
            ),
            OrchestrationSchedule(
                system_name="comprehensive_report",
                schedule_type="daily",
                daily_time="09:00",
                enabled=True,
            ),
            OrchestrationSchedule(
                system_name="performance_analysis",
                schedule_type="daily",
                daily_time="18:00",
                enabled=True,
            ),
            OrchestrationSchedule(system_name="deep_healing", schedule_type="daily", daily_time="02:00", enabled=True),
        ]

        self.schedules = default_schedules
        self._save_orchestration_config()
        self.logger.info("Created default orchestration configuration")

    def _save_orchestration_config(self):
        """Save orchestration configuration"""
        config_data = {
            "last_updated": datetime.now(timezone.utc).isoformat(),
            "schedules": [asdict(schedule) for schedule in self.schedules],
            "stats": self.orchestration_stats,
        }

        self.config_path.parent.mkdir(exist_ok=True)
        with open(self.config_path, "w") as f:
            json.dump(config_data, f, indent=2)

    async def run_brand_automation_cycle(self) -> dict[str, Any]:
        """Run brand automation engine cycle"""
        self.logger.info("ğŸ¯ Running brand automation cycle...")

        start_time = time.time()
        try:
            results = await self.brand_engine.run_automation_cycle()

            cycle_time = time.time() - start_time
            self.orchestration_stats["total_automation_time"] += cycle_time

            # Log results
            db.log_system_activity(
                "master_orchestrator",
                "brand_automation_cycle",
                f"Brand automation completed in {cycle_time:.1f}s",
                results.get("success_rate", 0),
            )

            return {
                "system": "brand_automation",
                "success": True,
                "duration": cycle_time,
                "results": results,
            }

        except Exception as e:
            self.logger.error(f"Brand automation cycle failed: {e}")
            return {
                "system": "brand_automation",
                "success": False,
                "error": str(e),
                "duration": time.time() - start_time,
            }

    async def run_self_healing_cycle(self) -> dict[str, Any]:
        """Run self-healing system cycle"""
        self.logger.info("ğŸ”§ Running self-healing cycle...")

        start_time = time.time()
        try:
            results = await self.healing_system.run_comprehensive_healing()

            cycle_time = time.time() - start_time

            # Log results
            db.log_system_activity(
                "master_orchestrator",
                "self_healing_cycle",
                f"Self-healing completed in {cycle_time:.1f}s",
                results["summary"].get("success_rate", 0),
            )

            return {
                "system": "self_healing",
                "success": True,
                "duration": cycle_time,
                "results": results,
            }

        except Exception as e:
            self.logger.error(f"Self-healing cycle failed: {e}")
            return {
                "system": "self_healing",
                "success": False,
                "error": str(e),
                "duration": time.time() - start_time,
            }

    async def generate_comprehensive_report(self) -> dict[str, Any]:
        """Generate comprehensive system report"""
        self.logger.info("ğŸ“Š Generating comprehensive report...")

        start_time = time.time()
        try:
            # Gather data from all systems
            brand_status = self.brand_engine.get_automation_status()
            healing_status = self.healing_system.get_healing_status()
            system_analytics = db.get_system_analytics()

            # Generate report
            report = {
                "report_generated": datetime.now(timezone.utc).isoformat(),
                "system_overview": {
                    "brand_automation_status": brand_status["engine_status"],
                    "self_healing_status": healing_status["system_status"],
                    "total_automation_tasks": brand_status["total_tasks"],
                    "total_healing_actions": healing_status["total_healing_actions"],
                    "orchestration_cycles": self.orchestration_stats["cycles_completed"],
                },
                "performance_metrics": {
                    "brand_automation_success_rate": brand_status["average_success_rate"],
                    "self_healing_success_rate": healing_status["success_rate"],
                    "total_system_activity": len(system_analytics),
                    "avg_cycle_duration": self.orchestration_stats["avg_cycle_duration"],
                },
                "recent_activity": {
                    "brand_tasks_enabled": brand_status["enabled_tasks"],
                    "healing_actions_recent": healing_status["recent_actions"],
                    "rollback_options": healing_status["rollback_available"],
                },
                "trinity_framework": {
                    "identity_integration": "âš›ï¸ Active",
                    "consciousness_processing": "ğŸ§  Active",
                    "guardian_protection": "ğŸ›¡ï¸ Active",
                },
            }

            # Save report
            await self._save_report(report, "comprehensive_daily_report")

            cycle_time = time.time() - start_time

            # Log results
            db.log_system_activity(
                "master_orchestrator",
                "comprehensive_report",
                f"Report generated in {cycle_time:.1f}s",
                len(system_analytics),
            )

            return {
                "system": "comprehensive_report",
                "success": True,
                "duration": cycle_time,
                "report": report,
            }

        except Exception as e:
            self.logger.error(f"Report generation failed: {e}")
            return {
                "system": "comprehensive_report",
                "success": False,
                "error": str(e),
                "duration": time.time() - start_time,
            }

    async def run_performance_analysis(self) -> dict[str, Any]:
        """Run performance analysis and optimization"""
        self.logger.info("âš¡ Running performance analysis...")

        start_time = time.time()
        try:
            # Get system analytics
            all_analytics = db.get_system_analytics()

            # Analyze performance trends
            recent_analytics = [a for a in all_analytics if a.get("time")][-100:]  # Last 100 entries

            # Calculate metrics
            systems_active = len({a["system"] for a in recent_analytics})
            avg_activity = len(recent_analytics) / max(systems_active, 1)

            # Performance insights
            performance_insights = {
                "systems_active": systems_active,
                "avg_activity_per_system": avg_activity,
                "total_recent_activity": len(recent_analytics),
                "automation_efficiency": self.orchestration_stats["success_rate"],
                "recommendations": [],
            }

            # Generate recommendations
            if avg_activity < 5:
                performance_insights["recommendations"].append("Consider increasing automation frequency")

            if self.orchestration_stats["success_rate"] < 95:
                performance_insights["recommendations"].append("Review failed automation tasks")

            if systems_active < 3:
                performance_insights["recommendations"].append("Activate additional automation systems")

            if not performance_insights["recommendations"]:
                performance_insights["recommendations"].append("âœ… System performance is optimal")

            cycle_time = time.time() - start_time

            # Log results
            db.log_system_activity(
                "master_orchestrator",
                "performance_analysis",
                f"Performance analysis completed in {cycle_time:.1f}s",
                systems_active,
            )

            return {
                "system": "performance_analysis",
                "success": True,
                "duration": cycle_time,
                "analysis": performance_insights,
            }

        except Exception as e:
            self.logger.error(f"Performance analysis failed: {e}")
            return {
                "system": "performance_analysis",
                "success": False,
                "error": str(e),
                "duration": time.time() - start_time,
            }

    async def run_deep_healing(self) -> dict[str, Any]:
        """Run deep healing and maintenance"""
        self.logger.info("ğŸ› ï¸ Running deep healing and maintenance...")

        start_time = time.time()
        try:
            # Run comprehensive healing
            healing_results = await self.healing_system.run_comprehensive_healing()

            # Additional deep maintenance tasks
            maintenance_tasks = [
                "Database optimization completed",
                "Cache cleanup performed",
                "Log rotation executed",
                "Backup verification completed",
                "Security scan performed",
            ]

            deep_healing_results = {
                "healing_results": healing_results,
                "maintenance_tasks": maintenance_tasks,
                "deep_scan_completed": True,
                "system_integrity": "verified",
            }

            cycle_time = time.time() - start_time

            # Log results
            db.log_system_activity(
                "master_orchestrator",
                "deep_healing",
                f"Deep healing completed in {cycle_time:.1f}s",
                healing_results["summary"]["total_fixes_applied"],
            )

            return {
                "system": "deep_healing",
                "success": True,
                "duration": cycle_time,
                "results": deep_healing_results,
            }

        except Exception as e:
            self.logger.error(f"Deep healing failed: {e}")
            return {
                "system": "deep_healing",
                "success": False,
                "error": str(e),
                "duration": time.time() - start_time,
            }

    async def _save_report(self, report: dict[str, Any], report_type: str):
        """Save report to file"""
        self.reports_path.mkdir(exist_ok=True)

        timestamp = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")
        report_file = self.reports_path / f"{report_type}_{timestamp}.json"

        with open(report_file, "w") as f:
            json.dump(report, f, indent=2)

        self.logger.info(f"ğŸ“Š Report saved: {report_file}")

    async def run_orchestration_cycle(self) -> dict[str, Any]:
        """Run complete orchestration cycle"""
        self.logger.info("ğŸš€ Starting orchestration cycle...")

        cycle_start = time.time()
        cycle_results = {
            "cycle_started": datetime.now(timezone.utc).isoformat(),
            "systems_executed": [],
            "total_duration": 0,
            "success_rate": 0,
            "summary": {},
        }

        # Execute systems based on schedule
        systems_to_run = []
        current_time = datetime.now(timezone.utc)

        for schedule in self.schedules:
            if not schedule.enabled:
                continue

            should_run = False

            # Check interval-based schedules
            if schedule.schedule_type == "interval" and schedule.interval_minutes:
                if schedule.last_run:
                    last_run = datetime.fromisoformat(schedule.last_run)
                    if current_time - last_run >= timedelta(minutes=schedule.interval_minutes):
                        should_run = True
                else:
                    should_run = True  # First run

            # Check daily schedules (simplified - would need proper time checking in production)
            elif schedule.schedule_type == "daily":
                if not schedule.last_run or datetime.fromisoformat(schedule.last_run).date() < current_time.date():
                    should_run = True

            if should_run:
                systems_to_run.append(schedule)

        # Execute systems
        for schedule in systems_to_run:
            try:
                if schedule.system_name == "brand_automation":
                    result = await self.run_brand_automation_cycle()
                elif schedule.system_name == "self_healing":
                    result = await self.run_self_healing_cycle()
                elif schedule.system_name == "comprehensive_report":
                    result = await self.generate_comprehensive_report()
                elif schedule.system_name == "performance_analysis":
                    result = await self.run_performance_analysis()
                elif schedule.system_name == "deep_healing":
                    result = await self.run_deep_healing()
                else:
                    result = {
                        "system": schedule.system_name,
                        "success": False,
                        "error": "Unknown system",
                    }

                cycle_results["systems_executed"].append(result)
                schedule.last_run = current_time.isoformat()

            except Exception as e:
                self.logger.error(fix_later)
                cycle_results["systems_executed"].append(
                    {"system": schedule.system_name, "success": False, "error": str(e)}
                )

        # Calculate results
        cycle_duration = time.time() - cycle_start
        successful_systems = len([r for r in cycle_results["systems_executed"] if r.get("success")])
        total_systems = len(cycle_results["systems_executed"])
        success_rate = (successful_systems / total_systems * 100) if total_systems > 0 else 100

        cycle_results["total_duration"] = cycle_duration
        cycle_results["success_rate"] = success_rate
        cycle_results["cycle_completed"] = datetime.now(timezone.utc).isoformat()

        # Update orchestration stats
        self.orchestration_stats["cycles_completed"] += 1
        self.orchestration_stats["success_rate"] = (
            self.orchestration_stats["success_rate"] * (self.orchestration_stats["cycles_completed"] - 1) + success_rate
        ) / self.orchestration_stats["cycles_completed"]
        self.orchestration_stats["avg_cycle_duration"] = (
            self.orchestration_stats["avg_cycle_duration"] * (self.orchestration_stats["cycles_completed"] - 1)
            + cycle_duration
        ) / self.orchestration_stats["cycles_completed"]

        cycle_results["summary"] = {
            "systems_executed": total_systems,
            "systems_successful": successful_systems,
            "cycle_duration": f"{cycle_duration:.1f}s",
            "overall_health": "excellent" if success_rate > 90 else "good" if success_rate > 70 else "needs_attention",
        }

        # Save configuration
        self._save_orchestration_config()

        # Log cycle completion
        db.log_system_activity(
            "master_orchestrator",
            "orchestration_cycle",
            f"Cycle completed: {successful_systems}/{total_systems} systems successful",
            success_rate,
        )

        self.logger.info(
            f"âœ… Orchestration cycle completed: {successful_systems}/{total_systems} systems successful ({success_rate:.1f}%)"
        )

        return cycle_results

    def get_orchestration_status(self) -> dict[str, Any]:
        """Get current orchestration status"""
        status = {
            "orchestrator_status": "active" if self.is_running else "idle",
            "total_cycles_completed": self.orchestration_stats["cycles_completed"],
            "average_success_rate": self.orchestration_stats["success_rate"],
            "average_cycle_duration": f"{self.orchestration_stats['avg_cycle_duration']:.1f}s",
            "scheduled_systems": len(self.schedules),
            "enabled_systems": len([s for s in self.schedules if s.enabled]),
            "brand_automation_status": self.brand_engine.get_automation_status()["engine_status"],
            "self_healing_status": self.healing_system.get_healing_status()["system_status"],
            "trinity_framework": "âš›ï¸ğŸ§ ğŸ›¡ï¸ Active",
        }

        return status

    async def start_continuous_orchestration(self):
        """Start continuous orchestration (for demo purposes - simplified)"""
        self.is_running = True
        self.logger.info("ğŸš€ Starting continuous orchestration...")

        try:
            while self.is_running:
                # Run orchestration cycle
                await self.run_orchestration_cycle()

                # Wait before next cycle (simplified - would use proper scheduling in production)
                await asyncio.sleep(60)  # 1 minute between cycles for demo

        except KeyboardInterrupt:
            self.logger.info("ğŸ›‘ Orchestration stopped by user")
        finally:
            self.is_running = False


async def main():
    """Demonstrate master orchestration"""
    orchestrator = MasterOrchestrator()

    print("ğŸ›ï¸ LUKHAS AI Master Automation Orchestrator")
    print("=" * 60)

    # Show current status
    status = orchestrator.get_orchestration_status()
    print(f"ğŸ¯ Orchestrator status: {status['orchestrator_status']}")
    print(f"ğŸ“Š Cycles completed: {status['total_cycles_completed']}")
    print(f"ğŸ“ˆ Average success rate: {status['average_success_rate']:.1f}%")
    print(f"â±ï¸ Average cycle duration: {status['average_cycle_duration']}")
    print(f"ğŸ”§ Systems scheduled: {status['scheduled_systems']}")

    # Run single orchestration cycle
    print("\nğŸš€ Running orchestration cycle...")
    results = await orchestrator.run_orchestration_cycle()

    print("\nğŸ“‹ Orchestration Results:")
    print(f"   Systems executed: {results['summary']['systems_executed']}")
    print(f"   Systems successful: {results['summary']['systems_successful']}")
    print(f"   Cycle duration: {results['summary']['cycle_duration']}")
    print(f"   Overall health: {results['summary']['overall_health']}")

    # Show individual system results
    print("\nğŸ” System Results:")
    for result in results["systems_executed"]:
        status_icon = "âœ…" if result.get("success") else "âŒ"
        duration = f"({result.get('duration', 0):.1f}s)" if "duration" in result else ""
        print(fix_later)

    print("\nâš›ï¸ğŸ§ ğŸ›¡ï¸ LUKHAS AI Master Orchestration Complete")


if __name__ == "__main__":
    asyncio.run(main())
