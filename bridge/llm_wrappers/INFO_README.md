# LLM Wrappers â€” Unified Clients and Modulated Services
## Swappable providers with retries, streaming, and safety (âš›ï¸ğŸ§ ğŸ›¡ï¸)

Purpose
- Provide thin, testable wrappers for provider SDKs and compose them into higher-level, signal-aware services.

Primary components
- `UnifiedOpenAIClient` â€” async client; retries; task-based model mapping; streaming support
- `OpenAIModulatedService` â€” signals â†’ modulation â†’ retrieval v1 â†’ moderation â†’ OpenAI call

Contracts (abridged)
- generate(request) â†’ { text, model, modulation, usage? }
- generate_stream(request) â†’ async iterator[str]

Safety and observability
- Pre/post moderation hooks (Guardian-first with safe fallback)
- Metrics counters for requests/streams/blocks (surfaced by serve)

Testing
- Fake client/service adapters enable network-free unit tests for both non-stream and stream flows.

Trinity alignment
- âš›ï¸ Stable interfaces for identity and audit
- ğŸ§  Modulation and context weaving for cognition
- ğŸ›¡ï¸ Defense-in-depth via moderation hooks
